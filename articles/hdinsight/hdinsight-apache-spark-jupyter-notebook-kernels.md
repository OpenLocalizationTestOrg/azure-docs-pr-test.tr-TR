---
title: "Azure Hdınsight'ta Spark üzerinde Jupyter not defteri aaaKernels kümeleri | Microsoft Docs"
description: "Merhaba PySpark, PySpark3 ve Spark tekrar kullanılabilir Azure hdınsight'ta Spark kümeleri ile Jupyter not defteri için hakkında bilgi edinin."
keywords: "spark, jupyter spark üzerinde jupyter not defteri"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 0719e503-ee6d-41ac-b37e-3d77db8b121b
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/15/2017
ms.author: nitinme
ms.openlocfilehash: 560c944fe850c5753ac9fa90550b804f0c47d14c
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: tr-TR
ms.lasthandoff: 10/06/2017
---
# <a name="kernels-for-jupyter-notebook-on-spark-clusters-in-azure-hdinsight"></a><span data-ttu-id="09540-104">Azure hdınsight'ta Spark kümeleri Jupyter not defteri için tekrar</span><span class="sxs-lookup"><span data-stu-id="09540-104">Kernels for Jupyter notebook on Spark clusters in Azure HDInsight</span></span> 

<span data-ttu-id="09540-105">Hdınsight Spark kümeleri uygulamalarınızı test etme için Spark üzerinde hello Jupyter not defteri ile kullanabileceğiniz çekirdek sağlar.</span><span class="sxs-lookup"><span data-stu-id="09540-105">HDInsight Spark clusters provide kernels that you can use with hello Jupyter notebook on Spark for testing your applications.</span></span> <span data-ttu-id="09540-106">Bir çekirdek çalıştıran ve kodunuzu yorumlar bir programdır.</span><span class="sxs-lookup"><span data-stu-id="09540-106">A kernel is a program that runs and interprets your code.</span></span> <span data-ttu-id="09540-107">Merhaba üç tekrar şunlardır:</span><span class="sxs-lookup"><span data-stu-id="09540-107">hello three kernels are:</span></span>

- <span data-ttu-id="09540-108">**PySpark** - Python2 içinde yazılmış uygulamalar için</span><span class="sxs-lookup"><span data-stu-id="09540-108">**PySpark** - for applications written in Python2</span></span>
- <span data-ttu-id="09540-109">**PySpark3** - Python3 içinde yazılmış uygulamalar için</span><span class="sxs-lookup"><span data-stu-id="09540-109">**PySpark3** - for applications written in Python3</span></span>
- <span data-ttu-id="09540-110">**Spark** - Scala içinde yazılmış uygulamalar için</span><span class="sxs-lookup"><span data-stu-id="09540-110">**Spark** - for applications written in Scala</span></span>

<span data-ttu-id="09540-111">Bu makalede, bilgi nasıl toouse Bu tekrar ve bunları kullanmanın yararları hello.</span><span class="sxs-lookup"><span data-stu-id="09540-111">In this article, you learn how toouse these kernels and hello benefits of using them.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="09540-112">Ön koşullar</span><span class="sxs-lookup"><span data-stu-id="09540-112">Prerequisites</span></span>

* <span data-ttu-id="09540-113">Hdınsight'ta bir Apache Spark kümesi.</span><span class="sxs-lookup"><span data-stu-id="09540-113">An Apache Spark cluster in HDInsight.</span></span> <span data-ttu-id="09540-114">Yönergeler için bkz: [Azure Hdınsight'ta Apache Spark oluşturmak kümeleri](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="09540-114">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="create-a-jupyter-notebook-on-spark-hdinsight"></a><span data-ttu-id="09540-115">Spark Hdınsight üzerinde bir Jupyter not defteri oluşturma</span><span class="sxs-lookup"><span data-stu-id="09540-115">Create a Jupyter notebook on Spark HDInsight</span></span>

1. <span data-ttu-id="09540-116">Merhaba gelen [Azure portal](https://portal.azure.com/), kümenizi açın.</span><span class="sxs-lookup"><span data-stu-id="09540-116">From hello [Azure portal](https://portal.azure.com/), open your cluster.</span></span>  <span data-ttu-id="09540-117">Bkz: [listesi ve Göster kümeleri](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) hello yönergeler için.</span><span class="sxs-lookup"><span data-stu-id="09540-117">See [List and show clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) for hello instructions.</span></span> <span data-ttu-id="09540-118">Yeni bir portal dikey penceresinde Hello Küme açılır.</span><span class="sxs-lookup"><span data-stu-id="09540-118">hello cluster is opened in a new portal blade.</span></span>

2. <span data-ttu-id="09540-119">Merhaba gelen **hızlı bağlantılar** 'yi tıklatın **küme panolar** tooopen hello **küme panolar** dikey.</span><span class="sxs-lookup"><span data-stu-id="09540-119">From hello **Quick links** section, click **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span></span>  <span data-ttu-id="09540-120">Görmüyorsanız, **hızlı bağlantılar**, tıklatın **genel bakış** hello dikey penceresinde hello sol menüden.</span><span class="sxs-lookup"><span data-stu-id="09540-120">If you don't see **Quick Links**, click **Overview** from hello left menu on hello blade.</span></span>

    <span data-ttu-id="09540-121">![Jupyter not defteri Spark üzerinde](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Spark üzerinde Jupyter not defteri")</span><span class="sxs-lookup"><span data-stu-id="09540-121">![Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook on Spark")</span></span> 

3. <span data-ttu-id="09540-122">Tıklatın **Jupyter not defteri**.</span><span class="sxs-lookup"><span data-stu-id="09540-122">Click **Jupyter Notebook**.</span></span> <span data-ttu-id="09540-123">İstenirse, hello küme için hello yönetici kimlik bilgilerini girin.</span><span class="sxs-lookup"><span data-stu-id="09540-123">If prompted, enter hello admin credentials for hello cluster.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="09540-124">Merhaba Jupyter not defteri açma hello tarayıcınızda URL aşağıdaki tarafından Spark kümesinde de ulaşabilir.</span><span class="sxs-lookup"><span data-stu-id="09540-124">You may also reach hello Jupyter notebook on Spark cluster by opening hello following URL in your browser.</span></span> <span data-ttu-id="09540-125">Değiştir **CLUSTERNAME** kümenizi hello adı:</span><span class="sxs-lookup"><span data-stu-id="09540-125">Replace **CLUSTERNAME** with hello name of your cluster:</span></span>
   >
   > `https://CLUSTERNAME.azurehdinsight.net/jupyter`
   > 
   > 

3. <span data-ttu-id="09540-126">Tıklatın **yeni**ve ardından ya da **Pyspark**, **PySpark3**, veya **Spark** toocreate bir not defteri.</span><span class="sxs-lookup"><span data-stu-id="09540-126">Click **New**, and then click either **Pyspark**, **PySpark3**, or **Spark** toocreate a notebook.</span></span> <span data-ttu-id="09540-127">Merhaba Spark çekirdek Scala uygulamaları için PySpark çekirdeği Python2 uygulamaları için ve PySpark3 çekirdek Python3 uygulamalar için kullanın.</span><span class="sxs-lookup"><span data-stu-id="09540-127">Use hello Spark kernel for Scala applications, PySpark kernel for Python2 applications, and PySpark3 kernel for Python3 applications.</span></span>
   
    <span data-ttu-id="09540-128">![Spark üzerinde Jupyter not defteri için tekrar](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "için Spark Jupyter not defterlerinde çekirdekler")</span><span class="sxs-lookup"><span data-stu-id="09540-128">![Kernels for Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels for Jupyter notebook on Spark")</span></span> 

4. <span data-ttu-id="09540-129">Bir not defteri seçtiğiniz hello çekirdek ile açılır.</span><span class="sxs-lookup"><span data-stu-id="09540-129">A notebook opens with hello kernel you selected.</span></span>

## <a name="benefits-of-using-hello-kernels"></a><span data-ttu-id="09540-130">Merhaba tekrar kullanmanın yararları</span><span class="sxs-lookup"><span data-stu-id="09540-130">Benefits of using hello kernels</span></span>

<span data-ttu-id="09540-131">Spark Hdınsight kümeleri Jupyter not defteri ile Merhaba yeni tekrar kullanmanın bazı avantajları şunlardır.</span><span class="sxs-lookup"><span data-stu-id="09540-131">Here are a few benefits of using hello new kernels with Jupyter notebook on Spark HDInsight clusters.</span></span>

- <span data-ttu-id="09540-132">**Bağlamları önceden**.</span><span class="sxs-lookup"><span data-stu-id="09540-132">**Preset contexts**.</span></span> <span data-ttu-id="09540-133">İle **PySpark**, **PySpark3**, veya hello **Spark** çekirdekleri gerektirmeyen tooset hello Spark veya Hive bağlamları açıkça, uygulamalarla çalışmaya başlamadan önce.</span><span class="sxs-lookup"><span data-stu-id="09540-133">With  **PySpark**, **PySpark3**, or hello **Spark** kernels, you do not need tooset hello Spark or Hive contexts explicitly before you start working with your applications.</span></span> <span data-ttu-id="09540-134">Bu, varsayılan olarak kullanılabilir.</span><span class="sxs-lookup"><span data-stu-id="09540-134">These are available by default.</span></span> <span data-ttu-id="09540-135">Bu içerikler şunlardır:</span><span class="sxs-lookup"><span data-stu-id="09540-135">These contexts are:</span></span>
   
   * <span data-ttu-id="09540-136">**sc** - Spark bağlamı için</span><span class="sxs-lookup"><span data-stu-id="09540-136">**sc** - for Spark context</span></span>
   * <span data-ttu-id="09540-137">**sqlContext** - Hive bağlamı için</span><span class="sxs-lookup"><span data-stu-id="09540-137">**sqlContext** - for Hive context</span></span>

    <span data-ttu-id="09540-138">Bu nedenle, hello tooset hello bağlamları aşağıdaki gibi toorun deyimlere yok:</span><span class="sxs-lookup"><span data-stu-id="09540-138">So, you don't have toorun statements like hello following tooset hello contexts:</span></span>

        <span data-ttu-id="09540-139">SC SparkContext('yarn-client') sqlContext = HiveContext(sc) =</span><span class="sxs-lookup"><span data-stu-id="09540-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span></span>

    <span data-ttu-id="09540-140">Bunun yerine, doğrudan kullanabileceğiniz hello uygulamanızı bağlamlarda hazır.</span><span class="sxs-lookup"><span data-stu-id="09540-140">Instead, you can directly use hello preset contexts in your application.</span></span>

- <span data-ttu-id="09540-141">**Hücre sihirleri**.</span><span class="sxs-lookup"><span data-stu-id="09540-141">**Cell magics**.</span></span> <span data-ttu-id="09540-142">Merhaba PySpark çekirdeği bazı önceden tanımlanmış "sihirleri" ile çağırabilir özel komutlar olduğu sağlar `%%` (örneğin, `%%MAGIC` <args>).</span><span class="sxs-lookup"><span data-stu-id="09540-142">hello PySpark kernel provides some predefined “magics”, which are special commands that you can call with `%%` (for example, `%%MAGIC` <args>).</span></span> <span data-ttu-id="09540-143">Merhaba Sihirli komutu hello birinci kod hücresini Word'de ve içeriği için birden çok satır izin gerekir.</span><span class="sxs-lookup"><span data-stu-id="09540-143">hello magic command must be hello first word in a code cell and allow for multiple lines of content.</span></span> <span data-ttu-id="09540-144">Merhaba Sihirli word hello ilk hello hücre Word'de olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="09540-144">hello magic word should be hello first word in hello cell.</span></span> <span data-ttu-id="09540-145">Merhaba Sihirli, hatta açıklamaları önce herhangi bir şey ekleme bir hataya neden olur.</span><span class="sxs-lookup"><span data-stu-id="09540-145">Adding anything before hello magic, even comments, causes an error.</span></span>     <span data-ttu-id="09540-146">Sihirler hakkında daha fazla bilgi için bkz: [burada](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span><span class="sxs-lookup"><span data-stu-id="09540-146">For more information on magics, see [here](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span></span>
   
    <span data-ttu-id="09540-147">Merhaba aşağıdaki tabloda farklı sihirler hello hello tekrar kullanılabilir listeler.</span><span class="sxs-lookup"><span data-stu-id="09540-147">hello following table lists hello different magics available through hello kernels.</span></span>

   | <span data-ttu-id="09540-148">Özel numarası</span><span class="sxs-lookup"><span data-stu-id="09540-148">Magic</span></span> | <span data-ttu-id="09540-149">Örnek</span><span class="sxs-lookup"><span data-stu-id="09540-149">Example</span></span> | <span data-ttu-id="09540-150">Açıklama</span><span class="sxs-lookup"><span data-stu-id="09540-150">Description</span></span> |
   | --- | --- | --- |
   | <span data-ttu-id="09540-151">Yardım</span><span class="sxs-lookup"><span data-stu-id="09540-151">help</span></span> |`%%help` |<span data-ttu-id="09540-152">Örnek ve açıklama ile tüm hello kullanılabilir sihirler oluşan bir tablo oluşturur</span><span class="sxs-lookup"><span data-stu-id="09540-152">Generates a table of all hello available magics with example and description</span></span> |
   | <span data-ttu-id="09540-153">bilgileri</span><span class="sxs-lookup"><span data-stu-id="09540-153">info</span></span> |`%%info` |<span data-ttu-id="09540-154">Çıkış oturum bilgilerini hello geçerli Livy uç noktası</span><span class="sxs-lookup"><span data-stu-id="09540-154">Outputs session information for hello current Livy endpoint</span></span> |
   | <span data-ttu-id="09540-155">Yapılandırma</span><span class="sxs-lookup"><span data-stu-id="09540-155">configure</span></span> |`%%configure -f`<br><span data-ttu-id="09540-156">`{"executorMemory": "1000M"`,</span><span class="sxs-lookup"><span data-stu-id="09540-156">`{"executorMemory": "1000M"`,</span></span><br><span data-ttu-id="09540-157">`"executorCores": 4`}</span><span class="sxs-lookup"><span data-stu-id="09540-157">`"executorCores": 4`}</span></span> |<span data-ttu-id="09540-158">Oturum oluşturmak için hello parametreler yapılandırır.</span><span class="sxs-lookup"><span data-stu-id="09540-158">Configures hello parameters for creating a session.</span></span> <span data-ttu-id="09540-159">Force bayrağını hello (-f) bir oturum zaten oluşturulmuşsa, bu hello oturum sağlar bırakılan ve yeniden zorunludur.</span><span class="sxs-lookup"><span data-stu-id="09540-159">hello force flag (-f) is mandatory if a session has already been created, which ensures that hello session is dropped and recreated.</span></span> <span data-ttu-id="09540-160">Bakmak [Livy'nın POST /sessions iste gövde](https://github.com/cloudera/livy#request-body) için geçerli parametrelerin bir listesi.</span><span class="sxs-lookup"><span data-stu-id="09540-160">Look at [Livy's POST /sessions Request Body](https://github.com/cloudera/livy#request-body) for a list of valid parameters.</span></span> <span data-ttu-id="09540-161">Parametreleri JSON dizesi olarak geçirilmesi gerekir ve hello sonraki satırda hello örnek sütununda gösterildiği gibi hello Sihirli sonra olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="09540-161">Parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span> |
   | <span data-ttu-id="09540-162">SQL</span><span class="sxs-lookup"><span data-stu-id="09540-162">sql</span></span> |`%%sql -o <variable name>`<br> `SHOW TABLES` |<span data-ttu-id="09540-163">Merhaba sqlContext bir Hive sorgusu yürütür.</span><span class="sxs-lookup"><span data-stu-id="09540-163">Executes a Hive query against hello sqlContext.</span></span> <span data-ttu-id="09540-164">Merhaba, `-o` parametresi geçirilir, hello hello sorgunun sonucu hello kalıcı %% yerel Python bağlamı olarak bir [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="09540-164">If hello `-o` parameter is passed, hello result of hello query is persisted in hello %%local Python context as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> |
   | <span data-ttu-id="09540-165">Yerel</span><span class="sxs-lookup"><span data-stu-id="09540-165">local</span></span> |`%%local`<br>`a=1` |<span data-ttu-id="09540-166">Sonraki satırların tüm hello kodda yerel olarak yürütülür.</span><span class="sxs-lookup"><span data-stu-id="09540-166">All hello code in subsequent lines is executed locally.</span></span> <span data-ttu-id="09540-167">Kodu dahi, kullanmakta olduğunuz hello çekirdek yedeklemiş geçerli Python2 kodu olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="09540-167">Code must be valid Python2 code even irrespective of hello kernel you are using.</span></span> <span data-ttu-id="09540-168">Bu nedenle, seçtiğiniz olsa bile **PySpark3** veya **Spark** hello kullanırsanız hello Not Defteri, oluşturma sırasında tekrar `%%local` Sihirli bir hücreye, o hücre yalnızca geçerli Python2 kodu olmalıdır...</span><span class="sxs-lookup"><span data-stu-id="09540-168">So, even if you selected **PySpark3** or **Spark** kernels while creating hello notebook, if you use hello `%%local` magic in a cell, that cell must only have valid Python2 code..</span></span> |
   | <span data-ttu-id="09540-169">günlükler</span><span class="sxs-lookup"><span data-stu-id="09540-169">logs</span></span> |`%%logs` |<span data-ttu-id="09540-170">Çıktı hello geçerli Livy oturumu için günlükleri hello.</span><span class="sxs-lookup"><span data-stu-id="09540-170">Outputs hello logs for hello current Livy session.</span></span> |
   | <span data-ttu-id="09540-171">Sil</span><span class="sxs-lookup"><span data-stu-id="09540-171">delete</span></span> |`%%delete -f -s <session number>` |<span data-ttu-id="09540-172">Belirli bir oturum hello geçerli Livy uç noktasının siler.</span><span class="sxs-lookup"><span data-stu-id="09540-172">Deletes a specific session of hello current Livy endpoint.</span></span> <span data-ttu-id="09540-173">Başlatılan hello oturumu hello çekirdek kendisi için silemezsiniz unutmayın.</span><span class="sxs-lookup"><span data-stu-id="09540-173">Note that you cannot delete hello session that is initiated for hello kernel itself.</span></span> |
   | <span data-ttu-id="09540-174">Temizleme</span><span class="sxs-lookup"><span data-stu-id="09540-174">cleanup</span></span> |`%%cleanup -f` |<span data-ttu-id="09540-175">Bu not defterinin oturum dahil olmak üzere hello geçerli Livy uç noktası için tüm hello oturumları siler.</span><span class="sxs-lookup"><span data-stu-id="09540-175">Deletes all hello sessions for hello current Livy endpoint, including this notebook's session.</span></span> <span data-ttu-id="09540-176">Merhaba force bayrağını -f zorunludur.</span><span class="sxs-lookup"><span data-stu-id="09540-176">hello force flag -f is mandatory.</span></span> |

   > [!NOTE]
   > <span data-ttu-id="09540-177">Ayrıca toohello sihirler eklenen hello PySpark çekirdeği tarafından hello da kullanabilirsiniz [yerleşik IPython sihirler](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics)gibi `%%sh`.</span><span class="sxs-lookup"><span data-stu-id="09540-177">In addition toohello magics added by hello PySpark kernel, you can also use hello [built-in IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), including `%%sh`.</span></span> <span data-ttu-id="09540-178">Merhaba kullanabilirsiniz `%%sh` Sihirli toorun komut dosyaları ve hello küme headnode üzerinde kod bloğu.</span><span class="sxs-lookup"><span data-stu-id="09540-178">You can use hello `%%sh` magic toorun scripts and block of code on hello cluster headnode.</span></span>
   >
   >
2. <span data-ttu-id="09540-179">**Otomatik görselleştirme**.</span><span class="sxs-lookup"><span data-stu-id="09540-179">**Auto visualization**.</span></span> <span data-ttu-id="09540-180">Merhaba **Pyspark** çekirdek otomatik olarak Hive ve SQL sorguları hello çıktısını visualizes.</span><span class="sxs-lookup"><span data-stu-id="09540-180">hello **Pyspark** kernel automatically visualizes hello output of Hive and SQL queries.</span></span> <span data-ttu-id="09540-181">Tablo, pasta, satır, alan, çubuk dahil olmak üzere görselleştirmeleri birkaç farklı türde arasında seçim yapabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="09540-181">You can choose between several different types of visualizations including Table, Pie, Line, Area, Bar.</span></span>

## <a name="parameters-supported-with-hello-sql-magic"></a><span data-ttu-id="09540-182">Merhaba ile desteklenen parametreler %% sql Sihirli</span><span class="sxs-lookup"><span data-stu-id="09540-182">Parameters supported with hello %%sql magic</span></span>
<span data-ttu-id="09540-183">Merhaba `%%sql` Sihirli toocontrol hello sorguları çalıştırdığınızda, aldığınız çıkış tür kullanabileceğiniz farklı parametreleri destekler.</span><span class="sxs-lookup"><span data-stu-id="09540-183">hello `%%sql` magic supports different parameters that you can use toocontrol hello kind of output that you receive when you run queries.</span></span> <span data-ttu-id="09540-184">Aşağıdaki tablonun hello hello çıkış listeler.</span><span class="sxs-lookup"><span data-stu-id="09540-184">hello following table lists hello output.</span></span>

| <span data-ttu-id="09540-185">Parametre</span><span class="sxs-lookup"><span data-stu-id="09540-185">Parameter</span></span> | <span data-ttu-id="09540-186">Örnek</span><span class="sxs-lookup"><span data-stu-id="09540-186">Example</span></span> | <span data-ttu-id="09540-187">Açıklama</span><span class="sxs-lookup"><span data-stu-id="09540-187">Description</span></span> |
| --- | --- | --- |
| <span data-ttu-id="09540-188">-o</span><span class="sxs-lookup"><span data-stu-id="09540-188">-o</span></span> |`-o <VARIABLE NAME>` |<span data-ttu-id="09540-189">Merhaba sorgu, bu parametre toopersist hello sonucunu hello kullanmak %% yerel Python bağlamı olarak bir [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="09540-189">Use this parameter toopersist hello result of hello query, in hello %%local Python context, as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> <span data-ttu-id="09540-190">Hello hello dataframe değişkenin adını, belirttiğiniz hello değişken adıdır.</span><span class="sxs-lookup"><span data-stu-id="09540-190">hello name of hello dataframe variable is hello variable name you specify.</span></span> |
| <span data-ttu-id="09540-191">-q</span><span class="sxs-lookup"><span data-stu-id="09540-191">-q</span></span> |`-q` |<span data-ttu-id="09540-192">Bu tooturn görselleştirmeleri kapalı hello hücre için kullanın.</span><span class="sxs-lookup"><span data-stu-id="09540-192">Use this tooturn off visualizations for hello cell.</span></span> <span data-ttu-id="09540-193">Tooauto istemiyorsanız-bir hücre Merhaba içeriğine görselleştirmek ve yalnızca toocapture istediğiniz bir dataframe olarak daha sonra kullanmak `-q -o <VARIABLE>`.</span><span class="sxs-lookup"><span data-stu-id="09540-193">If you don't want tooauto-visualize hello content of a cell and just want toocapture it as a dataframe, then use `-q -o <VARIABLE>`.</span></span> <span data-ttu-id="09540-194">Merhaba sonuçları yakalama olmadan tooturn görselleştirmeleri kapatmak istiyorsanız (örneğin, bir SQL sorgusu gibi çalıştırmak için bir `CREATE TABLE` deyimi), kullanın `-q` belirtmeden bir `-o` bağımsız değişkeni.</span><span class="sxs-lookup"><span data-stu-id="09540-194">If you want tooturn off visualizations without capturing hello results (for example, for running a SQL query, like a `CREATE TABLE` statement), use `-q` without specifying a `-o` argument.</span></span> |
| <span data-ttu-id="09540-195">-m</span><span class="sxs-lookup"><span data-stu-id="09540-195">-m</span></span> |`-m <METHOD>` |<span data-ttu-id="09540-196">Burada **yöntemi** ya **ele** veya **örnek** (varsayılan değer **ele**).</span><span class="sxs-lookup"><span data-stu-id="09540-196">Where **METHOD** is either **take** or **sample** (default is **take**).</span></span> <span data-ttu-id="09540-197">Merhaba yöntemi ise **ele**, hello çekirdek MAXROWS (daha sonra bu tabloda açıklanan) tarafından belirtilen hello sonuç veri kümesinin hello üst öğeden seçer.</span><span class="sxs-lookup"><span data-stu-id="09540-197">If hello method is **take**, hello kernel picks elements from hello top of hello result data set specified by MAXROWS (described later in this table).</span></span> <span data-ttu-id="09540-198">Merhaba yöntemi ise **örnek**, hello çekirdek rastgele örnekler hello veri çok göre kümenin öğeleri`-r` sonraki bu tabloda açıklanan parametresi.</span><span class="sxs-lookup"><span data-stu-id="09540-198">If hello method is **sample**, hello kernel randomly samples elements of hello data set according too`-r` parameter, described next in this table.</span></span> |
| <span data-ttu-id="09540-199">-r</span><span class="sxs-lookup"><span data-stu-id="09540-199">-r</span></span> |`-r <FRACTION>` |<span data-ttu-id="09540-200">Burada **KESİR** 0,0 ile 1,0 arasında bir kayan noktalı sayı.</span><span class="sxs-lookup"><span data-stu-id="09540-200">Here **FRACTION** is a floating-point number between 0.0 and 1.0.</span></span> <span data-ttu-id="09540-201">Merhaba SQL sorgusu Hello örnek yöntemi olarak ayarlanmışsa `sample`, sonra da hello çekirdek rastgele hello belirtilen kesir için ayarladığınız hello sonuç hello öğelerinin örnekleri.</span><span class="sxs-lookup"><span data-stu-id="09540-201">If hello sample method for hello SQL query is `sample`, then hello kernel randomly samples hello specified fraction of hello elements of hello result set for you.</span></span> <span data-ttu-id="09540-202">Örneğin, bir SQL sorgusu hello bağımsız değişkenlerle çalıştırırsanız `-m sample -r 0.01`, %1 hello sonuç satır rastgele örneklenen sonra.</span><span class="sxs-lookup"><span data-stu-id="09540-202">For example, if you run a SQL query with hello arguments `-m sample -r 0.01`, then 1% of hello result rows are randomly sampled.</span></span> |
| -n |`-n <MAXROWS>` |<span data-ttu-id="09540-203">**MAXROWS** bir tamsayı değil.</span><span class="sxs-lookup"><span data-stu-id="09540-203">**MAXROWS** is an integer value.</span></span> <span data-ttu-id="09540-204">Merhaba çekirdek sınırlar hello çıkış satır sayısı çok**MAXROWS**.</span><span class="sxs-lookup"><span data-stu-id="09540-204">hello kernel limits hello number of output rows too**MAXROWS**.</span></span> <span data-ttu-id="09540-205">Varsa **MAXROWS** negatif bir sayı olduğu gibi **-1**, hello hello sonuç kümesi satır sayısı sınırlı değildir.</span><span class="sxs-lookup"><span data-stu-id="09540-205">If **MAXROWS** is a negative number such as **-1**, then hello number of rows in hello result set is not limited.</span></span> |

<span data-ttu-id="09540-206">**Örnek:**</span><span class="sxs-lookup"><span data-stu-id="09540-206">**Example:**</span></span>

    %%sql -q -m sample -r 0.1 -n 500 -o query2
    SELECT * FROM hivesampletable

<span data-ttu-id="09540-207">Yukarıdaki Hello ifade aşağıdaki hello:</span><span class="sxs-lookup"><span data-stu-id="09540-207">hello statement above does hello following:</span></span>

* <span data-ttu-id="09540-208">Tüm kayıtları seçer **hivesampletable**.</span><span class="sxs-lookup"><span data-stu-id="09540-208">Selects all records from **hivesampletable**.</span></span>
* <span data-ttu-id="09540-209">-Q, kullandığımız için otomatik görselleştirme devre dışı bırakır.</span><span class="sxs-lookup"><span data-stu-id="09540-209">Because we use -q, it turns off auto-visualization.</span></span>
* <span data-ttu-id="09540-210">Biz kullandığından `-m sample -r 0.1 -n 500` % 10'hello hivesampletable hello satır rastgele örnekler ve sınırları hello hello sonuç kümesi too500 satır boyutu.</span><span class="sxs-lookup"><span data-stu-id="09540-210">Because we use `-m sample -r 0.1 -n 500` it randomly samples 10% of hello rows in hello hivesampletable and limits hello size of hello result set too500 rows.</span></span>
* <span data-ttu-id="09540-211">Son olarak, biz kullanıldığından `-o query2` de adlı bir dataframe hello çıkış kaydeder **sorgu2**.</span><span class="sxs-lookup"><span data-stu-id="09540-211">Finally, because we used `-o query2` it also saves hello output into a dataframe called **query2**.</span></span>

## <a name="considerations-while-using-hello-new-kernels"></a><span data-ttu-id="09540-212">Merhaba yeni tekrar kullanırken dikkat edilecek noktalar</span><span class="sxs-lookup"><span data-stu-id="09540-212">Considerations while using hello new kernels</span></span>

<span data-ttu-id="09540-213">Kullanın, hangi çekirdek çalıştıran hello not defterlerini bırakarak hello küme kaynaklarını kullanır.</span><span class="sxs-lookup"><span data-stu-id="09540-213">Whichever kernel you use, leaving hello notebooks running consumes hello cluster resources.</span></span>  <span data-ttu-id="09540-214">Bu çekirdekleri hello bağlamları hazır olduğundan, yalnızca hello not defterlerini çıkma hello bağlam KILL değil ve bu nedenle hello küme kaynaklarını toobe kullanımda devam.</span><span class="sxs-lookup"><span data-stu-id="09540-214">With these kernels, because hello contexts are preset, simply exiting hello notebooks does not kill hello context and hence hello cluster resources continue toobe in use.</span></span> <span data-ttu-id="09540-215">Toouse hello iyi bir uygulamadır **Kapat ve Durdur** hello not defterinin seçeneğinden **dosya** hello bağlam sonlandırır hello Not Defteri kullanarak tamamlanmış ve sonra not defteri çıkar hello menüsü.</span><span class="sxs-lookup"><span data-stu-id="09540-215">A good practice is toouse hello **Close and Halt** option from hello notebook's **File** menu when you are finished using hello notebook, which kills hello context and then exits hello notebook.</span></span>     

## <a name="show-me-some-examples"></a><span data-ttu-id="09540-216">Bazı örnekler Göster</span><span class="sxs-lookup"><span data-stu-id="09540-216">Show me some examples</span></span>

<span data-ttu-id="09540-217">Jupyter not defteri açtığınızda, iki klasör kullanılabilir hello kök düzeyinde görürsünüz.</span><span class="sxs-lookup"><span data-stu-id="09540-217">When you open a Jupyter notebook, you see two folders available at hello root level.</span></span>

* <span data-ttu-id="09540-218">Merhaba **PySpark** klasörü bulunan örnek not defterlerini bu kullanım hello yeni **Python** çekirdek.</span><span class="sxs-lookup"><span data-stu-id="09540-218">hello **PySpark** folder has sample notebooks that use hello new **Python** kernel.</span></span>
* <span data-ttu-id="09540-219">Merhaba **Scala** klasörü bulunan örnek not defterlerini bu kullanım hello yeni **Spark** çekirdek.</span><span class="sxs-lookup"><span data-stu-id="09540-219">hello **Scala** folder has sample notebooks that use hello new **Spark** kernel.</span></span>

<span data-ttu-id="09540-220">Merhaba açabilirsiniz **00 - [okuma önce BENİ] Spark Sihirli çekirdek Özellikler** hello dizüstü bilgisayarınızı **PySpark** veya **Spark** klasörü toolearn hakkında hello farklı sihirler kullanılabilir.</span><span class="sxs-lookup"><span data-stu-id="09540-220">You can open hello **00 - [READ ME FIRST] Spark Magic Kernel Features** notebook from hello **PySpark** or **Spark** folder toolearn about hello different magics available.</span></span> <span data-ttu-id="09540-221">Aynı zamanda diğer örnek not defterlerini hello iki klasörleri toolearn altında kullanılabilir nasıl hello tooachieve farklı senaryolar Hdınsight Spark kümeleri ile Jupyter not defterlerini kullanarak.</span><span class="sxs-lookup"><span data-stu-id="09540-221">You can also use hello other sample notebooks available under hello two folders toolearn how tooachieve different scenarios using Jupyter notebooks with HDInsight Spark clusters.</span></span>

## <a name="where-are-hello-notebooks-stored"></a><span data-ttu-id="09540-222">Merhaba not defterlerini depolandığı?</span><span class="sxs-lookup"><span data-stu-id="09540-222">Where are hello notebooks stored?</span></span>

<span data-ttu-id="09540-223">Jupyter not defterleri hello altında hello kümeyle ilişkili toohello depolama hesabı kaydedilir **/HdiNotebooks** klasör.</span><span class="sxs-lookup"><span data-stu-id="09540-223">Jupyter notebooks are saved toohello storage account associated with hello cluster under hello **/HdiNotebooks** folder.</span></span>  <span data-ttu-id="09540-224">Dizüstü bilgisayarlar, metin dosyaları ve Jupyter içinde oluşturduğunuz klasörler hello depolama hesabından erişilebilir.</span><span class="sxs-lookup"><span data-stu-id="09540-224">Notebooks, text files, and folders that you create from within Jupyter are accessible from hello storage account.</span></span>  <span data-ttu-id="09540-225">Jupyter toocreate bir klasörü kullanırsanız, örneğin, **Klasörüm'ün** ve dizüstü **myfolder/mynotebook.ipynb**, o not defteri konumunda erişebilirsiniz `/HdiNotebooks/myfolder/mynotebook.ipynb` hello depolama hesabındaki.</span><span class="sxs-lookup"><span data-stu-id="09540-225">For example, if you use Jupyter toocreate a folder **myfolder** and a notebook **myfolder/mynotebook.ipynb**, you can access that notebook at `/HdiNotebooks/myfolder/mynotebook.ipynb` within hello storage account.</span></span>  <span data-ttu-id="09540-226">Merhaba ters de true, diğer bir deyişle, tooyour depolama hesabı doğrudan bir not defteri yüklerseniz `/HdiNotebooks/mynotebook1.ipynb`, hello dizüstü görülebilir Jupyter de.</span><span class="sxs-lookup"><span data-stu-id="09540-226">hello reverse is also true, that is, if you upload a notebook directly tooyour storage account at `/HdiNotebooks/mynotebook1.ipynb`, hello notebook is visible from Jupyter as well.</span></span>  <span data-ttu-id="09540-227">Hatta hello kümesi silindikten sonra not defterlerini hello depolama hesabında kalır.</span><span class="sxs-lookup"><span data-stu-id="09540-227">Notebooks remain in hello storage account even after hello cluster is deleted.</span></span>

<span data-ttu-id="09540-228">not defterlerini toohello depolama hesabı kaydedilir hello ile HDFS uyumlu yoludur.</span><span class="sxs-lookup"><span data-stu-id="09540-228">hello way notebooks are saved toohello storage account is compatible with HDFS.</span></span> <span data-ttu-id="09540-229">Bunu, SSH kullanabilirsiniz hello kümesine yönetimi komutları hello aşağıdaki kod parçacığında gösterildiği gibi dosyası varsa:</span><span class="sxs-lookup"><span data-stu-id="09540-229">So, if you SSH into hello cluster you can use file management commands as shown in hello following snippet:</span></span>

    hdfs dfs -ls /HdiNotebooks                               # List everything at hello root directory – everything in this directory is visible tooJupyter from hello home page
    hdfs dfs –copyToLocal /HdiNotebooks                    # Download hello contents of hello HdiNotebooks folder
    hdfs dfs –copyFromLocal example.ipynb /HdiNotebooks   # Upload a notebook example.ipynb toohello root folder so it’s visible from Jupyter


<span data-ttu-id="09540-230">Durumunda hello hello küme için depolama hesabı erişim sorunları, hello not defterlerini hello headnode üzerinde de kaydedilir `/var/lib/jupyter`.</span><span class="sxs-lookup"><span data-stu-id="09540-230">In case there are issues accessing hello storage account for hello cluster, hello notebooks are also saved on hello headnode `/var/lib/jupyter`.</span></span>

## <a name="supported-browser"></a><span data-ttu-id="09540-231">Desteklenen tarayıcı</span><span class="sxs-lookup"><span data-stu-id="09540-231">Supported browser</span></span>

<span data-ttu-id="09540-232">Spark Hdınsight kümeleri Jupyter not defterlerini yalnızca Google Chrome üzerinde desteklenir.</span><span class="sxs-lookup"><span data-stu-id="09540-232">Jupyter notebooks on Spark HDInsight clusters are supported only on Google Chrome.</span></span>

## <a name="feedback"></a><span data-ttu-id="09540-233">Geri Bildirim</span><span class="sxs-lookup"><span data-stu-id="09540-233">Feedback</span></span>
<span data-ttu-id="09540-234">Hello yeni tekrar aşama gelişen olan ve zaman içinde yetişkin.</span><span class="sxs-lookup"><span data-stu-id="09540-234">hello new kernels are in evolving stage and will mature over time.</span></span> <span data-ttu-id="09540-235">Bu aynı zamanda bu tekrar yetişkin olarak API'leri değişebilir anlamına gelebilir.</span><span class="sxs-lookup"><span data-stu-id="09540-235">This could also mean that APIs could change as these kernels mature.</span></span> <span data-ttu-id="09540-236">Bu yeni tekrar kullanırken sahip herhangi bir geri bildirim veriyoruz.</span><span class="sxs-lookup"><span data-stu-id="09540-236">We would appreciate any feedback that you have while using these new kernels.</span></span> <span data-ttu-id="09540-237">Bu, bu tekrar son sürümünü hello şekillendirmeye yararlıdır.</span><span class="sxs-lookup"><span data-stu-id="09540-237">This is useful in shaping hello final release of these kernels.</span></span> <span data-ttu-id="09540-238">Yorumlar/geribildirim hello altında bırakabilirsiniz **açıklamaları** bu makalenin hello alt kısmına.</span><span class="sxs-lookup"><span data-stu-id="09540-238">You can leave your comments/feedback under hello **Comments** section at hello bottom of this article.</span></span>

## <span data-ttu-id="09540-239"><a name="seealso"></a>Ayrıca bkz.</span><span class="sxs-lookup"><span data-stu-id="09540-239"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="09540-240">Genel Bakış: Azure HDInsight’ta Apache Spark</span><span class="sxs-lookup"><span data-stu-id="09540-240">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="09540-241">Senaryolar</span><span class="sxs-lookup"><span data-stu-id="09540-241">Scenarios</span></span>
* [<span data-ttu-id="09540-242">BI ile Spark: BI araçlarıyla HDInsight’ta Spark kullanarak etkileşimli veri çözümlemesi gerçekleştirme</span><span class="sxs-lookup"><span data-stu-id="09540-242">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="09540-243">Machine Learning ile Spark: HVAC verilerini kullanarak bina sıcaklığını çözümlemek için HDInsight’ta Spark kullanma</span><span class="sxs-lookup"><span data-stu-id="09540-243">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="09540-244">Machine Learning ile Spark: Spark Hdınsight toopredict yemek İnceleme sonuçlarını içinde kullanma</span><span class="sxs-lookup"><span data-stu-id="09540-244">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="09540-245">Spark Akış: Gerçek zamanlı akış uygulamaları oluşturmak için HDInsight’ta Spark kullanma</span><span class="sxs-lookup"><span data-stu-id="09540-245">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="09540-246">HDInsight’ta Spark kullanarak Web sitesi günlüğü çözümlemesi</span><span class="sxs-lookup"><span data-stu-id="09540-246">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="09540-247">Uygulamaları oluşturma ve çalıştırma</span><span class="sxs-lookup"><span data-stu-id="09540-247">Create and run applications</span></span>
* [<span data-ttu-id="09540-248">Scala kullanarak tek başına uygulama oluşturma</span><span class="sxs-lookup"><span data-stu-id="09540-248">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="09540-249">Livy kullanarak Spark kümesinde işleri uzaktan çalıştırma</span><span class="sxs-lookup"><span data-stu-id="09540-249">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="09540-250">Araçlar ve uzantılar</span><span class="sxs-lookup"><span data-stu-id="09540-250">Tools and extensions</span></span>
* [<span data-ttu-id="09540-251">Intellij Idea toocreate için Hdınsight araçları eklentisi kullanma ve Spark Scala uygulamaları gönderin</span><span class="sxs-lookup"><span data-stu-id="09540-251">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="09540-252">Uzaktan Intellij Idea toodebug Spark uygulamaları için Hdınsight araçları eklentisi kullanma</span><span class="sxs-lookup"><span data-stu-id="09540-252">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="09540-253">HDInsight’ta Spark kümesi ile Zeppelin not defterlerini kullanma</span><span class="sxs-lookup"><span data-stu-id="09540-253">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="09540-254">Jupyter not defterleri ile dış paketleri kullanma</span><span class="sxs-lookup"><span data-stu-id="09540-254">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="09540-255">Jupyter bilgisayarınıza yüklemek ve tooan Hdınsight Spark kümesi bağlanın</span><span class="sxs-lookup"><span data-stu-id="09540-255">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="09540-256">Kaynakları yönetme</span><span class="sxs-lookup"><span data-stu-id="09540-256">Manage resources</span></span>
* [<span data-ttu-id="09540-257">Hello Azure hdınsight'ta Apache Spark küme kaynaklarını yönetme</span><span class="sxs-lookup"><span data-stu-id="09540-257">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="09540-258">HDInsight’ta bir Apache Spark kümesinde çalışan işleri izleme ve hata ayıklama</span><span class="sxs-lookup"><span data-stu-id="09540-258">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
