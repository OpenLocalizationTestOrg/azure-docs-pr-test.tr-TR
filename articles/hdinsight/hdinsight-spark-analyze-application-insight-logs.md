---
title: "-Azure Hdınsight Spark ile uygulama Insight günlüklerini çözümleme | Microsoft Docs"
description: "Blob depolama ve ardından günlüklerini hdınsight'ta Spark ile analiz etmek için uygulama Insight günlükleri dışarı aktarmak öğrenin."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: 883beae6-9839-45b5-94f7-7eb0f4534ad5
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 08/15/2017
ms.author: larryfr
ms.openlocfilehash: d98e403683618ef6115372f99e4949af87af4490
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: tr-TR
ms.lasthandoff: 08/18/2017
---
# <a name="analyze-application-insights-telemetry-logs-with-spark-on-hdinsight"></a><span data-ttu-id="43779-103">Application Insights telemetri günlüklerini hdınsight'ta Spark ile çözümleme</span><span class="sxs-lookup"><span data-stu-id="43779-103">Analyze Application Insights telemetry logs with Spark on HDInsight</span></span>

<span data-ttu-id="43779-104">Uygulama Insight telemetri verileri çözümlemek için Hdınsight'ta Spark kullanmayı öğrenin.</span><span class="sxs-lookup"><span data-stu-id="43779-104">Learn how to use Spark on HDInsight to analyze Application Insight telemetry data.</span></span>

<span data-ttu-id="43779-105">[Visual Studio Application Insights](../application-insights/app-insights-overview.md) web uygulamalarınızın izleyen bir analiz hizmetidir.</span><span class="sxs-lookup"><span data-stu-id="43779-105">[Visual Studio Application Insights](../application-insights/app-insights-overview.md) is an analytics service that monitors your web applications.</span></span> <span data-ttu-id="43779-106">Application Insights tarafından oluşturulan telemetri verileri Azure depolama alanına aktarılabilir.</span><span class="sxs-lookup"><span data-stu-id="43779-106">Telemetry data generated by Application Insights can be exported to Azure Storage.</span></span> <span data-ttu-id="43779-107">Verileri Azure depolama alanında olduğunda, Hdınsight incelemek üzere kullanılabilir.</span><span class="sxs-lookup"><span data-stu-id="43779-107">Once the data is in Azure Storage, HDInsight can be used to analyze it.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="43779-108">Ön koşullar</span><span class="sxs-lookup"><span data-stu-id="43779-108">Prerequisites</span></span>

* <span data-ttu-id="43779-109">Application Insights kullanmak üzere yapılandırılmış bir uygulama.</span><span class="sxs-lookup"><span data-stu-id="43779-109">An application that is configured to use Application Insights.</span></span>

* <span data-ttu-id="43779-110">Linux tabanlı Hdınsight kümesi oluşturma ile benzer.</span><span class="sxs-lookup"><span data-stu-id="43779-110">Familiarity with creating a Linux-based HDInsight cluster.</span></span> <span data-ttu-id="43779-111">Daha fazla bilgi için bkz: [hdınsight'ta Spark oluşturma](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="43779-111">For more information, see [Create Spark on HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

  > [!IMPORTANT]
  > <span data-ttu-id="43779-112">Bu belgede yer alan adımlar Linux kullanan bir Hdınsight kümesi gerektirir.</span><span class="sxs-lookup"><span data-stu-id="43779-112">The steps in this document require an HDInsight cluster that uses Linux.</span></span> <span data-ttu-id="43779-113">Linux, HDInsight sürüm 3.4 ve üzerinde kullanılan tek işletim sistemidir.</span><span class="sxs-lookup"><span data-stu-id="43779-113">Linux is the only operating system used on HDInsight version 3.4 or greater.</span></span> <span data-ttu-id="43779-114">Daha fazla bilgi için bkz. [Windows'da HDInsight'ın kullanımdan kaldırılması](hdinsight-component-versioning.md#hdinsight-windows-retirement).</span><span class="sxs-lookup"><span data-stu-id="43779-114">For more information, see [HDInsight retirement on Windows](hdinsight-component-versioning.md#hdinsight-windows-retirement).</span></span>

* <span data-ttu-id="43779-115">Bir web tarayıcısı.</span><span class="sxs-lookup"><span data-stu-id="43779-115">A web browser.</span></span>

<span data-ttu-id="43779-116">Aşağıdaki kaynaklar bu belgeyi test ve geliştirme de kullanılıyordu:</span><span class="sxs-lookup"><span data-stu-id="43779-116">The following resources were used in developing and testing this document:</span></span>

* <span data-ttu-id="43779-117">Uygulama Insights telemetri verilerini kullanarak üretilen bir [Application Insights kullanmak üzere yapılandırılmış Node.js web uygulamasına](../application-insights/app-insights-nodejs.md).</span><span class="sxs-lookup"><span data-stu-id="43779-117">Application Insights telemetry data was generated using a [Node.js web app configured to use Application Insights](../application-insights/app-insights-nodejs.md).</span></span>

* <span data-ttu-id="43779-118">Linux tabanlı bir Spark Hdınsight kümesi sürüm 3.5 üzerinde verileri çözümlemek için kullanıldı.</span><span class="sxs-lookup"><span data-stu-id="43779-118">A Linux-based Spark on HDInsight cluster version 3.5 was used to analyze the data.</span></span>

## <a name="architecture-and-planning"></a><span data-ttu-id="43779-119">Mimari ve planlama</span><span class="sxs-lookup"><span data-stu-id="43779-119">Architecture and planning</span></span>

<span data-ttu-id="43779-120">Aşağıdaki diyagramda bu örnek, hizmet mimarisi gösterilmektedir:</span><span class="sxs-lookup"><span data-stu-id="43779-120">The following diagram illustrates the service architecture of this example:</span></span>

![hdınsight'ta Spark tarafından işlenmekte olan sonra Application Insights blob depolama alanına akan veri gösteren diyagram](./media/hdinsight-spark-analyze-application-insight-logs/appinsightshdinsight.png)

### <a name="azure-storage"></a><span data-ttu-id="43779-122">Azure Storage</span><span class="sxs-lookup"><span data-stu-id="43779-122">Azure storage</span></span>

<span data-ttu-id="43779-123">Application Insights telemetri bilgilerini BLOB'lar için sürekli olarak dışarı aktarmak için yapılandırılabilir.</span><span class="sxs-lookup"><span data-stu-id="43779-123">Application Insights can be configured to continuously export telemetry information to blobs.</span></span> <span data-ttu-id="43779-124">Hdınsight sonra blob'larda depolanan verileri okuyabilir.</span><span class="sxs-lookup"><span data-stu-id="43779-124">HDInsight can then read data stored in the blobs.</span></span> <span data-ttu-id="43779-125">Ancak, uymanız gereken bazı gereksinimler vardır:</span><span class="sxs-lookup"><span data-stu-id="43779-125">However, there are some requirements that you must follow:</span></span>

* <span data-ttu-id="43779-126">**Konum**: depolama hesabı ve Hdınsight farklı konumlarda varsa, gecikme süresini artırabilir.</span><span class="sxs-lookup"><span data-stu-id="43779-126">**Location**: If the Storage Account and HDInsight are in different locations, it may increase latency.</span></span> <span data-ttu-id="43779-127">Aynı zamanda bölgeler arasında taşıma verilere ücretleri uygulanır çıkış olarak maliyeti artırır.</span><span class="sxs-lookup"><span data-stu-id="43779-127">It also increases cost, as egress charges are applied to data moving between regions.</span></span>

    > [!WARNING]
    > <span data-ttu-id="43779-128">Hdınsight farklı bir konumda bir depolama hesabıyla desteklenmiyor.</span><span class="sxs-lookup"><span data-stu-id="43779-128">Using a Storage Account in a different location than HDInsight is not supported.</span></span>

* <span data-ttu-id="43779-129">**BLOB türü**: Hdınsight yalnızca blok bloblarını destekler.</span><span class="sxs-lookup"><span data-stu-id="43779-129">**Blob type**: HDInsight only supports block blobs.</span></span> <span data-ttu-id="43779-130">Blok blobları kullanarak uygulama Öngörüler varsayılanlarını şekilde çalışmalıdır varsayılan Hdınsight ile.</span><span class="sxs-lookup"><span data-stu-id="43779-130">Application Insights defaults to using block blobs, so should work by default with HDInsight.</span></span>

<span data-ttu-id="43779-131">Ek depolama alanı olan bir Hdınsight kümesine ekleme hakkında daha fazla bilgi için bkz: [ek depolama hesapları ekleme](hdinsight-hadoop-add-storage.md) belge.</span><span class="sxs-lookup"><span data-stu-id="43779-131">For information on adding additional storage to an existing HDInsight cluster, see the [Add additional storage accounts](hdinsight-hadoop-add-storage.md) document.</span></span>

### <a name="data-schema"></a><span data-ttu-id="43779-132">Veri şeması</span><span class="sxs-lookup"><span data-stu-id="43779-132">Data schema</span></span>

<span data-ttu-id="43779-133">Application Insights sağlar [veri modeli verme](../application-insights/app-insights-export-data-model.md) bilgi telemetri veri biçimi için dışa aktarılan BLOB'lar için.</span><span class="sxs-lookup"><span data-stu-id="43779-133">Application Insights provides [export data model](../application-insights/app-insights-export-data-model.md) information for the telemetry data format exported to blobs.</span></span> <span data-ttu-id="43779-134">Bu belgede yer alan adımlar, verilerle çalışmak için Spark SQL kullanın.</span><span class="sxs-lookup"><span data-stu-id="43779-134">The steps in this document use Spark SQL to work with the data.</span></span> <span data-ttu-id="43779-135">Spark SQL, Application Insights tarafından günlüğe kaydedilen JSON veri yapısı için bir şema otomatik olarak oluşturabilir.</span><span class="sxs-lookup"><span data-stu-id="43779-135">Spark SQL can automatically generate a schema for the JSON data structure logged by Application Insights.</span></span>

## <a name="export-telemetry-data"></a><span data-ttu-id="43779-136">Telemetri verileri dışarı aktarma</span><span class="sxs-lookup"><span data-stu-id="43779-136">Export telemetry data</span></span>

<span data-ttu-id="43779-137">Adımları [yapılandırma sürekli verme](../application-insights/app-insights-export-telemetry.md) bir Azure storage blobuna telemetri bilgilerini dışarı aktarmak için Application Insights yapılandırmak için.</span><span class="sxs-lookup"><span data-stu-id="43779-137">Follow the steps in [Configure Continuous Export](../application-insights/app-insights-export-telemetry.md) to configure your Application Insights to export telemetry information to an Azure storage blob.</span></span>

## <a name="configure-hdinsight-to-access-the-data"></a><span data-ttu-id="43779-138">Hdınsight verilere erişmek için yapılandırma</span><span class="sxs-lookup"><span data-stu-id="43779-138">Configure HDInsight to access the data</span></span>

<span data-ttu-id="43779-139">Hdınsight kümesi oluşturuyorsanız, küme oluşturma sırasında depolama hesabı ekleyin.</span><span class="sxs-lookup"><span data-stu-id="43779-139">If you are creating an HDInsight cluster, add the storage account during cluster creation.</span></span>

<span data-ttu-id="43779-140">Varolan bir kümeye Azure depolama hesabı eklemek için bilgileri kullanın. [ek depolama hesapları ekleme](hdinsight-hadoop-add-storage.md) belge.</span><span class="sxs-lookup"><span data-stu-id="43779-140">To add the Azure Storage Account to an existing cluster, use the information in the [Add additional Storage Accounts](hdinsight-hadoop-add-storage.md) document.</span></span>

## <a name="analyze-the-data-pyspark"></a><span data-ttu-id="43779-141">Verileri çözümlemek: PySpark</span><span class="sxs-lookup"><span data-stu-id="43779-141">Analyze the data: PySpark</span></span>

1. <span data-ttu-id="43779-142">Gelen [Azure portal](https://portal.azure.com), Hdınsight kümesinde, Spark seçin.</span><span class="sxs-lookup"><span data-stu-id="43779-142">From the [Azure portal](https://portal.azure.com), select your Spark on HDInsight cluster.</span></span> <span data-ttu-id="43779-143">Gelen **hızlı bağlantılar** bölümünde, select **küme panolarında**ve ardından **Jupyter not defteri** küme Dashboard__ dikey penceresinden.</span><span class="sxs-lookup"><span data-stu-id="43779-143">From the **Quick Links** section, select **Cluster Dashboards**, and then select **Jupyter Notebook** from the Cluster Dashboard__ blade.</span></span>

    ![Küme panolarında](./media/hdinsight-spark-analyze-application-insight-logs/clusterdashboards.png)

2. <span data-ttu-id="43779-145">Jupyter sayfanın sağ üst köşesinde seçin **yeni**ve ardından **PySpark**.</span><span class="sxs-lookup"><span data-stu-id="43779-145">In the upper right corner of the Jupyter page, select **New**, and then **PySpark**.</span></span> <span data-ttu-id="43779-146">Python tabanlı Jupyter not defteri içeren yeni bir tarayıcı sekmesi açar.</span><span class="sxs-lookup"><span data-stu-id="43779-146">A new browser tab containing a Python-based Jupyter Notebook opens.</span></span>

3. <span data-ttu-id="43779-147">İlk alanında (adlı bir **hücre**) sayfasında, aşağıdaki metni girin:</span><span class="sxs-lookup"><span data-stu-id="43779-147">In the first field (called a **cell**) on the page, enter the following text:</span></span>

   ```python
   sc._jsc.hadoopConfiguration().set('mapreduce.input.fileinputformat.input.dir.recursive', 'true')
   ```

    <span data-ttu-id="43779-148">Bu kod yinelemeli olarak erişim dizin yapısına giriş verileri için Spark yapılandırır.</span><span class="sxs-lookup"><span data-stu-id="43779-148">This code configures Spark to recursively access the directory structure for the input data.</span></span> <span data-ttu-id="43779-149">Application Insights telemetrisi benzer bir dizin yapısına kaydedilir `/{telemetry type}/YYYY-MM-DD/{##}/`.</span><span class="sxs-lookup"><span data-stu-id="43779-149">Application Insights telemetry is logged to a directory structure similar to the `/{telemetry type}/YYYY-MM-DD/{##}/`.</span></span>

4. <span data-ttu-id="43779-150">Kullanım **SHIFT + ENTER** kodu çalıştırmak için.</span><span class="sxs-lookup"><span data-stu-id="43779-150">Use **SHIFT+ENTER** to run the code.</span></span> <span data-ttu-id="43779-151">Hücre sol tarafındaki bir '\*' Bu hücreyi kodda yürütülmekte olan göstermek için köşeli ayraçlar arasında görünür.</span><span class="sxs-lookup"><span data-stu-id="43779-151">On the left side of the cell, an '\*' appears between the brackets to indicate that the code in this cell is being executed.</span></span> <span data-ttu-id="43779-152">Tamamlandığında, '\*' numarası ve aşağıdakine benzer bir çıktı değişiklikler hücrede görüntülenir:</span><span class="sxs-lookup"><span data-stu-id="43779-152">Once it completes, the '\*' changes to a number, and output similar to the following text is displayed below the cell:</span></span>

        Creating SparkContext as 'sc'

        ID    YARN Application ID    Kind    State    Spark UI    Driver log    Current session?
        3    application_1468969497124_0001    pyspark    idle    Link    Link    ✔

        Creating HiveContext as 'sqlContext'
        SparkContext and HiveContext created. Executing user code ...
5. <span data-ttu-id="43779-153">Yeni bir hücreye birinci altında oluşturulur.</span><span class="sxs-lookup"><span data-stu-id="43779-153">A new cell is created below the first one.</span></span> <span data-ttu-id="43779-154">Yeni hücreye aşağıdaki metni girin.</span><span class="sxs-lookup"><span data-stu-id="43779-154">Enter the following text in the new cell.</span></span> <span data-ttu-id="43779-155">Değiştir `CONTAINER` ve `STORAGEACCOUNT` Azure depolama hesabı adı ve Application Insights verileri içeren blob kapsayıcı adı.</span><span class="sxs-lookup"><span data-stu-id="43779-155">Replace `CONTAINER` and `STORAGEACCOUNT` with the Azure storage account name and blob container name that contains Application Insights data.</span></span>

   ```python
   %%bash
   hdfs dfs -ls wasb://CONTAINER@STORAGEACCOUNT.blob.core.windows.net/
   ```

    <span data-ttu-id="43779-156">Kullanım **SHIFT + ENTER** Bu hücreyi yürütülecek.</span><span class="sxs-lookup"><span data-stu-id="43779-156">Use **SHIFT+ENTER** to execute this cell.</span></span> <span data-ttu-id="43779-157">Aşağıdakine benzer bir sonuç bakın:</span><span class="sxs-lookup"><span data-stu-id="43779-157">You see a result similar to the following text:</span></span>

        Found 1 items
        drwxrwxrwx   -          0 1970-01-01 00:00 wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_2bededa61bc741fbdee6b556571a4831

    <span data-ttu-id="43779-158">Döndürülen wasb yol Application Insights telemetri verilerini konumudur.</span><span class="sxs-lookup"><span data-stu-id="43779-158">The wasb path returned is the location of the Application Insights telemetry data.</span></span> <span data-ttu-id="43779-159">Değişiklik `hdfs dfs -ls` satır hücresine döndürülen wasb yolu kullanın ve sonra **SHIFT + ENTER** hücre yeniden çalıştırmak için.</span><span class="sxs-lookup"><span data-stu-id="43779-159">Change the `hdfs dfs -ls` line in the cell to use the wasb path returned, and then use **SHIFT+ENTER** to run the cell again.</span></span> <span data-ttu-id="43779-160">Bu süre, telemetri verilerini içeren dizinleri sonuçları görüntülemesi gerekir.</span><span class="sxs-lookup"><span data-stu-id="43779-160">This time, the results should display the directories that contain telemetry data.</span></span>

   > [!NOTE]
   > <span data-ttu-id="43779-161">Bu bölümdeki adımları kalanı için `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` dizin kullanıldı.</span><span class="sxs-lookup"><span data-stu-id="43779-161">For the remainder of the steps in this section, the `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` directory was used.</span></span> <span data-ttu-id="43779-162">Dizin yapısını farklı olabilir.</span><span class="sxs-lookup"><span data-stu-id="43779-162">Your directory structure may be different.</span></span>

6. <span data-ttu-id="43779-163">Sonraki hücreye aşağıdaki kodu girin: Değiştir `WASB_PATH` önceki adımdan yoluna sahip.</span><span class="sxs-lookup"><span data-stu-id="43779-163">In the next cell, enter the following code: Replace `WASB_PATH` with the path from the previous step.</span></span>

   ```python
   jsonFiles = sc.textFile('WASB_PATH')
   jsonData = sqlContext.read.json(jsonFiles)
   ```

    <span data-ttu-id="43779-164">Bu kod bir dataframe sürekli dışa aktarma işlemi tarafından dışarı aktarılan JSON dosyaları oluşturur.</span><span class="sxs-lookup"><span data-stu-id="43779-164">This code creates a dataframe from the JSON files exported by the continuous export process.</span></span> <span data-ttu-id="43779-165">Kullanım **SHIFT + ENTER** Bu hücreyi çalıştırmak için.</span><span class="sxs-lookup"><span data-stu-id="43779-165">Use **SHIFT+ENTER** to run this cell.</span></span>
7. <span data-ttu-id="43779-166">Sonraki hücrenin girin ve JSON dosyaları için Spark oluşturulan şemasını görüntülemek için aşağıdakini çalıştırın:</span><span class="sxs-lookup"><span data-stu-id="43779-166">In the next cell, enter and run the following to view the schema that Spark created for the JSON files:</span></span>

   ```python
   jsonData.printSchema()
   ```

    <span data-ttu-id="43779-167">Şemanın telemetri her tür için farklıdır.</span><span class="sxs-lookup"><span data-stu-id="43779-167">The schema for each type of telemetry is different.</span></span> <span data-ttu-id="43779-168">Aşağıdaki örnek web istekleri için oluşturulan şema aynıdır (depolanan verileri `Requests` alt dizin):</span><span class="sxs-lookup"><span data-stu-id="43779-168">The following example is the schema that is generated for web requests (data stored in the `Requests` subdirectory):</span></span>

        root
        |-- context: struct (nullable = true)
        |    |-- application: struct (nullable = true)
        |    |    |-- version: string (nullable = true)
        |    |-- custom: struct (nullable = true)
        |    |    |-- dimensions: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |    |-- metrics: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- eventTime: string (nullable = true)
        |    |    |-- isSynthetic: boolean (nullable = true)
        |    |    |-- samplingRate: double (nullable = true)
        |    |    |-- syntheticSource: string (nullable = true)
        |    |-- device: struct (nullable = true)
        |    |    |-- browser: string (nullable = true)
        |    |    |-- browserVersion: string (nullable = true)
        |    |    |-- deviceModel: string (nullable = true)
        |    |    |-- deviceName: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- osVersion: string (nullable = true)
        |    |    |-- type: string (nullable = true)
        |    |-- location: struct (nullable = true)
        |    |    |-- city: string (nullable = true)
        |    |    |-- clientip: string (nullable = true)
        |    |    |-- continent: string (nullable = true)
        |    |    |-- country: string (nullable = true)
        |    |    |-- province: string (nullable = true)
        |    |-- operation: struct (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |-- session: struct (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- isFirst: boolean (nullable = true)
        |    |-- user: struct (nullable = true)
        |    |    |-- anonId: string (nullable = true)
        |    |    |-- isAuthenticated: boolean (nullable = true)
        |-- internal: struct (nullable = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- documentVersion: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |-- request: array (nullable = true)
        |    |-- element: struct (containsNull = true)
        |    |    |-- count: long (nullable = true)
        |    |    |-- durationMetric: struct (nullable = true)
        |    |    |    |-- count: double (nullable = true)
        |    |    |    |-- max: double (nullable = true)
        |    |    |    |-- min: double (nullable = true)
        |    |    |    |-- sampledValue: double (nullable = true)
        |    |    |    |-- stdDev: double (nullable = true)
        |    |    |    |-- value: double (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |    |-- responseCode: long (nullable = true)
        |    |    |-- success: boolean (nullable = true)
        |    |    |-- url: string (nullable = true)
        |    |    |-- urlData: struct (nullable = true)
        |    |    |    |-- base: string (nullable = true)
        |    |    |    |-- hashTag: string (nullable = true)
        |    |    |    |-- host: string (nullable = true)
        |    |    |    |-- protocol: string (nullable = true)
8. <span data-ttu-id="43779-169">Geçici bir tablo olarak dataframe kaydetmek ve veri karşı sorgu çalıştırmak için aşağıdakileri kullanın:</span><span class="sxs-lookup"><span data-stu-id="43779-169">Use the following to register the dataframe as a temporary table and run a query against the data:</span></span>

   ```python
   jsonData.registerTempTable("requests")
   df = sqlContext.sql("select context.location.city from requests where context.location.city is not null")
   df.show()
   ```

    <span data-ttu-id="43779-170">Bu sorgu, burada context.location.city null olmayan ilk 20 kayıt Şehir bilgilerini döndürür.</span><span class="sxs-lookup"><span data-stu-id="43779-170">This query returns the city information for the top 20 records where context.location.city is not null.</span></span>

   > [!NOTE]
   > <span data-ttu-id="43779-171">Bağlam yapısı Application Insights tarafından günlüğe kaydedilen tüm telemetri bulunur.</span><span class="sxs-lookup"><span data-stu-id="43779-171">The context structure is present in all telemetry logged by Application Insights.</span></span> <span data-ttu-id="43779-172">Şehir öğesi, günlüklerinize doldurulmuş değil.</span><span class="sxs-lookup"><span data-stu-id="43779-172">The city element may not be populated in your logs.</span></span> <span data-ttu-id="43779-173">Günlükleriniz için verileri içerebilir Sorgulayabileceğiniz diğer öğeleri tanımlamak için şema kullanın.</span><span class="sxs-lookup"><span data-stu-id="43779-173">Use the schema to identify other elements that you can query that may contain data for your logs.</span></span>

    <span data-ttu-id="43779-174">Bu sorgu bilgileri aşağıdaki metni benzer döndürür:</span><span class="sxs-lookup"><span data-stu-id="43779-174">This query returns information similar to the following text:</span></span>

        +---------+
        |     city|
        +---------+
        | Bellevue|
        |  Redmond|
        |  Seattle|
        |Charlotte|
        ...
        +---------+

## <a name="analyze-the-data-scala"></a><span data-ttu-id="43779-175">Verileri çözümlemek: Scala</span><span class="sxs-lookup"><span data-stu-id="43779-175">Analyze the data: Scala</span></span>

1. <span data-ttu-id="43779-176">Gelen [Azure portal](https://portal.azure.com), Hdınsight kümesinde, Spark seçin.</span><span class="sxs-lookup"><span data-stu-id="43779-176">From the [Azure portal](https://portal.azure.com), select your Spark on HDInsight cluster.</span></span> <span data-ttu-id="43779-177">Gelen **hızlı bağlantılar** bölümünde, select **küme panolarında**ve ardından **Jupyter not defteri** küme Dashboard__ dikey penceresinden.</span><span class="sxs-lookup"><span data-stu-id="43779-177">From the **Quick Links** section, select **Cluster Dashboards**, and then select **Jupyter Notebook** from the Cluster Dashboard__ blade.</span></span>

    ![Küme panolarında](./media/hdinsight-spark-analyze-application-insight-logs/clusterdashboards.png)
2. <span data-ttu-id="43779-179">Jupyter sayfanın sağ üst köşesinde seçin **yeni**ve ardından **Scala**.</span><span class="sxs-lookup"><span data-stu-id="43779-179">In the upper right corner of the Jupyter page, select **New**, and then **Scala**.</span></span> <span data-ttu-id="43779-180">Scala tabanlı Jupyter not defteri içeren yeni bir tarayıcı sekmesi görüntülenir.</span><span class="sxs-lookup"><span data-stu-id="43779-180">A new browser tab containing a Scala-based Jupyter Notebook appears.</span></span>
3. <span data-ttu-id="43779-181">İlk alanında (adlı bir **hücre**) sayfasında, aşağıdaki metni girin:</span><span class="sxs-lookup"><span data-stu-id="43779-181">In the first field (called a **cell**) on the page, enter the following text:</span></span>

   ```scala
   sc.hadoopConfiguration.set("mapreduce.input.fileinputformat.input.dir.recursive", "true")
   ```

    <span data-ttu-id="43779-182">Bu kod yinelemeli olarak erişim dizin yapısına giriş verileri için Spark yapılandırır.</span><span class="sxs-lookup"><span data-stu-id="43779-182">This code configures Spark to recursively access the directory structure for the input data.</span></span> <span data-ttu-id="43779-183">Application Insights telemetrisi benzer bir dizin yapısına kaydedilir `/{telemetry type}/YYYY-MM-DD/{##}/`.</span><span class="sxs-lookup"><span data-stu-id="43779-183">Application Insights telemetry is logged to a directory structure similar to `/{telemetry type}/YYYY-MM-DD/{##}/`.</span></span>

4. <span data-ttu-id="43779-184">Kullanım **SHIFT + ENTER** kodu çalıştırmak için.</span><span class="sxs-lookup"><span data-stu-id="43779-184">Use **SHIFT+ENTER** to run the code.</span></span> <span data-ttu-id="43779-185">Hücre sol tarafındaki bir '\*' Bu hücreyi kodda yürütülmekte olan göstermek için köşeli ayraçlar arasında görünür.</span><span class="sxs-lookup"><span data-stu-id="43779-185">On the left side of the cell, an '\*' appears between the brackets to indicate that the code in this cell is being executed.</span></span> <span data-ttu-id="43779-186">Tamamlandığında, '\*' numarası ve aşağıdakine benzer bir çıktı değişiklikler hücrede görüntülenir:</span><span class="sxs-lookup"><span data-stu-id="43779-186">Once it completes, the '\*' changes to a number, and output similar to the following text is displayed below the cell:</span></span>

        Creating SparkContext as 'sc'

        ID    YARN Application ID    Kind    State    Spark UI    Driver log    Current session?
        3    application_1468969497124_0001    spark    idle    Link    Link    ✔

        Creating HiveContext as 'sqlContext'
        SparkContext and HiveContext created. Executing user code ...
5. <span data-ttu-id="43779-187">Yeni bir hücreye birinci altında oluşturulur.</span><span class="sxs-lookup"><span data-stu-id="43779-187">A new cell is created below the first one.</span></span> <span data-ttu-id="43779-188">Yeni hücreye aşağıdaki metni girin.</span><span class="sxs-lookup"><span data-stu-id="43779-188">Enter the following text in the new cell.</span></span> <span data-ttu-id="43779-189">Değiştir `CONTAINER` ve `STORAGEACCOUNT` Azure depolama hesabı adı ve Application Insights içeren blob kapsayıcı adı ile günlüğe kaydeder.</span><span class="sxs-lookup"><span data-stu-id="43779-189">Replace `CONTAINER` and `STORAGEACCOUNT` with the Azure storage account name and blob container name that contains Application Insights logs.</span></span>

   ```scala
   %%bash
   hdfs dfs -ls wasb://CONTAINER@STORAGEACCOUNT.blob.core.windows.net/
   ```

    <span data-ttu-id="43779-190">Kullanım **SHIFT + ENTER** Bu hücreyi yürütülecek.</span><span class="sxs-lookup"><span data-stu-id="43779-190">Use **SHIFT+ENTER** to execute this cell.</span></span> <span data-ttu-id="43779-191">Aşağıdakine benzer bir sonuç bakın:</span><span class="sxs-lookup"><span data-stu-id="43779-191">You see a result similar to the following text:</span></span>

        Found 1 items
        drwxrwxrwx   -          0 1970-01-01 00:00 wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_2bededa61bc741fbdee6b556571a4831

    <span data-ttu-id="43779-192">Döndürülen wasb yol Application Insights telemetri verilerini konumudur.</span><span class="sxs-lookup"><span data-stu-id="43779-192">The wasb path returned is the location of the Application Insights telemetry data.</span></span> <span data-ttu-id="43779-193">Değişiklik `hdfs dfs -ls` satır hücresine döndürülen wasb yolu kullanın ve sonra **SHIFT + ENTER** hücre yeniden çalıştırmak için.</span><span class="sxs-lookup"><span data-stu-id="43779-193">Change the `hdfs dfs -ls` line in the cell to use the wasb path returned, and then use **SHIFT+ENTER** to run the cell again.</span></span> <span data-ttu-id="43779-194">Bu süre, telemetri verilerini içeren dizinleri sonuçları görüntülemesi gerekir.</span><span class="sxs-lookup"><span data-stu-id="43779-194">This time, the results should display the directories that contain telemetry data.</span></span>

   > [!NOTE]
   > <span data-ttu-id="43779-195">Bu bölümdeki adımları kalanı için `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` dizin kullanıldı.</span><span class="sxs-lookup"><span data-stu-id="43779-195">For the remainder of the steps in this section, the `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` directory was used.</span></span> <span data-ttu-id="43779-196">Bir web uygulaması için telemetri verilerinizi olmadığı sürece bu dizinin var olmayabilir.</span><span class="sxs-lookup"><span data-stu-id="43779-196">This directory may not exist unless your telemetry data is for a web app.</span></span>

6. <span data-ttu-id="43779-197">Sonraki hücreye aşağıdaki kodu girin: Değiştir `WASB\_PATH` önceki adımdan yoluna sahip.</span><span class="sxs-lookup"><span data-stu-id="43779-197">In the next cell, enter the following code: Replace `WASB\_PATH` with the path from the previous step.</span></span>

   ```scala
   var jsonFiles = sc.textFile('WASB_PATH')
   val sqlContext = new org.apache.spark.sql.SQLContext(sc)
   var jsonData = sqlContext.read.json(jsonFiles)
   ```

    <span data-ttu-id="43779-198">Bu kod bir dataframe sürekli dışa aktarma işlemi tarafından dışarı aktarılan JSON dosyaları oluşturur.</span><span class="sxs-lookup"><span data-stu-id="43779-198">This code creates a dataframe from the JSON files exported by the continuous export process.</span></span> <span data-ttu-id="43779-199">Kullanım **SHIFT + ENTER** Bu hücreyi çalıştırmak için.</span><span class="sxs-lookup"><span data-stu-id="43779-199">Use **SHIFT+ENTER** to run this cell.</span></span>

7. <span data-ttu-id="43779-200">Sonraki hücrenin girin ve JSON dosyaları için Spark oluşturulan şemasını görüntülemek için aşağıdakini çalıştırın:</span><span class="sxs-lookup"><span data-stu-id="43779-200">In the next cell, enter and run the following to view the schema that Spark created for the JSON files:</span></span>

   ```scala
   jsonData.printSchema
   ```

    <span data-ttu-id="43779-201">Şemanın telemetri her tür için farklıdır.</span><span class="sxs-lookup"><span data-stu-id="43779-201">The schema for each type of telemetry is different.</span></span> <span data-ttu-id="43779-202">Aşağıdaki örnek web istekleri için oluşturulan şema aynıdır (depolanan verileri `Requests` alt dizin):</span><span class="sxs-lookup"><span data-stu-id="43779-202">The following example is the schema that is generated for web requests (data stored in the `Requests` subdirectory):</span></span>

        root
        |-- context: struct (nullable = true)
        |    |-- application: struct (nullable = true)
        |    |    |-- version: string (nullable = true)
        |    |-- custom: struct (nullable = true)
        |    |    |-- dimensions: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |    |-- metrics: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- eventTime: string (nullable = true)
        |    |    |-- isSynthetic: boolean (nullable = true)
        |    |    |-- samplingRate: double (nullable = true)
        |    |    |-- syntheticSource: string (nullable = true)
        |    |-- device: struct (nullable = true)
        |    |    |-- browser: string (nullable = true)
        |    |    |-- browserVersion: string (nullable = true)
        |    |    |-- deviceModel: string (nullable = true)
        |    |    |-- deviceName: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- osVersion: string (nullable = true)
        |    |    |-- type: string (nullable = true)
        |    |-- location: struct (nullable = true)
        |    |    |-- city: string (nullable = true)
        |    |    |-- clientip: string (nullable = true)
        |    |    |-- continent: string (nullable = true)
        |    |    |-- country: string (nullable = true)
        |    |    |-- province: string (nullable = true)
        |    |-- operation: struct (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |-- session: struct (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- isFirst: boolean (nullable = true)
        |    |-- user: struct (nullable = true)
        |    |    |-- anonId: string (nullable = true)
        |    |    |-- isAuthenticated: boolean (nullable = true)
        |-- internal: struct (nullable = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- documentVersion: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |-- request: array (nullable = true)
        |    |-- element: struct (containsNull = true)
        |    |    |-- count: long (nullable = true)
        |    |    |-- durationMetric: struct (nullable = true)
        |    |    |    |-- count: double (nullable = true)
        |    |    |    |-- max: double (nullable = true)
        |    |    |    |-- min: double (nullable = true)
        |    |    |    |-- sampledValue: double (nullable = true)
        |    |    |    |-- stdDev: double (nullable = true)
        |    |    |    |-- value: double (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |    |-- responseCode: long (nullable = true)
        |    |    |-- success: boolean (nullable = true)
        |    |    |-- url: string (nullable = true)
        |    |    |-- urlData: struct (nullable = true)
        |    |    |    |-- base: string (nullable = true)
        |    |    |    |-- hashTag: string (nullable = true)
        |    |    |    |-- host: string (nullable = true)
        |    |    |    |-- protocol: string (nullable = true)

8. <span data-ttu-id="43779-203">Geçici bir tablo olarak dataframe kaydetmek ve veri karşı sorgu çalıştırmak için aşağıdakileri kullanın:</span><span class="sxs-lookup"><span data-stu-id="43779-203">Use the following to register the dataframe as a temporary table and run a query against the data:</span></span>

   ```scala
   jsonData.registerTempTable("requests")
   var city = sqlContext.sql("select context.location.city from requests where context.location.city is not null limit 10").show()
   ```

    <span data-ttu-id="43779-204">Bu sorgu, burada context.location.city null olmayan ilk 20 kayıt Şehir bilgilerini döndürür.</span><span class="sxs-lookup"><span data-stu-id="43779-204">This query returns the city information for the top 20 records where context.location.city is not null.</span></span>

   > [!NOTE]
   > <span data-ttu-id="43779-205">Bağlam yapısı Application Insights tarafından günlüğe kaydedilen tüm telemetri bulunur.</span><span class="sxs-lookup"><span data-stu-id="43779-205">The context structure is present in all telemetry logged by Application Insights.</span></span> <span data-ttu-id="43779-206">Şehir öğesi, günlüklerinize doldurulmuş değil.</span><span class="sxs-lookup"><span data-stu-id="43779-206">The city element may not be populated in your logs.</span></span> <span data-ttu-id="43779-207">Günlükleriniz için verileri içerebilir Sorgulayabileceğiniz diğer öğeleri tanımlamak için şema kullanın.</span><span class="sxs-lookup"><span data-stu-id="43779-207">Use the schema to identify other elements that you can query that may contain data for your logs.</span></span>
   >
   >

    <span data-ttu-id="43779-208">Bu sorgu bilgileri aşağıdaki metni benzer döndürür:</span><span class="sxs-lookup"><span data-stu-id="43779-208">This query returns information similar to the following text:</span></span>

        +---------+
        |     city|
        +---------+
        | Bellevue|
        |  Redmond|
        |  Seattle|
        |Charlotte|
        ...
        +---------+

## <a name="next-steps"></a><span data-ttu-id="43779-209">Sonraki adımlar</span><span class="sxs-lookup"><span data-stu-id="43779-209">Next steps</span></span>

<span data-ttu-id="43779-210">Veriler ve Azure Hizmetleri ile çalışmak için Spark kullanmanın daha fazla örnek için aşağıdaki belgelere bakın:</span><span class="sxs-lookup"><span data-stu-id="43779-210">For more examples of using Spark to work with data and services in Azure, see the following documents:</span></span>

* [<span data-ttu-id="43779-211">BI ile Spark: BI araçlarıyla HDInsight’ta Spark kullanarak etkileşimli veri çözümlemesi gerçekleştirme</span><span class="sxs-lookup"><span data-stu-id="43779-211">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="43779-212">Machine Learning ile Spark: HVAC verilerini kullanarak bina sıcaklığını çözümlemek için HDInsight’ta Spark kullanma</span><span class="sxs-lookup"><span data-stu-id="43779-212">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="43779-213">Machine Learning ile Spark: Yemek inceleme sonuçlarını tahmin etmek için HDInsight’ta Spark kullanma</span><span class="sxs-lookup"><span data-stu-id="43779-213">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="43779-214">Spark akış: Akış uygulamaları oluşturmak için hdınsight'ta Spark kullanma</span><span class="sxs-lookup"><span data-stu-id="43779-214">Spark Streaming: Use Spark in HDInsight for building streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="43779-215">HDInsight’ta Spark kullanarak Web sitesi günlüğü çözümlemesi</span><span class="sxs-lookup"><span data-stu-id="43779-215">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

<span data-ttu-id="43779-216">Oluşturma ve Spark çalışan uygulamalar hakkında daha fazla bilgi için aşağıdaki belgelere bakın:</span><span class="sxs-lookup"><span data-stu-id="43779-216">For information on creating and running Spark applications, see the following documents:</span></span>

* [<span data-ttu-id="43779-217">Scala kullanarak tek başına uygulama oluşturma</span><span class="sxs-lookup"><span data-stu-id="43779-217">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="43779-218">Livy kullanarak Spark kümesinde işleri uzaktan çalıştırma</span><span class="sxs-lookup"><span data-stu-id="43779-218">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
