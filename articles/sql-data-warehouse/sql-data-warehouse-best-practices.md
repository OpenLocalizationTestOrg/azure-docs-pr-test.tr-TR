---
title: "Azure SQL Veri Ambarı için en iyi uygulamalar | Microsoft Belgeleri"
description: "Azure SQL Veri Ambarı için çözüm geliştirirken bilmeniz gerekenlerle ilgili öneriler ve en iyi yöntemler. Bu veriler, başarılı olmanıza yardımcı olacaktır."
services: sql-data-warehouse
documentationcenter: NA
author: shivaniguptamsft
manager: jhubbard
editor: 
ms.assetid: 7b698cad-b152-4d33-97f5-5155dfa60f79
ms.service: sql-data-warehouse
ms.devlang: NA
ms.topic: get-started-article
ms.tgt_pltfrm: NA
ms.workload: data-services
ms.custom: performance
ms.date: 10/31/2016
ms.author: shigu;barbkess
ms.openlocfilehash: c1fb0d8790d8c97ac45db02ac76403e7a80fae5d
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: tr-TR
ms.lasthandoff: 07/11/2017
---
# <a name="best-practices-for-azure-sql-data-warehouse"></a><span data-ttu-id="3a04c-104">Azure SQL Veri Ambarı için en iyi yöntemler</span><span class="sxs-lookup"><span data-stu-id="3a04c-104">Best practices for Azure SQL Data Warehouse</span></span>
<span data-ttu-id="3a04c-105">Bu makalede, Azure SQL Veri Ambarı çözümünüzden yüksek performans almanıza yardımcı olacak en iyi yöntemler bir arada sunulmaktadır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-105">This article is a collection of many best practices that will help you to achieve optimal performance from your Azure SQL Data Warehouse.</span></span>  <span data-ttu-id="3a04c-106">Bu makalede, temel ve kolay anlaşılır kavramların yanı sıra ileri düzey kavramlarla ilgili özet bilgilere yer verilmektedir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-106">Some of the concepts in this article are basic and easy to explain, other concepts are more advanced and we just scratch the surface in this article.</span></span>  <span data-ttu-id="3a04c-107">Bu makalenin amacı, veri ambarınızı oluşturmanız sırasında size temel noktalarda rehberlik yapmak ve odaklanmanız gereken önemli noktalara dikkat çekmektir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-107">The purpose of this article is to give you some basic guidance and to raise awareness of important areas to focus as you build your data warehouse.</span></span>  <span data-ttu-id="3a04c-108">Her bölümde bir kavram tanıtılmakta ve ardından ilgili kavramı ayrıntılı bir şekilde açıklayan ileri düzey makalelere bağlantı verilmektedir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-108">Each section introduces you to a concept and then point you to more detailed articles which cover the concept in more depth.</span></span>

<span data-ttu-id="3a04c-109">Azure SQL Veri Ambarı ile çalışmaya yeni başladıysanız, bu makale gözünüzü korkutmasın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-109">If you are just getting started with Azure SQL Data Warehouse, do not let this article overwhelm you.</span></span>  <span data-ttu-id="3a04c-110">Konular genelde önem sırasına göre verilmiştir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-110">The sequence of the topics is mostly in the order of importance.</span></span>  <span data-ttu-id="3a04c-111">Başlangıç olarak ilk birkaç kavrama odaklanırsanız, daha kolay ilerleyebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-111">If you start by focusing on the first few concepts, you'll be in good shape.</span></span>  <span data-ttu-id="3a04c-112">SQL Veri Ambarı hakkında daha fazla bilgi edinip daha çok kullanmaya başladıktan sonra bu makaleye dönerek birkaç kavrama daha göz atabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-112">As you get more familiar and comfortable with using SQL Date Warehouse, come back and look at a few more concepts.</span></span>  <span data-ttu-id="3a04c-113">Tüm kavramların oturması çok uzun sürmeyecektir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-113">It won't take long for everything to make sense.</span></span>

## <a name="reduce-cost-with-pause-and-scale"></a><span data-ttu-id="3a04c-114">Duraklatma ve ölçeklendirme ile maliyetleri azaltın</span><span class="sxs-lookup"><span data-stu-id="3a04c-114">Reduce cost with pause and scale</span></span>
<span data-ttu-id="3a04c-115">SQL Veri Ambarı’nın önemli özelliklerinden biri, kullanmadığınız zaman duraklatarak işlem kaynakların maliyetlerini durdurma şansına sahip olmanızdır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-115">A key feature of SQL Data Warehouse is the ability to pause when you are not using it, which stops the billing of compute resources.</span></span>  <span data-ttu-id="3a04c-116">Bir diğer önemli özellik ise kaynakları ölçeklendirmektir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-116">Another key feature is the ability to scale resources.</span></span>  <span data-ttu-id="3a04c-117">Duraklatma ve Ölçeklendirme işlemlerini Azure portal üzerinden veya PowerShell komutları aracılığıyla yapabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-117">Pausing and Scaling can be done via the Azure portal or through PowerShell commands.</span></span>  <span data-ttu-id="3a04c-118">Veri ambarınız kullanılmadığında ilgili maliyetleri önemli ölçüde düşürebildiğinden bu özellikleri inceleyip keşfetmeniz önerilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-118">Become familiar with these features as they can greatly reduce the cost of your data warehouse when it is not in use.</span></span>  <span data-ttu-id="3a04c-119">Veri ambarınızın her zaman erişilebilir durumda olmasını istiyorsanız, duraklatmak yerine en küçük boyut olan DW100’e ölçeklendirmeyi tercih edebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-119">If you always want your data warehouse accessible, you may want to consider scaling it down to the smallest size, a DW100 rather than pausing.</span></span>

<span data-ttu-id="3a04c-120">Ayrıca bkz. [İşlem kaynaklarını duraklatma][Pause compute resources], [İşlem kaynaklarını sürdürme][Resume compute resources], [İşlem kaynaklarını ölçeklendirme].</span><span class="sxs-lookup"><span data-stu-id="3a04c-120">See also [Pause compute resources][Pause compute resources], [Resume compute resources][Resume compute resources], [Scale compute resources].</span></span>

## <a name="drain-transactions-before-pausing-or-scaling"></a><span data-ttu-id="3a04c-121">Duraklatma veya ölçeklendirme öncesinde işlemleri boşaltın</span><span class="sxs-lookup"><span data-stu-id="3a04c-121">Drain transactions before pausing or scaling</span></span>
<span data-ttu-id="3a04c-122">SQL Veri Ambarınız için duraklatma veya ölçeklendirme isteğinde bulunduğunuzda, arka planda sorgularınız iptal edilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-122">When you pause or scale your SQL Data Warehouse, behind the scenes your queries are canceled when you initiate the pause or scale request.</span></span>  <span data-ttu-id="3a04c-123">Basit bir SELECT sorgusunu hızlıca ve örnek duraklatma veya ölçeklendirme süresini neredeyse hiç etkilemeden iptal edebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-123">Canceling a simple SELECT query is a quick operation and has almost no impact to the time it takes to pause or scale your instance.</span></span>  <span data-ttu-id="3a04c-124">Ancak, verilerinizi veya verilerinizin yapısını değiştiren işlem sorguları o kadar hızlı durdurulamayabilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-124">However, transactional queries, which modify your data or the structure of the data, may not be able to stop quickly.</span></span>  <span data-ttu-id="3a04c-125">**Bir işlem sorgusunun tamamlanması veya yaptığı değişiklikleri geri alması gerekir.**</span><span class="sxs-lookup"><span data-stu-id="3a04c-125">**Transactional queries, by definition, must either complete in their entirety or rollback their changes.**</span></span>  <span data-ttu-id="3a04c-126">Bir işlem sorgusunun tamamladığı işi geri almak, sorgunun değişiklik yapmak için harcadığı süre kadar, hatta bazen daha fazla zaman alabilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-126">Rolling back the work completed by a transactional query can take as long, or even longer, than the original change the query was applying.</span></span>  <span data-ttu-id="3a04c-127">Örneğin, bir saattir çalışan ve satır silen bir sorguyu iptal etmeniz halinde sistemin silinmiş olan satırları geri eklemesi bir saat sürebilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-127">For example, if you cancel a query which was deleting rows and has already been running for an hour, it could take the system an hour to insert back the rows which were deleted.</span></span>  <span data-ttu-id="3a04c-128">Duraklatma veya ölçeklendirme isteklerini işlemler devam ederken çalıştırmanız halinde, devam etmek için geri alma işleminin tamamlanmasını bekleyeceğinden ilgili duraklatma veya ölçeklendirme işleminin tamamlanması uzun sürebilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-128">If you run pause or scaling while transactions are in flight, your pause or scaling may seem to take a long time because pausing and scaling has to wait for the rollback to complete before it can proceed.</span></span>

<span data-ttu-id="3a04c-129">Ayrıca bkz. [İşlemleri anlama][Understanding transactions], [İşlemleri iyileştirme][Optimizing transactions]</span><span class="sxs-lookup"><span data-stu-id="3a04c-129">See also [Understanding transactions][Understanding transactions], [Optimizing transactions][Optimizing transactions]</span></span>

## <a name="maintain-statistics"></a><span data-ttu-id="3a04c-130">İstatistiklerin bakımını yapın</span><span class="sxs-lookup"><span data-stu-id="3a04c-130">Maintain statistics</span></span>
<span data-ttu-id="3a04c-131">Sütunlarla ilgili istatistikleri otomatik olarak algılayıp oluşturan veya güncelleştiren SQL Server’dan farklı olarak, SQL Veri Ambarı’nda istatistiklerin bakımının kullanıcı tarafından yapılması gerekir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-131">Unlike SQL Server, which automatically detects and creates or updates statistics on columns, SQL Data Warehouse requires manual maintenance of statistics.</span></span>  <span data-ttu-id="3a04c-132">Bu özelliği ilerleyen zamanlarda değiştirmeyi planlıyoruz ancak şimdilik SQL Veri Ambarı planlarının iyileştirilmiş olduğundan emin olmak için istatistiklerin bakımını sizin yapmanız gerekiyor.</span><span class="sxs-lookup"><span data-stu-id="3a04c-132">While we do plan to change this in the future, for now you will want to maintain your statistics to ensure that the SQL Data Warehouse plans are optimized.</span></span>  <span data-ttu-id="3a04c-133">İyileştirici tarafından oluşturulan planların verimi, istatistiklere bağlıdır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-133">The plans created by the optimizer are only as good as the available statistics.</span></span>  <span data-ttu-id="3a04c-134">**İstatistik tutmaya başlamanın kolay yollarından biri, her sütun için örnek istatistik oluşturmaktır.**</span><span class="sxs-lookup"><span data-stu-id="3a04c-134">**Creating sampled statistics on every column is an easy way to get started with statistics.**</span></span>  <span data-ttu-id="3a04c-135">İstatistiklerin güncelleştirilmesi, verilerinizde yapılan değişiklikler kadar önemlidir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-135">It's equally important to update statistics as significant changes happen to your data.</span></span>  <span data-ttu-id="3a04c-136">Garanti yaklaşımlardan biri, istatistiklerinizi her gün veya her yükleme sonrasında güncelleştirmektir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-136">A conservative approach may be to update your statistics daily or after each load.</span></span>  <span data-ttu-id="3a04c-137">İstatistiklerin sıfırdan oluşturulması veya mevcut olanların güncelleştirilmesi konusunda karar vermek için performans ve maliyet açısından değerlendirme yapmanız gerekir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-137">There are always trade-offs between performance and the cost to create and update statistics.</span></span> <span data-ttu-id="3a04c-138">Tüm istatistiklerin bakımını yapmanın çok uzun sürdüğünü düşünüyorsanız, istatistik tutulması veya sık güncelleştirilmesi gereken sütunlar konusunda daha ayrıntılı bir seçim yapabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-138">If you find it is taking too long to maintain all of your statistics, you may want to try to be more selective about which columns have statistics or which columns need frequent updating.</span></span>  <span data-ttu-id="3a04c-139">Örneğin, yeni değer eklenme ihtimali olan tarih sütunlarını her gün güncelleştirmeyi tercih edebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-139">For example, you might want to update date columns, where new values may be added, daily.</span></span> <span data-ttu-id="3a04c-140">**En çok faydayı birleştirmelerin bulunduğu sütunlar, WHERE yan tümcesinde kullanılan sütunlar ve GROUP BY içinde bulunan sütunlar için istatistik tutarak elde edebilirsiniz.**</span><span class="sxs-lookup"><span data-stu-id="3a04c-140">**You will gain the most benefit by having statistics on columns involved in joins, columns used in the WHERE clause and columns found in GROUP BY.**</span></span>

<span data-ttu-id="3a04c-141">Ayrıca bkz. [Tablo istatistiklerini yönetme][Manage table statistics], [CREATE STATISTICS][CREATE STATISTICS], [UPDATE STATISTICS][UPDATE STATISTICS]</span><span class="sxs-lookup"><span data-stu-id="3a04c-141">See also [Manage table statistics][Manage table statistics], [CREATE STATISTICS][CREATE STATISTICS], [UPDATE STATISTICS][UPDATE STATISTICS]</span></span>

## <a name="group-insert-statements-into-batches"></a><span data-ttu-id="3a04c-142">INSERT deyimlerini gruplayın</span><span class="sxs-lookup"><span data-stu-id="3a04c-142">Group INSERT statements into batches</span></span>
<span data-ttu-id="3a04c-143">Küçük bir tabloya bir INSERT deyimiyle tek seferlik yükleme yapmak veya `INSERT INTO MyLookup VALUES (1, 'Type 1')` gibi bir deyimle bir aramanın düzenli aralıklarla yeniden yüklenmesi işinizi fazlasıyla görebilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-143">A one-time load to a small table with an INSERT statement or even a periodic reload of a look-up may perform just fine for your needs with a statement like `INSERT INTO MyLookup VALUES (1, 'Type 1')`.</span></span>  <span data-ttu-id="3a04c-144">Ancak gün içinde binlerce veya milyonlarca satır yüklemeniz gerekiyorsa, ayrı ayrı INSERT deyimleri gerekli performansı göstermeyebilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-144">However, if you need to load thousands or millions of rows throughout the day, you might find that singleton INSERTS just can't keep up.</span></span>  <span data-ttu-id="3a04c-145">Bunun yerine işlemlerinizi bir dosyaya yazılacağı ve başka bir işlemin belirli aralıklarla bu dosyayı yükleyeceği şekilde geliştirin.</span><span class="sxs-lookup"><span data-stu-id="3a04c-145">Instead, develop your processes so that they write to a file and another process periodically comes along and loads this file.</span></span>

<span data-ttu-id="3a04c-146">Ayrıca bkz. [INSERT][INSERT]</span><span class="sxs-lookup"><span data-stu-id="3a04c-146">See also [INSERT][INSERT]</span></span>

## <a name="use-polybase-to-load-and-export-data-quickly"></a><span data-ttu-id="3a04c-147">Verileri hızlıca yüklemek ve dışarı aktarmak için PolyBase kullanın</span><span class="sxs-lookup"><span data-stu-id="3a04c-147">Use PolyBase to load and export data quickly</span></span>
<span data-ttu-id="3a04c-148">SQL Veri Ambarı, veri yüklemek ve dışarı aktarmak için Azure Data Factory, PolyBase ve BCP gibi birçok aracı destekler.</span><span class="sxs-lookup"><span data-stu-id="3a04c-148">SQL Data Warehouse supports loading and exporting data through several tools including Azure Data Factory, PolyBase, and BCP.</span></span>  <span data-ttu-id="3a04c-149">Performansın yüksek öneme sahip olmadığı küçük miktarlardaki veriler için bu araçlardan herhangi birini kullanabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-149">For small amounts of data where performance isn't critical, any tool may be sufficient for your needs.</span></span>  <span data-ttu-id="3a04c-150">Ancak, büyük hacimli verileri yüklerken veya dışarı aktarırken ya da yüksek performansa ihtiyaç duyduğunuzda, PolyBase en iyi çözüm olacaktır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-150">However, when you are loading or exporting large volumes of data or fast performance is needed, PolyBase is the best choice.</span></span>  <span data-ttu-id="3a04c-151">PolyBase, SQL Veri Ambarı’nın MPP (Massively Parallel Processing - Büyük Ölçekli Paralel İşleme) mimarisini kullanarak büyük verileri diğer tüm araçlardan daha hızlı bir şekilde yükleyecek ve dışarı aktaracak şekilde tasarlanmıştır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-151">PolyBase is designed to leverage the MPP (Massively Parallel Processing) architecture of SQL Data Warehouse and will therefore load and export data magnitudes faster than any other tool.</span></span>  <span data-ttu-id="3a04c-152">PolyBase yükleri CTAS veya INSERT INTO ile çalıştırılabilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-152">PolyBase loads can be run using CTAS or INSERT INTO.</span></span>  <span data-ttu-id="3a04c-153">**CTAS, işlem günlüğünü en aza indiren ve verilerinizi en hızlı yükleyen seçenektir.**</span><span class="sxs-lookup"><span data-stu-id="3a04c-153">**Using CTAS will minimize transaction logging and the fastest way to load your data.**</span></span>  <span data-ttu-id="3a04c-154">Azure Data Factory, PolyBase yüklerini de destekler.</span><span class="sxs-lookup"><span data-stu-id="3a04c-154">Azure Data Factory also supports PolyBase loads.</span></span>  <span data-ttu-id="3a04c-155">PolyBase, Gzip de dahil olmak üzere birçok dosya biçimi için destek sunar.</span><span class="sxs-lookup"><span data-stu-id="3a04c-155">PolyBase supports a variety of file formats including Gzip files.</span></span>  <span data-ttu-id="3a04c-156">**gzip metin dosyalarını kullanırken verimi en üst düzeye çıkarmak için dosyaları 60 veya daha fazla parçaya bölerek daha çok paralel işlem oluşturabilirsiniz.**</span><span class="sxs-lookup"><span data-stu-id="3a04c-156">**To maximize throughput when using gzip text files, break files up into 60 or more files to maximize parallelism of your load.**</span></span>  <span data-ttu-id="3a04c-157">Toplam hızı artırmak için verilerinizi aynı anda yükleyin.</span><span class="sxs-lookup"><span data-stu-id="3a04c-157">For faster total throughput, consider loading data concurrently.</span></span>

<span data-ttu-id="3a04c-158">Ayrıca bkz. [Yerel veriler][Load data], [PolyBase kullanma kılavuzu][Guide for using PolyBase], [Azure SQL Veri Ambarı yükleme modelleri ve stratejileri][Azure SQL Data Warehouse loading patterns and strategies], [Azure Data Factory ile veri yükleme][Load Data with Azure Data Factory], [Azure Data Factory ile veri taşıma][Move data with Azure Data Factory], [CREATE EXTERNAL FILE FORMAT][CREATE EXTERNAL FILE FORMAT], [Create table as select (CTAS)][Create table as select (CTAS)]</span><span class="sxs-lookup"><span data-stu-id="3a04c-158">See also [Load data][Load data], [Guide for using PolyBase][Guide for using PolyBase], [Azure SQL Data Warehouse loading patterns and strategies][Azure SQL Data Warehouse loading patterns and strategies], [Load Data with Azure Data Factory][Load Data with Azure Data Factory], [Move data with Azure Data Factory][Move data with Azure Data Factory], [CREATE EXTERNAL FILE FORMAT][CREATE EXTERNAL FILE FORMAT], [Create table as select (CTAS)][Create table as select (CTAS)]</span></span>

## <a name="load-then-query-external-tables"></a><span data-ttu-id="3a04c-159">Dış tabloları önce yükleyip sonra sorgu çalıştırın</span><span class="sxs-lookup"><span data-stu-id="3a04c-159">Load then query external tables</span></span>
<span data-ttu-id="3a04c-160">Dış tablolar olarak da bilinen Polybase, veri yüklemenin en hızlı yolu olsa da sorgular için en iyi çözüm değildir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-160">While Polybase, also known as external tables, can be the fastest way to load data, it is not optimal for queries.</span></span> <span data-ttu-id="3a04c-161">SQL Veri Ambarı Polybase tabloları şimdilik yalnızca Azure blob dosyalarını desteklemektedir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-161">SQL Data Warehouse Polybase tables currently only support Azure blob files.</span></span> <span data-ttu-id="3a04c-162">Bu dosyaları destekleyen herhangi bir işlem kaynağı yoktur.</span><span class="sxs-lookup"><span data-stu-id="3a04c-162">These files do not have any compute resources backing them.</span></span>  <span data-ttu-id="3a04c-163">Bu nedenle SQL Veri Ambarı bu işin yükünü boşaltamaz ve verileri okumak için dosyanın tamamını tempdb içine yüklemesi gerekir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-163">As a result, SQL Data Warehouse cannot offload this work and therefore must read the entire file by loading it to tempdb in order to read the data.</span></span>  <span data-ttu-id="3a04c-164">Sonuç olarak bu veriler için birden fazla sorgunuz varsa, verileri bir kez yükleyip sorguların yerel tabloyu kullanmalarını sağlamak daha iyi olacaktır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-164">Therefore, if you have several queries that will be querying this data, it is better to load this data once and have queries use the local table.</span></span>

<span data-ttu-id="3a04c-165">Ayrıca bkz. [PolyBase kullanma kılavuzu][Guide for using PolyBase]</span><span class="sxs-lookup"><span data-stu-id="3a04c-165">See also [Guide for using PolyBase][Guide for using PolyBase]</span></span>

## <a name="hash-distribute-large-tables"></a><span data-ttu-id="3a04c-166">Büyük tabloları karma olarak dağıtın</span><span class="sxs-lookup"><span data-stu-id="3a04c-166">Hash distribute large tables</span></span>
<span data-ttu-id="3a04c-167">Tablolar varsayılan olarak Hepsini Bir Kez Deneme yöntemiyle dağıtılmıştır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-167">By default, tables are Round Robin distributed.</span></span>  <span data-ttu-id="3a04c-168">Bu durum, kullanıcıların tabloların dağıtma şekli hakkında düşünmelerine gerek kalmadan tablo oluşturmaya başlamalarını sağlar.</span><span class="sxs-lookup"><span data-stu-id="3a04c-168">This makes it easy for users to get started creating tables without having to decide how their tables should be distributed.</span></span>  <span data-ttu-id="3a04c-169">Hepsini Bir Kez Deneme tabloları, belirli iş yükleri için yeterli performans sunabilir ancak birçok durumda dağıtım sütunu seçilmesi daha iyi sonuç verecektir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-169">Round Robin tables may perform sufficiently for some workloads, but in most cases selecting a distribution column will perform much better.</span></span>  <span data-ttu-id="3a04c-170">Sütuna göre dağıtılmış bir tablonun Hepsini Bir Kez Deneme tablosundan daha iyi performans sunacağı bir örnek, iki büyük bilgi tablosunun birleştirilmesidir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-170">The most common example of when a table distributed by a column will far outperform a Round Robin table is when two large fact tables are joined.</span></span>  <span data-ttu-id="3a04c-171">Örneğin, order_id ile dağıtılmış bir sipariş tablonuz ve yine order_id ile dağıtılmış bir işlem tablonuz varsa, sipariş tablonuzla işlem tablonuzu order_id üzerinden birleştirdiğinizde, ilgili sorgu bir geçiş sorgusu olur ve veri taşıma işlemleri atlanır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-171">For example, if you have an orders table, which is distributed by order_id, and a transactions table, which is also distributed by order_id, when you join your orders table to your transactions table on order_id, this query becomes a pass-through query, which means we eliminate data movement operations.</span></span>  <span data-ttu-id="3a04c-172">Adım sayısı ne kadar az olursa sorgu o kadar hızlı işlenir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-172">Fewer steps mean a faster query.</span></span>  <span data-ttu-id="3a04c-173">Taşınan veri miktarı azaldıkça sorgunun hızı artar.</span><span class="sxs-lookup"><span data-stu-id="3a04c-173">Less data movement also makes for faster queries.</span></span>  <span data-ttu-id="3a04c-174">Bu yalnızca yüzeysel bir açıklamadır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-174">This explanation just scratches the surface.</span></span> <span data-ttu-id="3a04c-175">Dağıtılmış bir tablo yüklenirken, yükleme işleminin yavaşlamaması için gelen verilerinizin dağıtım anahtarına göre sıralanmamış olduğundan emin olun.</span><span class="sxs-lookup"><span data-stu-id="3a04c-175">When loading a distributed table, be sure that your incoming data is not sorted on the distribution key as this will slow down your loads.</span></span>  <span data-ttu-id="3a04c-176">Dağıtım sütunu seçmenin performansı nasıl artıracağı hakkında daha fazla bilgi edinmek ve CREATE TABLES deyiminizin WITH yan tümcesinde dağıtılmış tablo tanımlamayı öğrenmek için aşağıdaki bağlantıları inceleyin.</span><span class="sxs-lookup"><span data-stu-id="3a04c-176">See the below links for much more details on how selecting a distribution column can improve performance as well as how to define a distributed table in the WITH clause of your CREATE TABLES statement.</span></span>

<span data-ttu-id="3a04c-177">Ayrıca bkz. [Tabloya genel bakış][Table overview], [Tablo dağıtımı][Table distribution], [Tablo dağıtımına genel bakış][Selecting table distribution], [CREATE TABLE][CREATE TABLE], [CREATE TABLE AS SELECT][CREATE TABLE AS SELECT]</span><span class="sxs-lookup"><span data-stu-id="3a04c-177">See also [Table overview][Table overview], [Table distribution][Table distribution], [Selecting table distribution][Selecting table distribution], [CREATE TABLE][CREATE TABLE], [CREATE TABLE AS SELECT][CREATE TABLE AS SELECT]</span></span>

## <a name="do-not-over-partition"></a><span data-ttu-id="3a04c-178">Aşırı bölümleme yapmayın</span><span class="sxs-lookup"><span data-stu-id="3a04c-178">Do not over-partition</span></span>
<span data-ttu-id="3a04c-179">Verileri bölümleme, bölüm değiştirme ile verilerinizin bakımını yapma veya bölüm eleme ile tarama iyileştirme konularında etkili olsa da, bölüm sayısının çok fazla olması sorgularınızı yavaşlatabilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-179">While partitioning data can be very effective for maintaining your data through partition switching or optimizing scans by with partition elimination, having too many partitions can slow down your queries.</span></span>  <span data-ttu-id="3a04c-180">Genelde SQL Server üzerinde iyi çalışan çok parçalı bölüm stratejisi SQL Veri Ambarı söz konusu olduğunda verimli olmayabilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-180">Often a high granularity partitioning strategy which may work well on SQL Server may not work well on SQL Data Warehouse.</span></span>  <span data-ttu-id="3a04c-181">Bölüm sayısının çok fazla olması, her bir bölümdeki satır sayısının 1 milyondan az olması halinde kümelenmiş columnstore dizinlerinin verimini de düşürebilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-181">Having too many partitions can also reduce the effectiveness of clustered columnstore indexes if each partition has fewer than 1 million rows.</span></span>  <span data-ttu-id="3a04c-182">Ayrıca, SQL Veri Ambarı’nın verilerinizi arka planda 60 veritabanına böldüğünü unutmayın. 100 bölüme sahip bir tablo oluşturduğunuzda, toplam 6000 bölüm oluşturulmuş olur.</span><span class="sxs-lookup"><span data-stu-id="3a04c-182">Keep in mind that behind the scenes, SQL Data Warehouse partitions your data for you into 60 databases, so if you create a table with 100 partitions, this actually results in 6000 partitions.</span></span>  <span data-ttu-id="3a04c-183">Her iş yükü farklı olduğundan, en iyi yöntem deneme yanılma ile iş yükünüze en uygun bölümleme şeklini belirlemektir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-183">Each workload is different so the best advice is to experiment with partitioning to see what works best for your workload.</span></span>  <span data-ttu-id="3a04c-184">SQL Server’da kullandığınızdan daha az parça kullanmayı deneyin.</span><span class="sxs-lookup"><span data-stu-id="3a04c-184">Consider lower granularity than what may have worked for you in SQL Server.</span></span>  <span data-ttu-id="3a04c-185">Örneğin, günlük bölümler yerine haftalık veya aylık bölümler kullanın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-185">For example, consider using weekly or monthly partitions rather than daily partitions.</span></span>

<span data-ttu-id="3a04c-186">Ayrıca bkz. [Tablo bölümleme][Table partitioning]</span><span class="sxs-lookup"><span data-stu-id="3a04c-186">See also [Table partitioning][Table partitioning]</span></span>

## <a name="minimize-transaction-sizes"></a><span data-ttu-id="3a04c-187">İşlem boyutları en aza indirin</span><span class="sxs-lookup"><span data-stu-id="3a04c-187">Minimize transaction sizes</span></span>
<span data-ttu-id="3a04c-188">Bir işlemde çalışan INSERT, UPDATE ve DELETE deyimleri başarısız olduğunda gerçekleştirilen adımların geri alınması gerekir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-188">INSERT, UPDATE, and DELETE statements run in a transaction and when they fail they must be rolled back.</span></span>  <span data-ttu-id="3a04c-189">Uzun sürecek bir geri alma işlemi olasılığını en aza indirmek için işlem boyutlarını mümkün oldukça küçültün.</span><span class="sxs-lookup"><span data-stu-id="3a04c-189">To minimize the potential for a long rollback, minimize transaction sizes whenever possible.</span></span>  <span data-ttu-id="3a04c-190">Bunu yapmak için INSERT, UPDATE ve DELETE deyimlerini parçalara ayırabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-190">This can be done by dividing INSERT, UPDATE, and DELETE statements into parts.</span></span>  <span data-ttu-id="3a04c-191">Örneğin, 1 saat sürmesini beklediğiniz bir INSERT deyiminiz varsa, bu INSERT deyimini her biri 15 dakika sürecek 4 parçaya ayırın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-191">For example, if you have an INSERT which you expect to take 1 hour, if possible, break the INSERT up into 4 parts, which will each run in 15 minutes.</span></span>  <span data-ttu-id="3a04c-192">Geri alma riskini azaltmak için CTAS, TRUNCATE, DROP TABLE veya INSERT gibi özel En Az Günlüğe Kaydetme durumlarında boş tablo kullanın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-192">Leverage special Minimal Logging cases, like CTAS, TRUNCATE, DROP TABLE or INSERT to empty tables, to reduce rollback risk.</span></span>  <span data-ttu-id="3a04c-193">Geri alma işlemlerini ortadan kaldırmanın başka bir yöntemi de veri yönetimi için bölüm değiştirme gibi Yalnızca Meta Veri işlemlerini kullanmaktır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-193">Another way to eliminate rollbacks is to use Metadata Only operations like partition switching for data management.</span></span>  <span data-ttu-id="3a04c-194">Örneğin, bir tablodaki order_date değerleri Ekim 2001 içinde olan tüm satırları silmek amacıyla bir DELETE deyimi çalıştırmak yerine verilerinizi aylık bölümlere ayırıp bölümü başka bir tablonun boş bölümüyle değiştirebilirsiniz (ALTER TABLE örneklerini inceleyin).</span><span class="sxs-lookup"><span data-stu-id="3a04c-194">For example, rather than execute a DELETE statement to delete all rows in a table where the order_date was in October of 2001, you could partition your data monthly and then switch out the partition with data for an empty partition from another table (see ALTER TABLE examples).</span></span>  <span data-ttu-id="3a04c-195">Bölümlenmemiş tablolar için DELETE deyimini kullanmak yerine CTAS kullanarak tutmak istediğiniz verileri bir tabloya yazabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-195">For unpartitioned tables consider using a CTAS to write the data you want to keep in a table rather than using DELETE.</span></span>  <span data-ttu-id="3a04c-196">Gereken süre aynıysa, günlüğe çok az işlem kaydı yapıldığı ve gerekli olması halinde hızlıca iptal edilebildiği için CTAS işlemi daha güvenli bir seçenektir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-196">If a CTAS takes the same amount of time, it is a much safer operation to run as it has very minimal transaction logging and can be canceled quickly if needed.</span></span>

<span data-ttu-id="3a04c-197">Ayrıca bkz. [İşlemleri anlama][Understanding transactions], [İşlemleri iyileştirme][Optimizing transactions], [Tablo bölümleme][Table partitioning], [TRUNCATE TABLE][TRUNCATE TABLE], [ALTER TABLE][ALTER TABLE], [Create table as select (CTAS)][Create table as select (CTAS)]</span><span class="sxs-lookup"><span data-stu-id="3a04c-197">See also [Understanding transactions][Understanding transactions], [Optimizing transactions][Optimizing transactions], [Table partitioning][Table partitioning], [TRUNCATE TABLE][TRUNCATE TABLE], [ALTER TABLE][ALTER TABLE], [Create table as select (CTAS)][Create table as select (CTAS)]</span></span>

## <a name="use-the-smallest-possible-column-size"></a><span data-ttu-id="3a04c-198">Mümkün olan en küçük sütun boyutunu kullanın</span><span class="sxs-lookup"><span data-stu-id="3a04c-198">Use the smallest possible column size</span></span>
<span data-ttu-id="3a04c-199">Sorgu performansını artırmak için, DDL tanımlaması yaparken verilerinizi destekleyecek en küçük veri türünü kullanın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-199">When defining your DDL, using the smallest data type which will support your data will improve query performance.</span></span>  <span data-ttu-id="3a04c-200">Bu durum özellikle CHAR ve VARCHAR sütunları için önemlidir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-200">This is especially important for CHAR and VARCHAR columns.</span></span>  <span data-ttu-id="3a04c-201">Bir sütundaki en uzun değer 25 karakterse, sütununuzu VARCHAR(25) olarak tanımlayın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-201">If the longest value in a column is 25 characters, then define your column as VARCHAR(25).</span></span>  <span data-ttu-id="3a04c-202">Tüm karakter sütunları için varsayılan uzunluk değeri olarak yüksek bir değer kullanmaktan kaçının.</span><span class="sxs-lookup"><span data-stu-id="3a04c-202">Avoid defining all character columns to a large default length.</span></span>  <span data-ttu-id="3a04c-203">Ayrıca, NVARCHAR şart değilse sütunları VARCHAR olarak tanımlayın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-203">In addition, define columns as VARCHAR when that is all that is needed rather than use NVARCHAR.</span></span>

<span data-ttu-id="3a04c-204">Ayrıca bkz. [Tabloya genel bakış][Table overview], [Tablo veri türleri][Table data types], [CREATE TABLE][CREATE TABLE]</span><span class="sxs-lookup"><span data-stu-id="3a04c-204">See also [Table overview][Table overview], [Table data types][Table data types], [CREATE TABLE][CREATE TABLE]</span></span>

## <a name="use-temporary-heap-tables-for-transient-data"></a><span data-ttu-id="3a04c-205">Geçiş verileri için geçici yığın tabloları kullanın</span><span class="sxs-lookup"><span data-stu-id="3a04c-205">Use temporary heap tables for transient data</span></span>
<span data-ttu-id="3a04c-206">SQL Veri Ambarı’na geçici veri yüklemesi yapıyorsanız, yığın tabloları kullanmanın işlem hızını artırdığını fark edeceksiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-206">When you are temporarily landing data on SQL Data Warehouse, you may find that using a heap table will make the overall process faster.</span></span>  <span data-ttu-id="3a04c-207">Verileri yalnızca daha fazla dönüştürme gerçekleştirmeden önce hazırlamak için yüklüyorsanız, tabloyu yığın tablosuna yüklemek verileri kümelenmiş bir columnstore tablosuna yüklemekten çok daha hızlı olacaktır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-207">If you are loading data only to stage it before running more transformations, loading the table to heap table will be much faster than loading the data to a clustered columnstore table.</span></span>  <span data-ttu-id="3a04c-208">Ayrıca verileri geçici bir tabloya yüklemek, tabloyu kalıcı bir depolama alanına yüklemekten çok daha hızlı gerçekleştirilecektir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-208">In addition, loading data to a temp table will also load much faster than loading a table to permanent storage.</span></span>  <span data-ttu-id="3a04c-209">Geçici tablolar "#" ile başlar ve yalnızca kendilerini oluşturan oturum tarafından erişilebilir. Bu nedenle sınırlı sayıda senaryoda çalışabilirler.</span><span class="sxs-lookup"><span data-stu-id="3a04c-209">Temporary tables start with a "#" and are only accessible by the session which created it, so they may only work in limited scenarios.</span></span>   <span data-ttu-id="3a04c-210">Yığın tabloları, CREATE TABLE deyiminin WITH yan tümcesinde tanımlanır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-210">Heap tables are defined in the WITH clause of a CREATE TABLE.</span></span>  <span data-ttu-id="3a04c-211">Geçici tablo kullanıyorsanız, onun için de istatistik oluşturmayı unutmayın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-211">If you do use a temporary table, remember to create statistics on that temporary table too.</span></span>

<span data-ttu-id="3a04c-212">Ayrıca bkz. [Geçici tablolar][Temporary tables], [CREATE TABLE][CREATE TABLE], [CREATE TABLE AS SELECT][CREATE TABLE AS SELECT]</span><span class="sxs-lookup"><span data-stu-id="3a04c-212">See also [Temporary tables][Temporary tables], [CREATE TABLE][CREATE TABLE], [CREATE TABLE AS SELECT][CREATE TABLE AS SELECT]</span></span>

## <a name="optimize-clustered-columnstore-tables"></a><span data-ttu-id="3a04c-213">Kümelenmiş columnstore tablolarını iyileştirin</span><span class="sxs-lookup"><span data-stu-id="3a04c-213">Optimize clustered columnstore tables</span></span>
<span data-ttu-id="3a04c-214">Kümelenmiş columnstore dizinleri, verilerinizi Azure SQL Veri Ambarı’nda depolamanın en verimli yöntemlerinden biridir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-214">Clustered columnstore indexes are one of the most efficient ways you can store your data in Azure SQL Data Warehouse.</span></span>  <span data-ttu-id="3a04c-215">SQL Veri Ambarı tabloları varsayılan ayarda Kümelenmiş ColumnStore olarak oluşturulur.</span><span class="sxs-lookup"><span data-stu-id="3a04c-215">By default, tables in SQL Data Warehouse are created as Clustered ColumnStore.</span></span>  <span data-ttu-id="3a04c-216">Columnstore tablolarında yapılan sorgularda en iyi performansı elde etmek için segment kalitesinin yüksek olması önemlidir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-216">To get the best performance for queries on columnstore tables, having good segment quality is important.</span></span>  <span data-ttu-id="3a04c-217">Satırlar columnstore tablolarına bellek baskısı altında yazıldığında, segment kalitesi düşebilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-217">When rows are written to columnstore tables under memory pressure, columnstore segment quality may suffer.</span></span>  <span data-ttu-id="3a04c-218">Segment kalitesi, sıkıştırılmış Satır Grubu içindeki satır sayısıyla ölçülebilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-218">Segment quality can be measured by number of rows in a compressed Row Group.</span></span>  <span data-ttu-id="3a04c-219">Kümelenmiş columnstore tablolarının segment kalitesini tespit etme ve iyileştirme talimatları için [Tablo dizinleri][Table indexes] makalesindeki [Columnstore dizin kalitesinin düşük olmasının nedenleri][Causes of poor columnstore index quality] bölümüne bakın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-219">See the [Causes of poor columnstore index quality][Causes of poor columnstore index quality] in the [Table indexes][Table indexes] article for step by step instructions on detecting and improving segment quality for clustered columnstore tables.</span></span>  <span data-ttu-id="3a04c-220">Yüksek kaliteli columnstore segmentleri önemli olduğundan, veri yüklemek için orta veya büyük kaynak sınıfındaki kullanıcı kimliklerinden faydalanabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-220">Because high quality columnstore segments is important, it's a good idea to use users ids which are in the medium or large resource class for loading data.</span></span>  <span data-ttu-id="3a04c-221">Ne kadar az DWU kullanırsanız, yüklenen kullanıcınıza o kadar büyük kaynak sınıfı atamanız gerekir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-221">The fewer DWUs you use, the larger the resource class you will want to assign to your loading user.</span></span>

<span data-ttu-id="3a04c-222">Columnstore tabloları genelde tablo başına 1 milyon satır sınırı aşılmadan verileri sıkıştırılmış columnstore segmentlerine aktarmadığından ve her SQL Veri Ambarı tablosu 60 tabloya ayrıldığından, tablodaki satır sayısı 60 milyonu aşana kadar sorgular için columnstore tabloları kullanmaz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-222">Since columnstore tables generally won't push data into a compressed columnstore segment until there are more than 1 million rows per table and each SQL Data Warehouse table is partitioned into 60 tables, as a rule of thumb, columnstore tables won't benefit a query unless the table has more than 60 million rows.</span></span>  <span data-ttu-id="3a04c-223">60 milyondan az satıra sahip tablolarda columnstore dizini kullanmaya gerek olmayabilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-223">For table with less than 60 million rows, it may not make any sense to have a columnstore index.</span></span>  <span data-ttu-id="3a04c-224">Kullanmanın da bir zararı olmayacaktır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-224">It also may not hurt.</span></span>  <span data-ttu-id="3a04c-225">Ayrıca, verilerinizi bölümlemeniz halinde her bir bölümün kümelenmiş columnstore dizini kullanabilmesi için en az 1 milyon satıra ihtiyaç duyacağını unutmayın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-225">Furthermore, if you partition your data, then you will want to consider that each partition will need to have 1 million rows to benefit from a clustered columnstore index.</span></span>  <span data-ttu-id="3a04c-226">100 bölüme sahip bir tablonun kümelenmiş columnstore kullanabilmesi için en az 6 milyar satıra sahip olması gerekir (60 dağıtım * 100 bölüm * 1 milyon satır).</span><span class="sxs-lookup"><span data-stu-id="3a04c-226">If a table has 100 partitions, then it will need to have at least 6 billion rows to benefit from a clustered columns store (60 distributions * 100 partitions * 1 million rows).</span></span>  <span data-ttu-id="3a04c-227">Bu örnekte tablonuzda 6 milyar satır yoksa, bölüm sayısını azaltabilir veya yığın tablo kullanabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-227">If your table does not have 6 billion rows in this example, either reduce the number of partitions or consider using a heap table instead.</span></span>  <span data-ttu-id="3a04c-228">Deneme yaparak columnstore tablosu yerine ikincil dizine sahip yığın tablo ile daha iyi performans elde edip etmeyeceğinizi görebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-228">It also may be worth experimenting to see if better performance can be gained with a heap table with secondary indexes rather than a columnstore table.</span></span>  <span data-ttu-id="3a04c-229">Columnstore tabloları ikincil dizinleri henüz desteklememektedir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-229">Columnstore tables do not yet support secondary indexes.</span></span>

<span data-ttu-id="3a04c-230">Columnstore tablosunda çalıştırılan sorgular yalnızca ihtiyacınız olan sütunları seçmeniz halinde daha hızlı olacaktır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-230">When querying a columnstore table, queries will run faster if you select only the columns you need.</span></span>  

<span data-ttu-id="3a04c-231">Ayrıca bkz. [Tablo dizinleri][Table indexes], [Columnstore dizinleri kılavuzu][Columnstore indexes guide], [Columnstore dizinlerini yeniden oluşturma][Rebuilding columnstore indexes]</span><span class="sxs-lookup"><span data-stu-id="3a04c-231">See also [Table indexes][Table indexes], [Columnstore indexes guide][Columnstore indexes guide], [Rebuilding columnstore indexes][Rebuilding columnstore indexes]</span></span>

## <a name="use-larger-resource-class-to-improve-query-performance"></a><span data-ttu-id="3a04c-232">Sorgu performansını artırmak için daha büyük kaynak sınıfı kullanın</span><span class="sxs-lookup"><span data-stu-id="3a04c-232">Use larger resource class to improve query performance</span></span>
<span data-ttu-id="3a04c-233">SQL Veri Ambarı, kaynak gruplarını sorgulara bellek ayırma yöntemi olarak kullanır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-233">SQL Data Warehouse uses resource groups as a way to allocate memory to queries.</span></span>  <span data-ttu-id="3a04c-234">Sistem ilk kurulduğunda tüm kullanıcılar, dağıtım başına 100 MB bellek veren küçük kaynak sınıfına atanır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-234">Out of the box, all users are assigned to the small resource class which grants 100 MB of memory per distribution.</span></span>  <span data-ttu-id="3a04c-235">Her zaman 60 dağıtım olduğundan ve her dağıtıma en az 100 MB verildiğinden, sistem genelinde ayrılan bellek toplam 6000 MB (yaklaşık 6 GB) olur.</span><span class="sxs-lookup"><span data-stu-id="3a04c-235">Since there are always 60 distributions and each distribution is given a minimum of 100 MB, system wide the total memory allocation is 6,000 MB, or just under 6 GB.</span></span>  <span data-ttu-id="3a04c-236">Büyük birleştirmeler veya kümelenmiş columnstore tablolarına yapılan yüklemeler gibi belirli sorgulara daha fazla bellek atanır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-236">Certain queries, like large joins or loads to clustered columnstore tables, will benefit from larger memory allocations.</span></span>  <span data-ttu-id="3a04c-237">Yalnızca tarama gibi bazı sorgulara ek atama yapılmaz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-237">Some queries, like pure scans, will see no benefit.</span></span>  <span data-ttu-id="3a04c-238">Diğer taraftan, daha büyük kaynak sınıflarının kullanılması eşzamanlı çalışmayı etkiler. Bu nedenle tüm kullanıcılarınızı büyük bir kaynak sınıfına taşımadan önce bu noktayı dikkate almanız gerekir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-238">On the flip side, utilizing larger resource classes impacts concurrency, so you will want to take this into consideration before moving all of your users to a large resource class.</span></span>

<span data-ttu-id="3a04c-239">Ayrıca bkz. [Eşzamanlılık ve iş yükü yönetimi][Concurrency and workload management]</span><span class="sxs-lookup"><span data-stu-id="3a04c-239">See also [Concurrency and workload management][Concurrency and workload management]</span></span>

## <a name="use-smaller-resource-class-to-increase-concurrency"></a><span data-ttu-id="3a04c-240">Eşzamanlılığı artırmak için daha küçük kaynak sınıfı kullanın</span><span class="sxs-lookup"><span data-stu-id="3a04c-240">Use Smaller Resource Class to Increase Concurrency</span></span>
<span data-ttu-id="3a04c-241">Kullanıcı sorgularında uzun süreli gecikmeler olduğunu fark ederseniz, kullanıcılarınız geniş kaynak sınıflarında çalışıyor ve çok fazla eşzamanlılık yuvası kullanarak diğer sorguların kuyrukta beklemesine neden oluyor olabilir.</span><span class="sxs-lookup"><span data-stu-id="3a04c-241">If you are noticing that user queries seem to have a long delay, it could be that your users are running in larger resource classes and are consuming a lot of concurrency slots causing other queries to queue up.</span></span>  <span data-ttu-id="3a04c-242">Kullanıcı sorgularının kuyrukta olup olmadığını görmek için `SELECT * FROM sys.dm_pdw_waits` çalıştırıp dönen satırlara bakın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-242">To see if users queries are queued, run `SELECT * FROM sys.dm_pdw_waits` to see if any rows are returned.</span></span>

<span data-ttu-id="3a04c-243">Ayrıca bkz. [Eşzamanlılık ve iş yükü yönetimi][Concurrency and workload management], [sys.dm_pdw_waits][sys.dm_pdw_waits]</span><span class="sxs-lookup"><span data-stu-id="3a04c-243">See also [Concurrency and workload management][Concurrency and workload management], [sys.dm_pdw_waits][sys.dm_pdw_waits]</span></span>

## <a name="use-dmvs-to-monitor-and-optimize-your-queries"></a><span data-ttu-id="3a04c-244">Sorgularınızı izlemek ve iyileştirmek için DMV’leri kullanın</span><span class="sxs-lookup"><span data-stu-id="3a04c-244">Use DMVs to monitor and optimize your queries</span></span>
<span data-ttu-id="3a04c-245">SQL Veri Ambarı’nda sorgu yürütmeyi izlemek için kullanabileceğiniz birçok DMV vardır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-245">SQL Data Warehouse has several DMVs which can be used to monitor query execution.</span></span>  <span data-ttu-id="3a04c-246">Aşağıdaki izleme makalesinde çalıştırılan bir sorgunun ayrıntılarını incelemeyle ilgili adım adım talimatlar yer almaktadır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-246">The monitoring article below walks through step-by-step instructions on how to look at the details of an executing query.</span></span>  <span data-ttu-id="3a04c-247">Bu DMV’lerdeki sorguları hızlıca bulmak için sorgularınızla LABEL seçeneğini kullanabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-247">To quickly find queries in these DMVs, using the LABEL option with your queries can help.</span></span>

<span data-ttu-id="3a04c-248">Ayrıca bkz. [DMV’leri kullanarak iş yükünüzü izleme][Monitor your workload using DMVs], [LABEL][LABEL], [OPTION][OPTION], [sys.dm_exec_sessions][sys.dm_exec_sessions], [sys.dm_pdw_exec_requests][sys.dm_pdw_exec_requests], [sys.dm_pdw_request_steps][sys.dm_pdw_request_steps], [sys.dm_pdw_sql_requests][sys.dm_pdw_sql_requests], [sys.dm_pdw_dms_workers], [DBCC PDW_SHOWEXECUTIONPLAN][DBCC PDW_SHOWEXECUTIONPLAN], [sys.dm_pdw_waits][sys.dm_pdw_waits]</span><span class="sxs-lookup"><span data-stu-id="3a04c-248">See also [Monitor your workload using DMVs][Monitor your workload using DMVs], [LABEL][LABEL], [OPTION][OPTION], [sys.dm_exec_sessions][sys.dm_exec_sessions], [sys.dm_pdw_exec_requests][sys.dm_pdw_exec_requests], [sys.dm_pdw_request_steps][sys.dm_pdw_request_steps], [sys.dm_pdw_sql_requests][sys.dm_pdw_sql_requests], [sys.dm_pdw_dms_workers], [DBCC PDW_SHOWEXECUTIONPLAN][DBCC PDW_SHOWEXECUTIONPLAN], [sys.dm_pdw_waits][sys.dm_pdw_waits]</span></span>

## <a name="other-resources"></a><span data-ttu-id="3a04c-249">Diğer kaynaklar</span><span class="sxs-lookup"><span data-stu-id="3a04c-249">Other resources</span></span>
<span data-ttu-id="3a04c-250">Genel sorunlar ve çözümleri için [Sorun giderme][Troubleshooting] makalemizi de inceleyin.</span><span class="sxs-lookup"><span data-stu-id="3a04c-250">Also see our [Troubleshooting][Troubleshooting] article for common issues and solutions.</span></span>

<span data-ttu-id="3a04c-251">Aradığınızı bu makalede bulamadıysanız, bu sayfanın sol tarafındaki "Belge ara" seçeneğini kullanarak tüm Azure SQL Veri Ambarı belgelerinde arama yapın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-251">If you didn't find what you were looking for in this article, try using the "Search for docs" on the left side of this page to search all of the Azure SQL Data Warehouse documents.</span></span>  <span data-ttu-id="3a04c-252">[Azure SQL Veri Ambarı MSDN Forumu][Azure SQL Data Warehouse MSDN Forum], diğer kullanıcılara ve SQL Veri Ambarı Ürün Grubu’na soru sormanız için tasarlanmış olan bir sayfadır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-252">The [Azure SQL Data Warehouse MSDN Forum][Azure SQL Data Warehouse MSDN Forum] was create as a place for you to ask questions to other users and to the SQL Data Warehouse Product Group.</span></span>  <span data-ttu-id="3a04c-253">Sorularınızın diğer kullanıcılar veya ekibimiz tarafından yanıtlandığından emin olmak için bu forumu sürekli takip ediyoruz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-253">We actively monitor this forum to ensure that your questions are answered either by another user or one of us.</span></span>  <span data-ttu-id="3a04c-254">Sorularınızı Stack Overflow sitesinde sormak isterseniz, [Azure SQL Veri Ambarı Stack Overflow Forumu][Azure SQL Data Warehouse Stack Overflow Forum]’nu da kullanabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="3a04c-254">If you prefer to ask your questions on Stack Overflow, we also have an [Azure SQL Data Warehouse Stack Overflow Forum][Azure SQL Data Warehouse Stack Overflow Forum].</span></span>

<span data-ttu-id="3a04c-255">Son olarak özellik isteğinde bulunmak için lütfen [Azure SQL Veri Ambarı Geri Bildirim][Azure SQL Data Warehouse Feedback] sayfasını kullanın.</span><span class="sxs-lookup"><span data-stu-id="3a04c-255">Finally, please do use the [Azure SQL Data Warehouse Feedback][Azure SQL Data Warehouse Feedback] page to make feature requests.</span></span>  <span data-ttu-id="3a04c-256">İsteklerinizi eklemeniz veya diğer istekleri oylamanız, özellikleri önceliklendirme konusunda bize yardımcı olmaktadır.</span><span class="sxs-lookup"><span data-stu-id="3a04c-256">Adding your requests or up-voting other requests really helps us prioritize features.</span></span>

<!--Image references-->

<!--Article references-->
[Create a support ticket]: ./sql-data-warehouse-get-started-create-support-ticket.md
[Concurrency and workload management]: ./sql-data-warehouse-develop-concurrency.md
[Create table as select (CTAS)]: ./sql-data-warehouse-develop-ctas.md
[Table overview]: ./sql-data-warehouse-tables-overview.md
[Table data types]: ./sql-data-warehouse-tables-data-types.md
[Table distribution]: ./sql-data-warehouse-tables-distribute.md
[Table indexes]: ./sql-data-warehouse-tables-index.md
[Causes of poor columnstore index quality]: ./sql-data-warehouse-tables-index.md#causes-of-poor-columnstore-index-quality
[Rebuilding columnstore indexes]: ./sql-data-warehouse-tables-index.md#rebuilding-indexes-to-improve-segment-quality
[Table partitioning]: ./sql-data-warehouse-tables-partition.md
[Manage table statistics]: ./sql-data-warehouse-tables-statistics.md
[Temporary tables]: ./sql-data-warehouse-tables-temporary.md
[Guide for using PolyBase]: ./sql-data-warehouse-load-polybase-guide.md
[Load data]: ./sql-data-warehouse-overview-load.md
[Move data with Azure Data Factory]: ../data-factory/data-factory-azure-sql-data-warehouse-connector.md
[Load data with Azure Data Factory]: ./sql-data-warehouse-get-started-load-with-azure-data-factory.md
[Load data with bcp]: ./sql-data-warehouse-load-with-bcp.md
[Load data with PolyBase]: ./sql-data-warehouse-get-started-load-with-polybase.md
[Monitor your workload using DMVs]: ./sql-data-warehouse-manage-monitor.md
[Pause compute resources]: ./sql-data-warehouse-manage-compute-overview.md#pause-compute-bk
[Resume compute resources]: ./sql-data-warehouse-manage-compute-overview.md#resume-compute-bk
<span data-ttu-id="3a04c-257">[İşlem kaynaklarını ölçeklendirme]: ./sql-data-warehouse-manage-compute-overview.md#scale-compute</span><span class="sxs-lookup"><span data-stu-id="3a04c-257">[Scale compute resources]: ./sql-data-warehouse-manage-compute-overview.md#scale-compute</span></span>
[Understanding transactions]: ./sql-data-warehouse-develop-transactions.md
[Optimizing transactions]: ./sql-data-warehouse-develop-best-practices-transactions.md
[Troubleshooting]: ./sql-data-warehouse-troubleshoot.md
[LABEL]: ./sql-data-warehouse-develop-label.md

<!--MSDN references-->
[ALTER TABLE]: https://msdn.microsoft.com/library/ms190273.aspx
[CREATE EXTERNAL FILE FORMAT]: https://msdn.microsoft.com/library/dn935026.aspx
[CREATE STATISTICS]: https://msdn.microsoft.com/library/ms188038.aspx
[CREATE TABLE]: https://msdn.microsoft.com/library/mt203953.aspx
[CREATE TABLE AS SELECT]: https://msdn.microsoft.com/library/mt204041.aspx
[DBCC PDW_SHOWEXECUTIONPLAN]: https://msdn.microsoft.com/library/mt204017.aspx
[INSERT]: https://msdn.microsoft.com/library/ms174335.aspx
[OPTION]: https://msdn.microsoft.com/library/ms190322.aspx
[TRUNCATE TABLE]: https://msdn.microsoft.com/library/ms177570.aspx
[UPDATE STATISTICS]: https://msdn.microsoft.com/library/ms187348.aspx
[sys.dm_exec_sessions]: https://msdn.microsoft.com/library/ms176013.aspx
[sys.dm_pdw_exec_requests]: https://msdn.microsoft.com/library/mt203887.aspx
[sys.dm_pdw_request_steps]: https://msdn.microsoft.com/library/mt203913.aspx
[sys.dm_pdw_sql_requests]: https://msdn.microsoft.com/library/mt203889.aspx
<span data-ttu-id="3a04c-258">[sys.dm_pdw_dms_workers]: https://msdn.microsoft.com/library/mt203878.aspx</span><span class="sxs-lookup"><span data-stu-id="3a04c-258">[sys.dm_pdw_dms_workers]: https://msdn.microsoft.com/library/mt203878.aspx</span></span>
[sys.dm_pdw_waits]: https://msdn.microsoft.com/library/mt203893.aspx
[Columnstore indexes guide]: https://msdn.microsoft.com/library/gg492088.aspx

<!--Other Web references-->
[Selecting table distribution]: https://blogs.msdn.microsoft.com/sqlcat/2015/08/11/choosing-hash-distributed-table-vs-round-robin-distributed-table-in-azure-sql-dw-service/
[Azure SQL Data Warehouse Feedback]: https://feedback.azure.com/forums/307516-sql-data-warehouse
[Azure SQL Data Warehouse MSDN Forum]: https://social.msdn.microsoft.com/Forums/sqlserver/home?forum=AzureSQLDataWarehouse
[Azure SQL Data Warehouse Stack Overflow Forum]:  http://stackoverflow.com/questions/tagged/azure-sqldw
[Azure SQL Data Warehouse loading patterns and strategies]: https://blogs.msdn.microsoft.com/sqlcat/2016/02/06/azure-sql-data-warehouse-loading-patterns-and-strategies
