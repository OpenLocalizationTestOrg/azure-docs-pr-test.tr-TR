---
title: "Merhaba takım veri bilimi işlemi aaaFeature seçimde | Microsoft Docs"
description: "Özellik Seçimi Hello amacını açıklayan ve machine learning hello veri geliştirme sürecinin içindeki rollerine örnekler sağlar."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 878541f5-1df8-4368-889a-ced6852aba47
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/24/2017
ms.author: zhangya;bradsev
ms.openlocfilehash: 54af93c83e4cc6a3670b3ad62490e0f74082b4ee
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: tr-TR
ms.lasthandoff: 10/06/2017
---
# <a name="feature-selection-in-hello-team-data-science-process-tdsp"></a><span data-ttu-id="f9fcd-103">Özellik Seçimi'nde hello takım veri bilimi işlem (TDSP)</span><span class="sxs-lookup"><span data-stu-id="f9fcd-103">Feature selection in hello Team Data Science Process (TDSP)</span></span>
<span data-ttu-id="f9fcd-104">Bu makalede özellik seçimi hello amaçları açıklar ve makine öğrenme hello veri geliştirme sürecinde rolü örnekleri sağlar.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-104">This article explains hello purposes of feature selection and provides examples of its role in hello data enhancement process of machine learning.</span></span> <span data-ttu-id="f9fcd-105">Bu örnekler, Azure Machine Learning Studio'dan çizilir.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-105">These examples are drawn from Azure Machine Learning Studio.</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="f9fcd-106">Mühendislik hello ve çeşitli özellikler hello takım veri bilimi işlem (TDSP) özetlenen bir parçası olan [hello takım veri bilimi işlemi nedir?](data-science-process-overview.md).</span><span class="sxs-lookup"><span data-stu-id="f9fcd-106">hello engineering and selection of features is one part of hello Team Data Science Process (TDSP) outlined in [What is hello Team Data Science Process?](data-science-process-overview.md).</span></span> <span data-ttu-id="f9fcd-107">Özellik Mühendisliği ve seçim olan hello bölümlerini **geliştirmek özellikleri** hello TDSP adımında.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-107">Feature engineering and selection are parts of hello **Develop features** step of hello TDSP.</span></span>

* <span data-ttu-id="f9fcd-108">**özellik Mühendisliği**: Bu işlem toocreate ek ilgili özellikleri özelliklerinden hello varolan ham hello veri ve tooincrease Tahmine dayalı güç toohello öğrenme algoritmasını çalışır.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-108">**feature engineering**: This process attempts toocreate additional relevant features from hello existing raw features in hello data, and tooincrease predictive power toohello learning algorithm.</span></span>
* <span data-ttu-id="f9fcd-109">**Özellik Seçimi**: Bu işlem bir girişim tooreduce hello boyut hello eğitim sorununun içinde hello anahtar özelliklerin alt kümesini özgün veri seçer.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-109">**feature selection**: This process selects hello key subset of original data features in an attempt tooreduce hello dimensionality of hello training problem.</span></span>

<span data-ttu-id="f9fcd-110">Normalde **özellik Mühendisliği** uygulanan ilk toogenerate ek özellikler ve hello **özellik seçimi** adımdır gerçekleştirilen tooeliminate ilgisiz, artık ya da son derece bağıntılı Özellikler.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-110">Normally **feature engineering** is applied first toogenerate additional features, and then hello **feature selection** step is performed tooeliminate irrelevant, redundant, or highly correlated features.</span></span>

## <a name="filtering-features-from-your-data---feature-selection"></a><span data-ttu-id="f9fcd-111">Verilerinizden - özellik seçimi filtreleme özellikleri</span><span class="sxs-lookup"><span data-stu-id="f9fcd-111">Filtering Features from Your Data - Feature Selection</span></span>
<span data-ttu-id="f9fcd-112">Özellik Seçimi sınıflandırma veya regresyon görevler gibi Tahmine dayalı modelleme görevleri için eğitim veri kümesi hello yapımı için yaygın olarak uygulanan bir işlemdir.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-112">Feature selection is a process that is commonly applied for hello construction of training datasets for predictive modeling tasks such as classification or regression tasks.</span></span> <span data-ttu-id="f9fcd-113">Merhaba, tooselect hello verilerde özellikleri toorepresent hello maksimum farkı en az sayıda kullanarak boyutlarıyla azaltın hello özelliklerinin hello özgün veri kümesinden bir alt kümesi hedeftir.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-113">hello goal is tooselect a subset of hello features from hello original dataset that reduce its dimensions by using a minimal set of features toorepresent hello maximum amount of variance in hello data.</span></span> <span data-ttu-id="f9fcd-114">Bu alt özellikler kümesidir, ardından tootrain hello modeli hello yalnızca özellikleri toobe dahil.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-114">This subset of features are, then, hello only features toobe included tootrain hello model.</span></span> <span data-ttu-id="f9fcd-115">Özellik Seçimi iki ana amaca hizmet eder.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-115">Feature selection serves two main purposes.</span></span>

* <span data-ttu-id="f9fcd-116">İlk olarak, özellik seçimi sıklıkla ortadan kaldırarak ilgisiz, yedekli sınıflandırma doğruluğu artırır veya özellikleri son derece bağıntılı.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-116">First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</span></span>
* <span data-ttu-id="f9fcd-117">İkinci olarak, hello model Eğitim işlemini daha verimli hale getirir özellikleri sayısı azalır.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-117">Second, it decreases hello number of features which makes model training process more efficient.</span></span> <span data-ttu-id="f9fcd-118">Bu destek vektör makineleri gibi pahalı tootrain olan öğrencileriyle için özellikle önemlidir.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-118">This is particularly important for learners that are expensive tootrain such as support vector machines.</span></span>

<span data-ttu-id="f9fcd-119">Özellik Seçimi tooreduce hello birçok özellik hello kullanılan dataset tootrain hello modelinde arama olsa da, genellikle başvurulan tooby hello terimi "boyut azaltma" değil.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-119">Although feature selection does seek tooreduce hello number of features in hello dataset used tootrain hello model, it is not usually referred tooby hello term "dimensionality reduction".</span></span> <span data-ttu-id="f9fcd-120">Özellik Seçimi yöntemleri, bunları değiştirmeden hello verilerdeki özgün özelliklerinin bir kısmı ayıklayın.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-120">Feature selection methods extract a subset of original features in hello data without changing them.</span></span>  <span data-ttu-id="f9fcd-121">Boyut azaltma yöntemleri hello özgün özellikler dönüştürmek ve bu nedenle bunlarda değişiklik tasarlanan özellikleri kullanın.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-121">Dimensionality reduction methods employ engineered features that can transform hello original features and thus modify them.</span></span> <span data-ttu-id="f9fcd-122">Asıl bileşen analiz, kurallı bağıntı analiz ve tekil değer ayrıştırma boyut azaltma yöntemler örnekleridir.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-122">Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</span></span>

<span data-ttu-id="f9fcd-123">Diğerleriyle birlikte, yaygın olarak uygulanan bir kategori denetimli bağlamda özellik seçimi yöntemlerin "dayalı filtre özellik seçimi" adı verilir.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-123">Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</span></span> <span data-ttu-id="f9fcd-124">Her özellik ve hello target özniteliği arasında Hello bağıntı değerlendirerek istatistiksel ölçü tooassign bir puan tooeach özelliği bu yöntemleri uygulayın.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-124">By evaluating hello correlation between each feature and hello target attribute, these methods apply a statistical measure tooassign a score tooeach feature.</span></span> <span data-ttu-id="f9fcd-125">Merhaba özellikleri sonra tutma veya belirli bir özellik ortadan kaldırmak için kullanılan toohelp ayarlanan hello eşiği olabilir hello puana göre sıralanır.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-125">hello features are then ranked by hello score, which may be used toohelp set hello threshold for keeping or eliminating a specific feature.</span></span> <span data-ttu-id="f9fcd-126">Kişi bağıntı, karşılıklı bilgileri ve hello Şi squared test hello istatistiksel ölçümler bu yöntemlerinde kullanılan örneklerindendir.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-126">Examples of hello statistical measures used in these methods include Person correlation, mutual information, and hello Chi squared test.</span></span>

<span data-ttu-id="f9fcd-127">Azure Machine Learning Studio'daki modüller için özellik seçimi sağlanan vardır.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-127">In Azure Machine Learning Studio, there are modules provided for feature selection.</span></span> <span data-ttu-id="f9fcd-128">Hello aşağıdaki şekilde gösterildiği gibi bu modülleri dahil [filtre tabanlı özellik seçimi] [ filter-based-feature-selection] ve [Fisher doğrusal Discriminant analiz] [ fisher-linear-discriminant-analysis].</span><span class="sxs-lookup"><span data-stu-id="f9fcd-128">As shown in hello following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</span></span>

![Özellik Seçimi örneği](./media/machine-learning-data-science-select-features/feature-Selection.png)

<span data-ttu-id="f9fcd-130">Örneğin, hello hello kullanımını göz önünde bulundurun [filtre tabanlı özellik seçimi] [ filter-based-feature-selection] modülü.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-130">Consider, for example, hello use of hello [Filter-Based Feature Selection][filter-based-feature-selection] module.</span></span> <span data-ttu-id="f9fcd-131">Kolaylık Hello amaçla toouse hello metni araştırma örneği yukarıda özetlenen devam ediyoruz.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-131">For hello purpose of convenience, we continue toouse hello text mining example outlined above.</span></span> <span data-ttu-id="f9fcd-132">Biz 256 özellikler kümesi sonra bir regresyon modeli hello oluşturulan toobuild istediğinizi varsayalım [özellik karma] [ feature-hashing] modülü ve bu hello yanıt değişken hello "Col1" ve kitap temsil eder 1 too5 arasında değişen derecelendirmelerini gözden geçirin.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-132">Assume that we want toobuild a regression model after a set of 256 features are created through hello [Feature Hashing][feature-hashing] module, and that hello response variable is hello "Col1" and represents a book review ratings ranging from 1 too5.</span></span> <span data-ttu-id="f9fcd-133">"Özellik yöntemi Puanlama" toobe "Pearson bağıntı" ayarlayarak, "Hedef sütun" toobe "Col1" ve "İstenen özelliklerini sayısı" too50 hello hello.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-133">By setting "Feature scoring method" toobe "Pearson Correlation", hello "Target column" toobe "Col1", and hello "Number of desired features" too50.</span></span> <span data-ttu-id="f9fcd-134">Ardından hello Modülü [filtre tabanlı özellik seçimi] [ filter-based-feature-selection] hello target özniteliği "Col1" ile birlikte 50 özellikleri içeren bir veri kümesi oluşturur.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-134">Then hello module [Filter-Based Feature Selection][filter-based-feature-selection] will produce a dataset containing 50 features together with hello target attribute "Col1".</span></span> <span data-ttu-id="f9fcd-135">Merhaba aşağıdakileri gösterir hello akışını bu deneme şekil ve yeni tanımlanan giriş parametreleri hello.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-135">hello following figure shows hello flow of this experiment and hello input parameters we just described.</span></span>

![Özellik Seçimi örneği](./media/machine-learning-data-science-select-features/feature-Selection1.png)

<span data-ttu-id="f9fcd-137">Merhaba aşağıdaki şekilde hello ortaya çıkan veri kümeleri gösterilmektedir.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-137">hello following figure shows hello resulting datasets.</span></span> <span data-ttu-id="f9fcd-138">Her bir özelliğin hello kendisi arasında Pearson bağıntı üzerinde göre puanlanır ve hedef özniteliği "Col1" Merhaba.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-138">Each feature is scored based on hello Pearson Correlation between itself and hello target attribute "Col1".</span></span> <span data-ttu-id="f9fcd-139">üst puanları Hello özelliklerle tutulur.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-139">hello features with top scores are kept.</span></span>

![Özellik Seçimi örneği](./media/machine-learning-data-science-select-features/feature-Selection2.png)

<span data-ttu-id="f9fcd-141">Seçili hello özelliklerinin Hello karşılık gelen puanları hello aşağıdaki şekilde gösterilmiştir.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-141">hello corresponding scores of hello selected features are shown in hello following figure.</span></span>

![Özellik Seçimi örneği](./media/machine-learning-data-science-select-features/feature-Selection3.png)

<span data-ttu-id="f9fcd-143">Bu uygulama tarafından [filtre tabanlı özellik seçimi] [ filter-based-feature-selection] modülü, 50 dışında özellikleri seçili sahip hello çünkü çoğu bağıntılı özellik hello hedef değişkeni "Col1" ile 256 dayalı hello Puanlama yöntem "Pearson bağıntı".</span><span class="sxs-lookup"><span data-stu-id="f9fcd-143">By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have hello most correlated features with hello target variable "Col1", based on hello scoring method "Pearson Correlation".</span></span>

## <a name="conclusion"></a><span data-ttu-id="f9fcd-144">Sonuç</span><span class="sxs-lookup"><span data-stu-id="f9fcd-144">Conclusion</span></span>
<span data-ttu-id="f9fcd-145">Özellik Mühendisliği ve özellik seçimi iki yaygın olarak tasarlanmıştır ve seçilen özellikler tooextract hello anahtar bilgileri hello verilerde bulunan çalışır işleminin eğitim hello hello verimliliğini artırmak kümesidir.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-145">Feature engineering and feature selection are two commonly Engineered and selected features increase hello efficiency of hello training process which attempts tooextract hello key information contained in hello data.</span></span> <span data-ttu-id="f9fcd-146">Bunlar ayrıca bu modeller tooclassify hello giriş verisi hello gücünü doğru şekilde artırmak ve toopredict sonuçlarını ilgi daha fazla yerine.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-146">They also improve hello power of these models tooclassify hello input data accurately and toopredict outcomes of interest more robustly.</span></span> <span data-ttu-id="f9fcd-147">Ayrıca özellik mühendislik ve seçim toomake hello öğrenme daha pkı'ya tractable birleştirebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-147">Feature engineering and selection can also combine toomake hello learning more computationally tractable.</span></span> <span data-ttu-id="f9fcd-148">Bunu geliştirme tarafından yapar ve sonra Özellikler hello sayısının azaltılması toocalibrate veya train model gerekli.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-148">It does so by enhancing and then reducing hello number of features needed toocalibrate or train a model.</span></span> <span data-ttu-id="f9fcd-149">Matematiksel konuşarak hello özellikleri seçili tootrain hello modeli hello veri hello düzenleri açıklayabilir ve sonuçları başarıyla tahmin bağımsız değişkenlerini en az sayıda vardır.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-149">Mathematically speaking, hello features selected tootrain hello model are a minimal set of independent variables that explain hello patterns in hello data and then predict outcomes successfully.</span></span>

<span data-ttu-id="f9fcd-150">Bu her zaman mutlaka tooperform özellik Mühendisliği veya özellik seçimi olmadığını unutmayın.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-150">Note that it is not always necessarily tooperform feature engineering or feature selection.</span></span> <span data-ttu-id="f9fcd-151">Olup olmadığını veya gerekli biz sahip veya, biz çekme, hello algoritması toplamak ve hello deneme amacı hello hello verilere bağlıdır.</span><span class="sxs-lookup"><span data-stu-id="f9fcd-151">Whether it is needed or not depends on hello data we have or collect, hello algorithm we pick, and hello objective of hello experiment.</span></span>

<!-- Module References -->
[feature-hashing]: https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/
[filter-based-feature-selection]: https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/
[fisher-linear-discriminant-analysis]: https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/

