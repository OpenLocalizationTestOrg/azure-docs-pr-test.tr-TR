---
title: "Net # sinir ağları belirtimi dili Kılavuzu | Microsoft Docs"
description: "Net # kullanarak Microsoft Azure ML içinde bir özel sinir ağı model oluşturmak nasıl örnekleri ile birlikte belirtimi dili sözdizimi için Net # sinir ağları"
services: machine-learning
documentationcenter: 
author: jeannt
manager: jhubbard
editor: cgronlun
ms.assetid: cfd1454b-47df-4745-b064-ce5f9b3be303
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/31/2017
ms.author: jeannt
ms.openlocfilehash: 965c60ffde55041cc3864d06d81f5590c7ea1c11
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: tr-TR
ms.lasthandoff: 07/11/2017
---
# <a name="guide-to-net-neural-network-specification-language-for-azure-machine-learning"></a><span data-ttu-id="ae093-103">Azure Machine Learning için NET # sinir ağı belirtimi dili için kılavuz</span><span class="sxs-lookup"><span data-stu-id="ae093-103">Guide to Net# neural network specification language for Azure Machine Learning</span></span>
## <a name="overview"></a><span data-ttu-id="ae093-104">Genel Bakış</span><span class="sxs-lookup"><span data-stu-id="ae093-104">Overview</span></span>
<span data-ttu-id="ae093-105">NET # sinir ağı mimarileri tanımlamak için kullanılan Microsoft tarafından geliştirilen bir dildir.</span><span class="sxs-lookup"><span data-stu-id="ae093-105">Net# is a language developed by Microsoft that is used to define neural network architectures.</span></span> <span data-ttu-id="ae093-106">Microsoft Azure Machine Learning sinir ağı modüllerde Net # kullanabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="ae093-106">You can use Net# in neural network modules in Microsoft Azure Machine Learning.</span></span>

<!-- This function doesn't currentlyappear in the MicrosoftML documentation. If it is added in a future update, we can uncomment this text.

, or in the `rxNeuralNetwork()` function in [MicrosoftML](https://msdn.microsoft.com/microsoft-r/microsoftml/microsoftml). 

-->

<span data-ttu-id="ae093-107">Bu makalede, özel bir sinir ağı geliştirmek için gereken temel kavramlar öğreneceksiniz:</span><span class="sxs-lookup"><span data-stu-id="ae093-107">In this article, you will learn basic concepts needed to develop a custom neural network:</span></span> 

* <span data-ttu-id="ae093-108">Sinir ağı gereksinimleri ve birincil bileşenleri tanımlama</span><span class="sxs-lookup"><span data-stu-id="ae093-108">Neural network requirements and how to define the primary components</span></span>
* <span data-ttu-id="ae093-109">Net # belirtimi dili anahtar sözcüklerini ve sözdizimi</span><span class="sxs-lookup"><span data-stu-id="ae093-109">The syntax and keywords of the Net# specification language</span></span>
* <span data-ttu-id="ae093-110">Net # kullanılarak oluşturulan özel sinir ağları örnekleri</span><span class="sxs-lookup"><span data-stu-id="ae093-110">Examples of custom neural networks created using Net#</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

## <a name="neural-network-basics"></a><span data-ttu-id="ae093-111">Sinir ağı temelleri</span><span class="sxs-lookup"><span data-stu-id="ae093-111">Neural network basics</span></span>
<span data-ttu-id="ae093-112">Sinir ağı yapısı oluşan ***düğümleri*** içinde düzenlenmiş ***katmanları***ve ağırlıklı ***bağlantıları*** (veya ***kenarları***) arasında düğümleri.</span><span class="sxs-lookup"><span data-stu-id="ae093-112">A neural network structure consists of ***nodes*** that are organized in ***layers***, and weighted ***connections*** (or ***edges***) between the nodes.</span></span> <span data-ttu-id="ae093-113">Bağlantılar tek yönlü ve her bağlantısı olan bir ***kaynak*** düğümü ve ***hedef*** düğümü.</span><span class="sxs-lookup"><span data-stu-id="ae093-113">The connections are directional, and each connection has a ***source*** node and a ***destination*** node.</span></span>  

<span data-ttu-id="ae093-114">Her ***trainable katman*** (gizli veya bir çıkış katmanı) bir veya daha fazla sahip ***bağlantı paketleri***.</span><span class="sxs-lookup"><span data-stu-id="ae093-114">Each ***trainable layer*** (a hidden or an output layer) has one or more ***connection bundles***.</span></span> <span data-ttu-id="ae093-115">Bir bağlantı paket kaynak katmanı ve kaynak katman bağlantılarından belirtimini oluşur.</span><span class="sxs-lookup"><span data-stu-id="ae093-115">A connection bundle consists of a source layer and a specification of the connections from that source layer.</span></span> <span data-ttu-id="ae093-116">Belirli bir paketteki tüm bağlantıları aynı paylaşmak ***kaynak katman*** ve aynı ***hedef katman***.</span><span class="sxs-lookup"><span data-stu-id="ae093-116">All the connections in a given bundle share the same ***source layer*** and the same ***destination layer***.</span></span> <span data-ttu-id="ae093-117">NET #'ta bağlantı paket paketin hedef katmana ait olarak kabul edilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-117">In Net#, a connection bundle is considered as belonging to the bundle's destination layer.</span></span>  

<span data-ttu-id="ae093-118">NET # çeşitli şekilde girişleri özelleştirmenizi sağlar paketleri gizli katmanlara eşlenen ve çıktıları eşlenen bağlantısı destekler.</span><span class="sxs-lookup"><span data-stu-id="ae093-118">Net# supports various kinds of connection bundles, which lets you customize the way inputs are mapped to hidden layers and mapped to the outputs.</span></span>   

<span data-ttu-id="ae093-119">Varsayılan veya standart paket bir **tam paket**, hedef katmanı kümedeki her düğüm için kaynak katmandaki her düğüme bağlı olarak.</span><span class="sxs-lookup"><span data-stu-id="ae093-119">The default or standard bundle is a **full bundle**, in which each node in the source layer is connected to every node in the destination layer.</span></span>  

<span data-ttu-id="ae093-120">Ayrıca, Gelişmiş bağlantı paketleri aşağıdaki dört tür Net # destekler:</span><span class="sxs-lookup"><span data-stu-id="ae093-120">Additionally, Net# supports the following four kinds of advanced connection bundles:</span></span>  

* <span data-ttu-id="ae093-121">**Filtre paketleri**.</span><span class="sxs-lookup"><span data-stu-id="ae093-121">**Filtered bundles**.</span></span> <span data-ttu-id="ae093-122">Kullanıcı, kaynak katman ve hedef katman düğümlerini konumlarını kullanarak bir koşul tanımlayabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="ae093-122">The user can define a predicate by using the locations of the source layer node and the destination layer node.</span></span> <span data-ttu-id="ae093-123">Koşul True olduğunda düğümleri bağlanır.</span><span class="sxs-lookup"><span data-stu-id="ae093-123">Nodes are connected whenever the predicate is True.</span></span>
* <span data-ttu-id="ae093-124">**Convolutional paketleri**.</span><span class="sxs-lookup"><span data-stu-id="ae093-124">**Convolutional bundles**.</span></span> <span data-ttu-id="ae093-125">Kullanıcı düğümlerinin küçük Semt kaynak katmanda tanımlayabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="ae093-125">The user can define small neighborhoods of nodes in the source layer.</span></span> <span data-ttu-id="ae093-126">Hedef katmanı içindeki her bir düğümün bir Komşuları kaynak katmandaki düğümlerinin bağlı.</span><span class="sxs-lookup"><span data-stu-id="ae093-126">Each node in the destination layer is connected to one neighborhood of nodes in the source layer.</span></span>
* <span data-ttu-id="ae093-127">**Paket havuzu** ve **yanıt normalleştirme paketleri**.</span><span class="sxs-lookup"><span data-stu-id="ae093-127">**Pooling bundles** and **Response normalization bundles**.</span></span> <span data-ttu-id="ae093-128">Kullanıcının kaynak katmanda düğümlerinin küçük Semt tanımlar, bunlar convolutional paketleri benzerdir.</span><span class="sxs-lookup"><span data-stu-id="ae093-128">These are similar to convolutional bundles in that the user defines small neighborhoods of nodes in the source layer.</span></span> <span data-ttu-id="ae093-129">Bu paketleri kenarları ağırlıkları trainable olmayan farktır.</span><span class="sxs-lookup"><span data-stu-id="ae093-129">The difference is that the weights of the edges in these bundles are not trainable.</span></span> <span data-ttu-id="ae093-130">Bunun yerine, önceden tanımlanmış bir işlev hedef düğüm değeri belirlemek için kaynak düğüm değerleri uygulanır.</span><span class="sxs-lookup"><span data-stu-id="ae093-130">Instead, a predefined function is applied to the source node values to determine the destination node value.</span></span>  

<span data-ttu-id="ae093-131">NET # sinir ağı yapısını tanımlamak için kullanarak, derin sinir ağları veya görüntü, ses veya video gibi verileri öğrenmeyi artırmak için bilinen rasgele boyutlarının convolutions gibi karmaşık yapıları tanımlamanızı mümkün kılar.</span><span class="sxs-lookup"><span data-stu-id="ae093-131">Using Net# to define the structure of a neural network makes it possible to define complex structures such as deep neural networks or convolutions of arbitrary dimensions, which are known to improve learning on data such as image, audio, or video.</span></span>  

## <a name="supported-customizations"></a><span data-ttu-id="ae093-132">Desteklenen özelleştirme</span><span class="sxs-lookup"><span data-stu-id="ae093-132">Supported customizations</span></span>
<span data-ttu-id="ae093-133">Azure Machine Learning ile oluşturduğunuz sinir ağı modelleri mimarisini Net # kullanarak kapsamlı bir şekilde özelleştirilebilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-133">The architecture of neural network models that you create in Azure Machine Learning can be extensively customized by using Net#.</span></span> <span data-ttu-id="ae093-134">Şunları yapabilirsiniz:</span><span class="sxs-lookup"><span data-stu-id="ae093-134">You can:</span></span>  

* <span data-ttu-id="ae093-135">Gizli katmanları oluşturun ve her katmandaki düğüm sayısını denetler.</span><span class="sxs-lookup"><span data-stu-id="ae093-135">Create hidden layers and control the number of nodes in each layer.</span></span>
* <span data-ttu-id="ae093-136">Nasıl birbirine bağlı olması katmanlardır belirtin.</span><span class="sxs-lookup"><span data-stu-id="ae093-136">Specify how layers are to be connected to each other.</span></span>
* <span data-ttu-id="ae093-137">Convolutions ve paket paylaşımı ağırlık gibi özel bağlantı yapılarını tanımlar.</span><span class="sxs-lookup"><span data-stu-id="ae093-137">Define special connectivity structures, such as convolutions and weight sharing bundles.</span></span>
* <span data-ttu-id="ae093-138">Başka bir etkinleştirme işlevleri belirtin.</span><span class="sxs-lookup"><span data-stu-id="ae093-138">Specify different activation functions.</span></span>  

<span data-ttu-id="ae093-139">Belirtimi dili sözdizimi Ayrıntılar için bkz [yapısı belirtimi](#Structure-specifications).</span><span class="sxs-lookup"><span data-stu-id="ae093-139">For details of the specification language syntax, see [Structure Specification](#Structure-specifications).</span></span>  

<span data-ttu-id="ae093-140">Karmaşık için tek yönlü görevlerden öğrenme bazı ortak makine sinir ağları tanımlayan örnekler için bkz: [örnekleri](#Examples-of-Net#-usage).</span><span class="sxs-lookup"><span data-stu-id="ae093-140">For examples of defining neural networks for some common machine learning tasks, from simplex to complex, see [Examples](#Examples-of-Net#-usage).</span></span>  

## <a name="general-requirements"></a><span data-ttu-id="ae093-141">Genel gereksinimler</span><span class="sxs-lookup"><span data-stu-id="ae093-141">General requirements</span></span>
* <span data-ttu-id="ae093-142">Tam olarak bir çıkış katman, en az bir giriş katman ve sıfır veya daha çok gizli katmanları olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-142">There must be exactly one output layer, at least one input layer, and zero or more hidden layers.</span></span> 
* <span data-ttu-id="ae093-143">Her katman rasgele boyutları dikdörtgen bir dizi kavramsal olarak düzenlenmiş düğümler, sabit bir sayısına sahip.</span><span class="sxs-lookup"><span data-stu-id="ae093-143">Each layer has a fixed number of nodes, conceptually arranged in a rectangular array of arbitrary dimensions.</span></span> 
* <span data-ttu-id="ae093-144">Giriş Katmanlar ilişkili eğitilen parametresi olmayan ve burada örnek verilerini ağ girer noktasını temsil eder.</span><span class="sxs-lookup"><span data-stu-id="ae093-144">Input layers have no associated trained parameters and represent the point where instance data enters the network.</span></span> 
* <span data-ttu-id="ae093-145">Trainable Katmanlar (gizli ve çıkış katmanları) ağırlıkları ve stratejimizdeki bilinen eğitilen parametreler ilişkilendirdiniz.</span><span class="sxs-lookup"><span data-stu-id="ae093-145">Trainable layers (the hidden and output layers) have associated trained parameters, known as weights and biases.</span></span> 
* <span data-ttu-id="ae093-146">Kaynak ve hedef düğümleri ayrı katmanda olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-146">The source and destination nodes must be in separate layers.</span></span> 
* <span data-ttu-id="ae093-147">Bağlantıları Çevrimsiz olmalıdır; diğer bir deyişle, ilk kaynak düğüme geri önde gelen bağlantılar zinciri olamaz.</span><span class="sxs-lookup"><span data-stu-id="ae093-147">Connections must be acyclic; in other words, there cannot be a chain of connections leading back to the initial source node.</span></span>
* <span data-ttu-id="ae093-148">Çıktı katman bir bağlantı paketin kaynak katmanı olamaz.</span><span class="sxs-lookup"><span data-stu-id="ae093-148">The output layer cannot be a source layer of a connection bundle.</span></span>  

## <a name="structure-specifications"></a><span data-ttu-id="ae093-149">Yapı belirtimleri</span><span class="sxs-lookup"><span data-stu-id="ae093-149">Structure specifications</span></span>
<span data-ttu-id="ae093-150">Sinir ağı yapısı belirtimi üç bölümlerini oluşur: **Sabit bildiriminde**, **katman bildirimi**, **bağlantı bildirimi**.</span><span class="sxs-lookup"><span data-stu-id="ae093-150">A neural network structure specification is composed of three sections: the **constant declaration**, the **layer declaration**, the **connection declaration**.</span></span> <span data-ttu-id="ae093-151">Ayrıca vardır isteğe bağlı bir **paylaşmak bildirimi** bölümü.</span><span class="sxs-lookup"><span data-stu-id="ae093-151">There is also an optional **share declaration** section.</span></span> <span data-ttu-id="ae093-152">Bölümler herhangi bir sırada belirtilebilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-152">The sections can be specified in any order.</span></span>  

## <a name="constant-declaration"></a><span data-ttu-id="ae093-153">Sabit bildirimi</span><span class="sxs-lookup"><span data-stu-id="ae093-153">Constant declaration</span></span>
<span data-ttu-id="ae093-154">Sabit bildiriminde isteğe bağlıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-154">A constant declaration is optional.</span></span> <span data-ttu-id="ae093-155">Sinir ağı tanımı'nda başka bir yerde kullanılan değerleri tanımlamak için bir yol sağlar.</span><span class="sxs-lookup"><span data-stu-id="ae093-155">It provides a means to define values used elsewhere in the neural network definition.</span></span> <span data-ttu-id="ae093-156">Ardından bir eşittir işareti ve değer ifadesi bir tanımlayıcı, bildirim deyiminin oluşur.</span><span class="sxs-lookup"><span data-stu-id="ae093-156">The declaration statement consists of an identifier followed by an equal sign and a value expression.</span></span>   

<span data-ttu-id="ae093-157">Örneğin, bir sabit aşağıdaki ifadeyi tanımlar **x**:</span><span class="sxs-lookup"><span data-stu-id="ae093-157">For example, the following statement defines a constant **x**:</span></span>  

    Const X = 28;  

<span data-ttu-id="ae093-158">İki veya daha fazla sabitleri eşzamanlı olarak tanımlamak için tanımlayıcı adları ve değerleri ayraç içine alın ve bunları noktalı virgülle ayırın.</span><span class="sxs-lookup"><span data-stu-id="ae093-158">To define two or more constants simultaneously, enclose the identifier names and values in braces, and separate them by using semicolons.</span></span> <span data-ttu-id="ae093-159">Örneğin:</span><span class="sxs-lookup"><span data-stu-id="ae093-159">For example:</span></span>  

    Const { X = 28; Y = 4; }  

<span data-ttu-id="ae093-160">Her atama ifadesi sağ tarafında, tamsayı, gerçek bir sayı, bir Boole değeri (True veya False) veya bir matematik ifadesindeki olabilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-160">The right-hand side of each assignment expression can be an integer, a real number, a Boolean value (True or False), or a mathematical expression.</span></span> <span data-ttu-id="ae093-161">Örneğin:</span><span class="sxs-lookup"><span data-stu-id="ae093-161">For example:</span></span>  

    Const { X = 17 * 2; Y = true; }  

## <a name="layer-declaration"></a><span data-ttu-id="ae093-162">Katman bildirimi</span><span class="sxs-lookup"><span data-stu-id="ae093-162">Layer declaration</span></span>
<span data-ttu-id="ae093-163">Katman bildirimi gereklidir.</span><span class="sxs-lookup"><span data-stu-id="ae093-163">The layer declaration is required.</span></span> <span data-ttu-id="ae093-164">Boyut ve kaynak öznitelikleri ve bağlantı paketleri de dahil olmak üzere bu katmanın tanımlar.</span><span class="sxs-lookup"><span data-stu-id="ae093-164">It defines the size and source of the layer, including its connection bundles and attributes.</span></span> <span data-ttu-id="ae093-165">Bildirim deyiminin (giriş, gizli veya çıktı) katman adı ile başlar (pozitif tamsayılar tuple) katman boyutları tarafından izlenen.</span><span class="sxs-lookup"><span data-stu-id="ae093-165">The declaration statement starts with the name of the layer (input, hidden, or output), followed by the dimensions of the layer (a tuple of positive integers).</span></span> <span data-ttu-id="ae093-166">Örneğin:</span><span class="sxs-lookup"><span data-stu-id="ae093-166">For example:</span></span>  

    input Data auto;
    hidden Hidden[5,20] from Data all;
    output Result[2] from Hidden all;  

* <span data-ttu-id="ae093-167">Katmandaki düğüm sayısını boyutları ürünüdür.</span><span class="sxs-lookup"><span data-stu-id="ae093-167">The product of the dimensions is the number of nodes in the layer.</span></span> <span data-ttu-id="ae093-168">Bu örnekte, katmanda 100 düğümleri olduğu anlamına gelir iki boyut [5,20] vardır.</span><span class="sxs-lookup"><span data-stu-id="ae093-168">In this example, there are two dimensions [5,20], which means there are  100 nodes in the layer.</span></span>
* <span data-ttu-id="ae093-169">Bir istisna dışında herhangi bir sırada katmanları bildirilebilir: birden fazla giriş katman tanımlanmış olması durumunda, bunlar bildirilen giriş verilerini özelliklerinde sırasını eşleşmesi gerekir.</span><span class="sxs-lookup"><span data-stu-id="ae093-169">The layers can be declared in any order, with one exception: If more than one input layer is defined, the order in which they are declared must match the order of features in the input data.</span></span>  

<span data-ttu-id="ae093-170">Katmandaki düğüm sayısını otomatik olarak belirlenmesi belirtmek için kullanın **otomatik** anahtar sözcüğü.</span><span class="sxs-lookup"><span data-stu-id="ae093-170">To specify that the number of nodes in a layer be determined automatically, use the **auto** keyword.</span></span> <span data-ttu-id="ae093-171">**Otomatik** anahtar sözcüğü katman bağlı olarak farklı efektler vardır:</span><span class="sxs-lookup"><span data-stu-id="ae093-171">The **auto** keyword has different effects, depending on the layer:</span></span>  

* <span data-ttu-id="ae093-172">Bir giriş katman bildiriminde düğüm sayısını giriş verilerini özelliklerinde sayısıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-172">In an input layer declaration, the number of nodes is the number of features in the input data.</span></span>
* <span data-ttu-id="ae093-173">Gizli Katman bildiriminde düğümleri sayısı için parametre değeri tarafından belirtilen sayıdır **gizli düğüm sayısını**.</span><span class="sxs-lookup"><span data-stu-id="ae093-173">In a hidden layer declaration, the number of nodes is the number that is specified by the parameter value for **Number of hidden nodes**.</span></span> 
* <span data-ttu-id="ae093-174">Bir çıkış katman bildiriminde düğüm sayısını iki sınıflı Sınıflandırma, regresyon ve çok sınıflı sınıflandırma için çıktı düğüm sayısına eşittir 1 için 2'dir.</span><span class="sxs-lookup"><span data-stu-id="ae093-174">In an output layer declaration, the number of nodes is 2 for two-class classification, 1 for regression, and equal to the number of output nodes for multiclass classification.</span></span>   

<span data-ttu-id="ae093-175">Örneğin, aşağıdaki ağ tanımını otomatik olarak belirlenmesi için tüm katmanlar boyutunu sağlar:</span><span class="sxs-lookup"><span data-stu-id="ae093-175">For example, the following network definition allows the size of all layers to be automatically determined:</span></span>  

    input Data auto;
    hidden Hidden auto from Data all;
    output Result auto from Hidden all;  


<span data-ttu-id="ae093-176">Bir katman bildirimi trainable katman (gizli veya çıkış katmanları) için isteğe bağlı olarak varsayılan olarak (bir etkinleştirme işlevi olarak da bilinir) çıktı işlevini içerebilir **sigmoid** sınıflandırma modelleri için ve  **Doğrusal** regresyon modelleri için.</span><span class="sxs-lookup"><span data-stu-id="ae093-176">A layer declaration for a trainable layer (the hidden or output layers) can optionally include the output function (also called an activation function), which defaults to **sigmoid** for classification models, and **linear** for regression models.</span></span> <span data-ttu-id="ae093-177">(Varsayılan kullansanız bile, açıkça etkinleştirme işlevi daha anlaşılır olması için isterseniz durumunu.)</span><span class="sxs-lookup"><span data-stu-id="ae093-177">(Even if you use the default, you can explicitly state the activation function, if desired for clarity.)</span></span>

<span data-ttu-id="ae093-178">Aşağıdaki çıkış işlevleri desteklenir:</span><span class="sxs-lookup"><span data-stu-id="ae093-178">The following output functions are supported:</span></span>  

* <span data-ttu-id="ae093-179">sigmoid</span><span class="sxs-lookup"><span data-stu-id="ae093-179">sigmoid</span></span>
* <span data-ttu-id="ae093-180">Doğrusal</span><span class="sxs-lookup"><span data-stu-id="ae093-180">linear</span></span>
* <span data-ttu-id="ae093-181">softmax</span><span class="sxs-lookup"><span data-stu-id="ae093-181">softmax</span></span>
* <span data-ttu-id="ae093-182">rlinear</span><span class="sxs-lookup"><span data-stu-id="ae093-182">rlinear</span></span>
* <span data-ttu-id="ae093-183">Kare</span><span class="sxs-lookup"><span data-stu-id="ae093-183">square</span></span>
* <span data-ttu-id="ae093-184">Sqrt</span><span class="sxs-lookup"><span data-stu-id="ae093-184">sqrt</span></span>
* <span data-ttu-id="ae093-185">srlinear</span><span class="sxs-lookup"><span data-stu-id="ae093-185">srlinear</span></span>
* <span data-ttu-id="ae093-186">Abs</span><span class="sxs-lookup"><span data-stu-id="ae093-186">abs</span></span>
* <span data-ttu-id="ae093-187">TANH</span><span class="sxs-lookup"><span data-stu-id="ae093-187">tanh</span></span> 
* <span data-ttu-id="ae093-188">brlinear</span><span class="sxs-lookup"><span data-stu-id="ae093-188">brlinear</span></span>  

<span data-ttu-id="ae093-189">Örneğin, aşağıdaki bildirimini kullanır **softmax** işlevi:</span><span class="sxs-lookup"><span data-stu-id="ae093-189">For example, the following declaration uses the **softmax** function:</span></span>  

    output Result [100] softmax from Hidden all;  

## <a name="connection-declaration"></a><span data-ttu-id="ae093-190">Bağlantı bildirimi</span><span class="sxs-lookup"><span data-stu-id="ae093-190">Connection declaration</span></span>
<span data-ttu-id="ae093-191">Hemen trainable katman tanımladıktan sonra tanımladığınız katmanlar arasında bağlantı bildirmeniz gerekir.</span><span class="sxs-lookup"><span data-stu-id="ae093-191">Immediately after defining the trainable layer, you must declare connections among the layers you have defined.</span></span> <span data-ttu-id="ae093-192">Bağlantı paket bildirimi anahtar sözcüğüyle başlar **gelen**, paketin kaynak katman ve bağlantı paket oluşturmak için tür adının ardından.</span><span class="sxs-lookup"><span data-stu-id="ae093-192">The connection bundle declaration starts with the keyword **from**, followed by the name of the bundle's source layer and the kind of connection bundle to create.</span></span>   

<span data-ttu-id="ae093-193">Şu anda beş bağlantı paket türleri desteklenir:</span><span class="sxs-lookup"><span data-stu-id="ae093-193">Currently, five kinds of connection bundles are supported:</span></span>  

* <span data-ttu-id="ae093-194">**Tam** anahtar sözcüğüyle belirtilen paket, **tüm**</span><span class="sxs-lookup"><span data-stu-id="ae093-194">**Full** bundles, indicated by the keyword **all**</span></span>
* <span data-ttu-id="ae093-195">**Filtre** anahtar sözcüğüyle belirtilen paket, **burada**takip eden bir koşul ifadesi</span><span class="sxs-lookup"><span data-stu-id="ae093-195">**Filtered** bundles, indicated by the keyword **where**, followed by a predicate expression</span></span>
* <span data-ttu-id="ae093-196">**Convolutional** anahtar sözcüğüyle belirtilen paket, **convolve**, ardından evrişim öznitelikleri</span><span class="sxs-lookup"><span data-stu-id="ae093-196">**Convolutional** bundles, indicated by the keyword **convolve**, followed by the convolution attributes</span></span>
* <span data-ttu-id="ae093-197">**Havuzu** anahtar sözcükleri belirtilen paket, **en büyük havuz** veya **havuzu anlama**</span><span class="sxs-lookup"><span data-stu-id="ae093-197">**Pooling** bundles, indicated by the keywords **max pool** or **mean pool**</span></span>
* <span data-ttu-id="ae093-198">**Yanıt normalleştirme** anahtar sözcüğüyle belirtilen paket, **yanıt norm**</span><span class="sxs-lookup"><span data-stu-id="ae093-198">**Response normalization** bundles, indicated by the keyword **response norm**</span></span>      

## <a name="full-bundles"></a><span data-ttu-id="ae093-199">Tam paketleri</span><span class="sxs-lookup"><span data-stu-id="ae093-199">Full bundles</span></span>
<span data-ttu-id="ae093-200">Bir tam bağlantı paket Hedef katmanı her düğüme kaynak katmanda her düğümden bir bağlantı içerir.</span><span class="sxs-lookup"><span data-stu-id="ae093-200">A full connection bundle includes a connection from each node in the source layer to each node in the destination layer.</span></span> <span data-ttu-id="ae093-201">Varsayılan ağ bağlantısı türü budur.</span><span class="sxs-lookup"><span data-stu-id="ae093-201">This is the default network connection type.</span></span>  

## <a name="filtered-bundles"></a><span data-ttu-id="ae093-202">Filtrelenmiş paketler</span><span class="sxs-lookup"><span data-stu-id="ae093-202">Filtered bundles</span></span>
<span data-ttu-id="ae093-203">Filtrelenmiş bağlantıda paket belirtimi, C# lambda ifadesi gibi koşul, ifade edilen sözdizimsel olarak, çok içerir.</span><span class="sxs-lookup"><span data-stu-id="ae093-203">A filtered connection bundle specification includes a predicate, expressed syntactically, much like a C# lambda expression.</span></span> <span data-ttu-id="ae093-204">Aşağıdaki örnek, iki filtrelenmiş paketler tanımlar:</span><span class="sxs-lookup"><span data-stu-id="ae093-204">The following example defines two filtered bundles:</span></span>  

    input Pixels [10, 20];
    hidden ByRow[10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol[5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;  

* <span data-ttu-id="ae093-205">İçin koşulunda *ByRow*, **s** dizin giriş katman düğümlerinin dikdörtgen diziye temsil eden bir parametre *piksel*, ve **d** dizin gizli katmanın düğümlerinin diziye temsil eden bir parametre *ByRow*.</span><span class="sxs-lookup"><span data-stu-id="ae093-205">In the predicate for *ByRow*, **s** is a parameter representing an index into the rectangular array of nodes of the input layer, *Pixels*, and **d** is a parameter representing an index into the array of nodes of the hidden layer, *ByRow*.</span></span> <span data-ttu-id="ae093-206">Her ikisi de türünü **s** ve **d** iki uzunluğu tamsayıların bir tanımlama grubu değil.</span><span class="sxs-lookup"><span data-stu-id="ae093-206">The type of both **s** and **d** is a tuple of integers of length two.</span></span> <span data-ttu-id="ae093-207">Kavramsal olarak, **s** aralıkları ile tamsayıların tüm çiftleri üzerinden *0 < = s [0] < 10* ve *0 < = s[1] < 20*, ve **d**  ile tamsayılar, tüm çiftlerini aralıkları *0 < = [0] d < 10* ve *0 < = d[1] < 12*.</span><span class="sxs-lookup"><span data-stu-id="ae093-207">Conceptually, **s** ranges over all pairs of integers with *0 <= s[0] < 10* and *0 <= s[1] < 20*, and **d** ranges over all pairs of integers, with *0 <= d[0] < 10* and *0 <= d[1] < 12*.</span></span> 
* <span data-ttu-id="ae093-208">Koşul ifadesi sağ tarafta bir koşulu yoktur.</span><span class="sxs-lookup"><span data-stu-id="ae093-208">On the right-hand side of the predicate expression, there is a condition.</span></span> <span data-ttu-id="ae093-209">Bu örnekte, her değeri için **s** ve **d** koşul True olacak şekilde, kaynak katman düğümünden kenar hedef katman düğümüne yoktur.</span><span class="sxs-lookup"><span data-stu-id="ae093-209">In this example, for every value of **s** and **d** such that the condition is True, there is an edge from the source layer node to the destination layer node.</span></span> <span data-ttu-id="ae093-210">Bu nedenle, bu filtre ifadesi paket bağlantı tarafından tanımlanan düğümünden içerdiğini gösterir **s** tarafından tanımlanan düğüme **d** burada s [0], [0] d eşit tüm durumlarda.</span><span class="sxs-lookup"><span data-stu-id="ae093-210">Thus, this filter expression indicates that the bundle includes a connection from the node defined by **s** to the node defined by **d** in all cases where s[0] is equal to d[0].</span></span>  

<span data-ttu-id="ae093-211">İsteğe bağlı olarak, ağırlıkları filtre uygulanmış bir paket için bir dizi belirtebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="ae093-211">Optionally, you can specify a set of weights for a filtered bundle.</span></span> <span data-ttu-id="ae093-212">Değeri **ağırlıkları** özniteliği, kayan nokta değerlerine paket tarafından tanımlanan bağlantı sayısı ile eşleşen bir uzunluğa sahip bir tanımlama grubu olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-212">The value for the **Weights** attribute must be a tuple of floating point values with a length that matches the number of connections defined by the bundle.</span></span> <span data-ttu-id="ae093-213">Varsayılan olarak, ağırlıkları rastgele üretilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-213">By default, weights are randomly generated.</span></span>  

<span data-ttu-id="ae093-214">Ağırlık değerleri hedef düğüm dizine göre gruplandırılır.</span><span class="sxs-lookup"><span data-stu-id="ae093-214">Weight values are grouped by the destination node index.</span></span> <span data-ttu-id="ae093-215">Diğer bir deyişle, ilk hedef düğüm K kaynak düğümlerine bağlıysa ilk *K* öğeleri **ağırlıkları** tanımlama grubu olan ilk hedef düğüm, kaynak dizin sırasını ağırlıkları.</span><span class="sxs-lookup"><span data-stu-id="ae093-215">That is, if the first destination node is connected to K source nodes, the first *K* elements of the **Weights** tuple are the weights for the first destination node, in source index order.</span></span> <span data-ttu-id="ae093-216">Aynı kalan hedef düğümleri için geçerlidir.</span><span class="sxs-lookup"><span data-stu-id="ae093-216">The same applies for the remaining destination nodes.</span></span>  

<span data-ttu-id="ae093-217">Ağırlıkları doğrudan sabit değer olarak belirtmek mümkündür.</span><span class="sxs-lookup"><span data-stu-id="ae093-217">It's possible to specify weights directly as constant values.</span></span> <span data-ttu-id="ae093-218">Örneğin, ağırlıkları önceden öğrenilen varsa, bunları bu söz dizimini kullanarak sabitleri belirtebilirsiniz:</span><span class="sxs-lookup"><span data-stu-id="ae093-218">For example, if you learned the weights previously, you can specify them as constants using this syntax:</span></span>

    const Weights_1 = [0.0188045055, 0.130500451, ...]


## <a name="convolutional-bundles"></a><span data-ttu-id="ae093-219">Convolutional paketleri</span><span class="sxs-lookup"><span data-stu-id="ae093-219">Convolutional bundles</span></span>
<span data-ttu-id="ae093-220">Eğitim verileri homojen bir yapıya sahip olduğunda, convolutional bağlantıları verileri üst düzey özelliklerini öğrenmek için yaygın olarak kullanılır.</span><span class="sxs-lookup"><span data-stu-id="ae093-220">When the training data has a homogeneous structure, convolutional connections are commonly used to learn high-level features of the data.</span></span> <span data-ttu-id="ae093-221">Örneğin, ses veya video veriler, uzamsal veya zamana bağlı boyut görüntüde oldukça Tekdüzen olabilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-221">For example, in image, audio, or video data, spatial or temporal dimensionality can be fairly uniform.</span></span>  

<span data-ttu-id="ae093-222">Convolutional paketleri uygulamadığınız dikdörtgen **tekrar** boyutları aracılığıyla slid.</span><span class="sxs-lookup"><span data-stu-id="ae093-222">Convolutional bundles employ rectangular **kernels** that are slid through the dimensions.</span></span> <span data-ttu-id="ae093-223">Esas olarak, her çekirdek yerel Semt içinde uygulanan ağırlıkları olarak adlandırılan bir dizi tanımlar **çekirdek uygulamaları**.</span><span class="sxs-lookup"><span data-stu-id="ae093-223">Essentially, each kernel defines a set of weights applied in local neighborhoods, referred to as **kernel applications**.</span></span> <span data-ttu-id="ae093-224">Bir düğüm olarak adlandırılır kaynak katmanda her çekirdek uygulama karşılık **merkezi düğümü**.</span><span class="sxs-lookup"><span data-stu-id="ae093-224">Each kernel application corresponds to a node in the source layer, which is referred to as the **central node**.</span></span> <span data-ttu-id="ae093-225">Bir çekirdek ağırlıkları birçok bağlantıları arasında paylaşılır.</span><span class="sxs-lookup"><span data-stu-id="ae093-225">The weights of a kernel are shared among many connections.</span></span> <span data-ttu-id="ae093-226">Bir convolutional paketteki her dikdörtgen çekirdeğidir ve tüm çekirdek uygulamalar aynı boyuttadır.</span><span class="sxs-lookup"><span data-stu-id="ae093-226">In a convolutional bundle, each kernel is rectangular and all kernel applications are the same size.</span></span>  

<span data-ttu-id="ae093-227">Convolutional paketleri aşağıdaki öznitelikleri destekler:</span><span class="sxs-lookup"><span data-stu-id="ae093-227">Convolutional bundles support the following attributes:</span></span>

<span data-ttu-id="ae093-228">**InputShape** convolutional bu paket amaçlarla kaynak katman boyut tanımlar.</span><span class="sxs-lookup"><span data-stu-id="ae093-228">**InputShape** defines the dimensionality of the source layer for the purposes of this convolutional bundle.</span></span> <span data-ttu-id="ae093-229">Değer pozitif tamsayılar tanımlama grubu olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-229">The value must be a tuple of positive integers.</span></span> <span data-ttu-id="ae093-230">Tamsayıların ürün kaynak katmandaki düğüm sayısını eşit olmalıdır, ancak Aksi halde, kaynak katmanı için bildirilen boyut özelliğiyle eşleşen gerekmez.</span><span class="sxs-lookup"><span data-stu-id="ae093-230">The product of the integers must equal the number of nodes in the source layer, but otherwise, it does not need to match the dimensionality declared for the source layer.</span></span> <span data-ttu-id="ae093-231">Bu kayıt uzunluğu hale **parametre** convolutional paket için değer.</span><span class="sxs-lookup"><span data-stu-id="ae093-231">The length of this tuple becomes the **arity** value for the convolutional bundle.</span></span> <span data-ttu-id="ae093-232">(Genellikle parametre bağımsız değişken veya işlev sürebilir işlenenler sayısını ifade eder.)</span><span class="sxs-lookup"><span data-stu-id="ae093-232">(Typically arity refers to the number of arguments or operands that a function can take.)</span></span>  

<span data-ttu-id="ae093-233">Şekil ve tekrar konumları tanımlamak için öznitelikleri kullanma **KernelShape**, **STRIDE**, **doldurma**, **LowerPad**ve  **UpperPad**:</span><span class="sxs-lookup"><span data-stu-id="ae093-233">To define the shape and locations of the kernels, use the attributes **KernelShape**, **Stride**, **Padding**, **LowerPad**, and **UpperPad**:</span></span>   

* <span data-ttu-id="ae093-234">**KernelShape**: her çekirdek convolutional paket için boyut (gerekli) tanımlar.</span><span class="sxs-lookup"><span data-stu-id="ae093-234">**KernelShape**: (required) Defines the dimensionality of each kernel for the convolutional bundle.</span></span> <span data-ttu-id="ae093-235">Değer pozitif tamsayılar paket kapsamalıdır eşittir bir uzunluğa sahip bir tanımlama grubu olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-235">The value must be a tuple of positive integers with a length that equals the arity of the bundle.</span></span> <span data-ttu-id="ae093-236">Bu tanımlama grubu alanının her bileşeni ilgili bileşen büyük olmaması **InputShape**.</span><span class="sxs-lookup"><span data-stu-id="ae093-236">Each component of this tuple must be no greater than the corresponding component of **InputShape**.</span></span> 
* <span data-ttu-id="ae093-237">**STRIDE**: (isteğe bağlı) merkezi düğümü arasında uzaklık Evrişim (tek bir adımda boyutu) her boyut için kayan adım boyutları tanımlar.</span><span class="sxs-lookup"><span data-stu-id="ae093-237">**Stride**: (optional) Defines the sliding step sizes of the convolution (one step size for each dimension), that is the distance between the central nodes.</span></span> <span data-ttu-id="ae093-238">Değer pozitif tamsayılar paket kapsamalıdır olan uzunluğa sahip bir tanımlama grubu olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-238">The value must be a tuple of positive integers with a length that is the arity of the bundle.</span></span> <span data-ttu-id="ae093-239">Bu tanımlama grubu alanının her bileşeni ilgili bileşen büyük olmaması **KernelShape**.</span><span class="sxs-lookup"><span data-stu-id="ae093-239">Each component of this tuple must be no greater than the corresponding component of **KernelShape**.</span></span> <span data-ttu-id="ae093-240">Tüm bileşenlerle birine eşit bir tanımlama grubu varsayılan değerdir.</span><span class="sxs-lookup"><span data-stu-id="ae093-240">The default value is a tuple with all components equal to one.</span></span> 
* <span data-ttu-id="ae093-241">**Paylaşımı**: (isteğe bağlı) evrişim her boyut için paylaşımı ağırlık tanımlar.</span><span class="sxs-lookup"><span data-stu-id="ae093-241">**Sharing**: (optional) Defines the weight sharing for each dimension of the convolution.</span></span> <span data-ttu-id="ae093-242">Değer, tek bir Boole değeri veya Boolean değeri paket kapsamalıdır olan uzunluğa sahip bir tanımlama grubu olabilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-242">The value can be a single Boolean value or a tuple of Boolean values with a length that is the arity of the bundle.</span></span> <span data-ttu-id="ae093-243">Tek bir Boole değeri belirtilen değere eşit tüm bileşenlerle doğru uzunlukta bir tanımlama grubu olarak genişletilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-243">A single Boolean value is extended to be a tuple of the correct length with all components equal to the specified value.</span></span> <span data-ttu-id="ae093-244">Tüm gerçek değerlerin oluşan bir dizi varsayılan değerdir.</span><span class="sxs-lookup"><span data-stu-id="ae093-244">The default value is a tuple that consists of all True values.</span></span> 
* <span data-ttu-id="ae093-245">**MapCount**: özellik sayısı eşler için convolutional paket (isteğe bağlı) tanımlar.</span><span class="sxs-lookup"><span data-stu-id="ae093-245">**MapCount**: (optional) Defines the number of feature maps for the convolutional bundle.</span></span> <span data-ttu-id="ae093-246">Değer, tek bir pozitif tamsayı veya bir tanımlama grubu pozitif tamsayılar paket kapsamalıdır olan uzunluğa sahip olabilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-246">The value can be a single positive integer or a tuple of positive integers with a length that is the arity of the bundle.</span></span> <span data-ttu-id="ae093-247">Tek bir tamsayı değeri belirtilen değere eşit ilk bileşenlerle doğru uzunlukta bir tanımlama grubu olması için genişletilmiş ve kalan tüm bileşenleri birine eşit.</span><span class="sxs-lookup"><span data-stu-id="ae093-247">A single integer value is extended to be a tuple of the correct length with the first components equal to the specified value and all the remaining components equal to one.</span></span> <span data-ttu-id="ae093-248">Varsayılan değer biridir.</span><span class="sxs-lookup"><span data-stu-id="ae093-248">The default value is one.</span></span> <span data-ttu-id="ae093-249">Özellik eşlemeleri toplam sayısı tanımlama grubu bileşenlerinin ürünüdür.</span><span class="sxs-lookup"><span data-stu-id="ae093-249">The total number of feature maps is the product of the components of the tuple.</span></span> <span data-ttu-id="ae093-250">Bu toplam sayısı bileşenlerinde Finansman özellik eşlemesi değerleri hedef düğümleri nasıl gruplandırılacağını belirler.</span><span class="sxs-lookup"><span data-stu-id="ae093-250">The factoring of this total number across the components determines how the feature map values are grouped in the destination nodes.</span></span> 
* <span data-ttu-id="ae093-251">**Ağırlıkları**: (isteğe bağlı) paket için ilk ağırlıkları tanımlar.</span><span class="sxs-lookup"><span data-stu-id="ae093-251">**Weights**: (optional) Defines the initial weights for the bundle.</span></span> <span data-ttu-id="ae093-252">Değer, bu makalenin sonraki bölümlerinde tanımlanan ağırlıkları sayısı nokta değerleri tekrar sayısı olan uzunluğa sahip Çekirdek kayan bir tanımlama grubu olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-252">The value must be a tuple of floating point values with a length that is the number of kernels times the number of weights per kernel, as defined later in this article.</span></span> <span data-ttu-id="ae093-253">Varsayılan ağırlıkları rastgele üretilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-253">The default weights are randomly generated.</span></span>  

<span data-ttu-id="ae093-254">Doldurma, birbirini dışlayan olan özellikleri denetleyen özellikler iki kümesi vardır:</span><span class="sxs-lookup"><span data-stu-id="ae093-254">There are two sets of properties that control padding, the properties being mutually exclusive:</span></span>

* <span data-ttu-id="ae093-255">**Doldurma**: (isteğe bağlı) belirler olup giriş kullanarak dolgu uygulanması bir **varsayılan doldurma düzenini**.</span><span class="sxs-lookup"><span data-stu-id="ae093-255">**Padding**: (optional) Determines whether the input should be padded by using a **default padding scheme**.</span></span> <span data-ttu-id="ae093-256">Değer, tek bir Boole değeri veya Boolean değeri paket kapsamalıdır olan uzunluğa sahip bir tanımlama grubu olabilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-256">The value can be a single Boolean value, or it can be a tuple of Boolean values with a length that is the arity of the bundle.</span></span> <span data-ttu-id="ae093-257">Tek bir Boole değeri belirtilen değere eşit tüm bileşenlerle doğru uzunlukta bir tanımlama grubu olarak genişletilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-257">A single Boolean value is extended to be a tuple of the correct length with all components equal to the specified value.</span></span> <span data-ttu-id="ae093-258">Bir boyut değeri True ise, bu boyuttaki ilk ve son tekrar merkezi düğümleri, ilk ve son düğümlerin olan şekilde kaynak mantıksal olarak sıfır değerli hücreler ek çekirdek uygulamaları desteklemek için o boyutundaki sıfır eklenir Kaynak katman boyutu.</span><span class="sxs-lookup"><span data-stu-id="ae093-258">If the value for a dimension is True, the source is logically padded in that dimension with zero-valued cells to support additional kernel applications, such that the central nodes of the first and last kernels in that dimension are the first and last nodes in that dimension in the source layer.</span></span> <span data-ttu-id="ae093-259">Bu nedenle, her boyut "kukla" düğümlerin sayısı otomatik olarak tam olarak sığması için belirlenen *(InputShape [d] - 1) / [d] STRIDE + 1* tekrar doldurulan kaynak katmana.</span><span class="sxs-lookup"><span data-stu-id="ae093-259">Thus, the number of "dummy" nodes in each dimension is determined automatically, to fit exactly *(InputShape[d] - 1) / Stride[d] + 1* kernels into the padded source layer.</span></span> <span data-ttu-id="ae093-260">Bir boyut değeri False ise, sol çıkışı her tarafında düğüm sayısını (en fazla bir fark 1) aynı böylece tekrar tanımlanır.</span><span class="sxs-lookup"><span data-stu-id="ae093-260">If the value for a dimension is False, the kernels are defined so that the number of nodes on each side that are left out is the same (up to a difference of 1).</span></span> <span data-ttu-id="ae093-261">Bir tanımlama grubu yanlış eşit tüm bileşenlerle bu özniteliğin varsayılan değerdir.</span><span class="sxs-lookup"><span data-stu-id="ae093-261">The default value of this attribute is a tuple with all components equal to False.</span></span>
* <span data-ttu-id="ae093-262">**UpperPad** ve **LowerPad**: (isteğe bağlı) sağlama büyük denetime kullanmak için doldurma miktarı.</span><span class="sxs-lookup"><span data-stu-id="ae093-262">**UpperPad** and **LowerPad**: (optional) Provide greater control over the amount of padding to use.</span></span> <span data-ttu-id="ae093-263">**Önemli:** tanımlanmış ise ve yalnızca bu öznitelikler olabilir **doldurma** özelliği yukarıdaki ***değil*** tanımlanmış.</span><span class="sxs-lookup"><span data-stu-id="ae093-263">**Important:** These attributes can be defined if and only if the **Padding** property above is ***not*** defined.</span></span> <span data-ttu-id="ae093-264">Değerleri tamsayı değerli diziler paket kapsamalıdır olan uzunluklarına sahip olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-264">The values should be integer-valued tuples with lengths that are the arity of the bundle.</span></span> <span data-ttu-id="ae093-265">Bu öznitelikler belirtildiğinde, "kukla" düğümler giriş katmanın her boyut alt ve üst ucunun eklenir.</span><span class="sxs-lookup"><span data-stu-id="ae093-265">When these attributes are specified, "dummy" nodes are added to the lower and upper ends of each dimension of the input layer.</span></span> <span data-ttu-id="ae093-266">Her boyut alt ve üst sona eriyor eklenen düğüm sayısı tarafından belirlenir **LowerPad**[i] ve **UpperPad**[i] sırasıyla.</span><span class="sxs-lookup"><span data-stu-id="ae093-266">The number of nodes added to the lower and upper ends in each dimension is determined by **LowerPad**[i] and **UpperPad**[i] respectively.</span></span> <span data-ttu-id="ae093-267">Tekrar yalnızca "gerçek" düğümler ve "kukla" düğümleri karşılık geldiğinden emin olmak için aşağıdaki koşullar karşılanmalıdır:</span><span class="sxs-lookup"><span data-stu-id="ae093-267">To ensure that kernels correspond only to "real" nodes and not to "dummy" nodes, the following conditions must be met:</span></span>
  * <span data-ttu-id="ae093-268">Her bir bileşeninin **LowerPad** [d] KernelShape değerinden kesinlikle küçük olmalıdır / 2.</span><span class="sxs-lookup"><span data-stu-id="ae093-268">Each component of **LowerPad** must be strictly less than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="ae093-269">Her bir bileşeninin **UpperPad** KernelShape [d] ' büyük olmalıdır / 2.</span><span class="sxs-lookup"><span data-stu-id="ae093-269">Each component of **UpperPad** must be no greater than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="ae093-270">Tüm bileşenlerle 0'a eşit bir tanımlama grubu bu özniteliklerin varsayılan değerdir.</span><span class="sxs-lookup"><span data-stu-id="ae093-270">The default value of these attributes is a tuple with all components equal to 0.</span></span> 

<span data-ttu-id="ae093-271">Ayar **doldurma** = true "giriş merkezini" çekirdek "gerçek" içinde tutmak için gerektiği kadar doldurma sağlar.</span><span class="sxs-lookup"><span data-stu-id="ae093-271">The setting **Padding** = true allows as much padding as is needed to keep the "center" of the kernel inside the "real" input.</span></span> <span data-ttu-id="ae093-272">Bu çıktı boyutunu bilgi işlem için bir bit matematik değiştirir.</span><span class="sxs-lookup"><span data-stu-id="ae093-272">This changes the math a bit for computing the output size.</span></span> <span data-ttu-id="ae093-273">Genellikle, çıkış boyutu *D* olarak hesaplanan *D = (ı - K) / S + 1*, burada *ı* giriş boyutu *K* çekirdek boyutu *S*  STRIDE olduğu ve  */*  tamsayı bölme (sıfıra doğru yuvarlar) değil.</span><span class="sxs-lookup"><span data-stu-id="ae093-273">Generally, the output size *D* is computed as *D = (I - K) / S + 1*, where *I* is the input size, *K* is the kernel size, *S* is the stride, and */* is integer division (round toward zero).</span></span> <span data-ttu-id="ae093-274">UpperPad ayarlarsanız = [1, 1], giriş boyutu *ı* 29 etkin olduğunu ve bu nedenle *D = (29-5) / 2 + 1 = 13*.</span><span class="sxs-lookup"><span data-stu-id="ae093-274">If you set UpperPad = [1, 1], the input size *I* is effectively 29, and thus *D = (29 - 5) / 2 + 1 = 13*.</span></span> <span data-ttu-id="ae093-275">Ancak, ne zaman **doldurma** = true, aslında *ı* tarafından indirgenmesine *K - 1*; bu nedenle *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span><span class="sxs-lookup"><span data-stu-id="ae093-275">However, when **Padding** = true, essentially *I* gets bumped up by *K - 1*; hence *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span></span> <span data-ttu-id="ae093-276">İçin değerler belirterek **UpperPad** ve **LowerPad** yalnızca ayarlarsanız daha çok daha fazla denetime doldurma alma **doldurma** = true.</span><span class="sxs-lookup"><span data-stu-id="ae093-276">By specifying values for **UpperPad** and **LowerPad** you get much more control over the padding than if you just set **Padding** = true.</span></span>

<span data-ttu-id="ae093-277">Convolutional ağları ve bunların uygulamaları hakkında daha fazla bilgi için bu makalelere bakın:</span><span class="sxs-lookup"><span data-stu-id="ae093-277">For more information about convolutional networks and their applications, see these articles:</span></span>  

* [<span data-ttu-id="ae093-278">http://deeplearning.NET/Tutorial/lenet.HTML</span><span class="sxs-lookup"><span data-stu-id="ae093-278">http://deeplearning.net/tutorial/lenet.html </span></span>](http://deeplearning.net/tutorial/lenet.html)
* [<span data-ttu-id="ae093-279">http://Research.microsoft.com/pubs/68920/icdar03.PDF</span><span class="sxs-lookup"><span data-stu-id="ae093-279">http://research.microsoft.com/pubs/68920/icdar03.pdf</span></span>](http://research.microsoft.com/pubs/68920/icdar03.pdf) 
* [<span data-ttu-id="ae093-280">http://People.csail.mit.edu/jvb/Papers/cnn_tutorial.PDF</span><span class="sxs-lookup"><span data-stu-id="ae093-280">http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf</span></span>](http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf)  

## <a name="pooling-bundles"></a><span data-ttu-id="ae093-281">Paket havuzu</span><span class="sxs-lookup"><span data-stu-id="ae093-281">Pooling bundles</span></span>
<span data-ttu-id="ae093-282">A **paket havuzu** geometri convolutional bağlantısı benzer geçerlidir, ancak hedef düğüm değeri türetilmesi için kaynak düğüm değerleri için önceden tanımlanmış işlevleri kullanır.</span><span class="sxs-lookup"><span data-stu-id="ae093-282">A **pooling bundle** applies geometry similar to convolutional connectivity, but it uses predefined functions to source node values to derive the destination node value.</span></span> <span data-ttu-id="ae093-283">Bu nedenle, havuzu paketleri trainable durum yok (ağırlıkları veya stratejimizdeki) sahip.</span><span class="sxs-lookup"><span data-stu-id="ae093-283">Hence, pooling bundles have no trainable state (weights or biases).</span></span> <span data-ttu-id="ae093-284">Havuzu paketleri destek dışındaki tüm convolutional öznitelikleri **paylaşım**, **MapCount**, ve **ağırlıkları**.</span><span class="sxs-lookup"><span data-stu-id="ae093-284">Pooling bundles support all the convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

<span data-ttu-id="ae093-285">Genellikle, bitişik havuzu birimler tarafından özetlenen tekrar çakışmaz.</span><span class="sxs-lookup"><span data-stu-id="ae093-285">Typically, the kernels summarized by adjacent pooling units do not overlap.</span></span> <span data-ttu-id="ae093-286">STRIDE [d] her boyut KernelShape [d] eşit ise, elde edilen katman hangi convolutional sinir ağlarda yaygın olarak kullanılan geleneksel yerel havuzu oluşturma, katmanıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-286">If Stride[d] is equal to KernelShape[d] in each dimension, the layer obtained is the traditional local pooling layer, which is commonly employed in convolutional neural networks.</span></span> <span data-ttu-id="ae093-287">Her hedef düğüm maksimum veya kendi çekirdek kaynak katmandaki etkinliklerini ortalaması hesaplar.</span><span class="sxs-lookup"><span data-stu-id="ae093-287">Each destination node computes the maximum or the mean of the activities of its kernel in the source layer.</span></span>  

<span data-ttu-id="ae093-288">Aşağıdaki örnek bir havuzu paket gösterilmektedir:</span><span class="sxs-lookup"><span data-stu-id="ae093-288">The following example illustrates a pooling bundle:</span></span> 

    hidden P1 [5, 12, 12]
      from C1 max pool {
        InputShape  = [ 5, 24, 24];
        KernelShape = [ 1,  2,  2];
        Stride      = [ 1,  2,  2];
      }  

* <span data-ttu-id="ae093-289">3 paket kapsamalıdır. (başlıklar uzunluğu **InputShape**, **KernelShape**, ve **STRIDE**).</span><span class="sxs-lookup"><span data-stu-id="ae093-289">The arity of the bundle is 3 (the length of the tuples **InputShape**, **KernelShape**, and **Stride**).</span></span> 
* <span data-ttu-id="ae093-290">Kaynak katmandaki düğüm sayısı: *5 * 24 * 24 = 2880*.</span><span class="sxs-lookup"><span data-stu-id="ae093-290">The number of nodes in the source layer is *5 * 24 * 24 = 2880*.</span></span> 
* <span data-ttu-id="ae093-291">Bunun nedeni geleneksel yerel havuzu katman, **KernelShape** ve **STRIDE** eşit.</span><span class="sxs-lookup"><span data-stu-id="ae093-291">This is a traditional local pooling layer because **KernelShape** and **Stride** are equal.</span></span> 
* <span data-ttu-id="ae093-292">Hedef katmandaki düğüm sayısı: *5 * 12 * 12 = 1440*.</span><span class="sxs-lookup"><span data-stu-id="ae093-292">The number of nodes in the destination layer is *5 * 12 * 12 = 1440*.</span></span>  

<span data-ttu-id="ae093-293">Havuzu katmanları hakkında daha fazla bilgi için bu makalelere bakın:</span><span class="sxs-lookup"><span data-stu-id="ae093-293">For more information about pooling layers, see these articles:</span></span>  

* <span data-ttu-id="ae093-294">[http://www.cs.Toronto.edu/~hinton/absps/imagenet.PDF](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Bölüm 3.4)</span><span class="sxs-lookup"><span data-stu-id="ae093-294">[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Section 3.4)</span></span>
* [<span data-ttu-id="ae093-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.PDF</span><span class="sxs-lookup"><span data-stu-id="ae093-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf</span></span>](http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf) 
* [<span data-ttu-id="ae093-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.PDF</span><span class="sxs-lookup"><span data-stu-id="ae093-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf</span></span>](http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf)

## <a name="response-normalization-bundles"></a><span data-ttu-id="ae093-297">Yanıt normalleştirme paketleri</span><span class="sxs-lookup"><span data-stu-id="ae093-297">Response normalization bundles</span></span>
<span data-ttu-id="ae093-298">**Yanıt normalleştirme** ilk Geoffrey Hinton tarafından sunulan bir yerel normalleştirme düzenidir yazıda et al [ImageNet Classiﬁcation Convolutional derin sinir ağları ile](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span><span class="sxs-lookup"><span data-stu-id="ae093-298">**Response normalization** is a local normalization scheme that was first introduced by Geoffrey Hinton, et al, in the paper [ImageNet Classiﬁcation with Deep Convolutional Neural Networks](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span></span> <span data-ttu-id="ae093-299">Yanıt normalleştirme sinir ağ Genelleştirme yardımcı olmak için kullanılır.</span><span class="sxs-lookup"><span data-stu-id="ae093-299">Response normalization is used to aid generalization in neural nets.</span></span> <span data-ttu-id="ae093-300">Çok yüksek etkinleştirme düzeyinde bir neuron tetikleme, yerel yanıt normalleştirme katman çevresindeki neurons etkinleştirme düzeyini gizler.</span><span class="sxs-lookup"><span data-stu-id="ae093-300">When one neuron is firing at a very high activation level, a local response normalization layer suppresses the activation level of the surrounding neurons.</span></span> <span data-ttu-id="ae093-301">Bu üç parametre kullanılarak yapılır (***α***, ***β***, ve ***k***) ve bir convolutional yapısı (veya Komşuları Şekil).</span><span class="sxs-lookup"><span data-stu-id="ae093-301">This is done by using three parameters (***α***, ***β***, and ***k***) and a convolutional structure (or neighborhood shape).</span></span> <span data-ttu-id="ae093-302">Hedef katmanda her neuron ***y*** neuron için karşılık gelen ***x*** kaynak katmandaki.</span><span class="sxs-lookup"><span data-stu-id="ae093-302">Every neuron in the destination layer ***y*** corresponds to a neuron ***x*** in the source layer.</span></span> <span data-ttu-id="ae093-303">Etkinleştirme düzeyi ***y*** aşağıdaki formülde verilen nerede ***f*** bir neuron etkinleştirme düzeyi ve ***Nx*** çekirdeğidir (veya neurons içeren küme Komşuları olarak ***x***), aşağıdaki convolutional yapısı tarafından tanımlanan:</span><span class="sxs-lookup"><span data-stu-id="ae093-303">The activation level of ***y*** is given by the following formula, where ***f*** is the activation level of a neuron, and ***Nx*** is the kernel (or the set that contains the neurons in the neighborhood of ***x***), as defined by the following convolutional structure:</span></span>  

![][1]  

<span data-ttu-id="ae093-304">Yanıt normalleştirme paketleri destek dışındaki tüm convolutional öznitelikleri **paylaşım**, **MapCount**, ve **ağırlıkları**.</span><span class="sxs-lookup"><span data-stu-id="ae093-304">Response normalization bundles support all the convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

* <span data-ttu-id="ae093-305">Çekirdek neurons aynı eşlemesindeki içeriyorsa ***x***, normalleştirme düzeni olarak adlandırılır **aynı eşleme normalleştirme**.</span><span class="sxs-lookup"><span data-stu-id="ae093-305">If the kernel contains neurons in the same map as ***x***, the normalization scheme is referred to as **same map normalization**.</span></span> <span data-ttu-id="ae093-306">Aynı eşleme normalleştirme, ilk koordinat tanımlamak için **InputShape** 1 değeri olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-306">To define same map normalization, the first coordinate in **InputShape** must have the value 1.</span></span>
* <span data-ttu-id="ae093-307">Çekirdek neurons aynı konumda yer alan uzamsal içeriyorsa ***x***, ancak neurons diğer eşlemeleri, normalleştirme düzeni adı verilen **normalleştirme'çapraz eşlemeleri**.</span><span class="sxs-lookup"><span data-stu-id="ae093-307">If the kernel contains neurons in the same spatial position as ***x***, but the neurons are in other maps, the normalization scheme is called **across maps normalization**.</span></span> <span data-ttu-id="ae093-308">Yanıt normalleştirme bu tür yanal inhibition farklı eşlemeleri hesaplanan neuron çıktılar arasında büyük etkinleştirme düzeyleri için rekabet oluşturma gerçek neurons içinde bulunan türe göre esin biçimi uygular.</span><span class="sxs-lookup"><span data-stu-id="ae093-308">This type of response normalization implements a form of lateral inhibition inspired by the type found in real neurons, creating competition for big activation levels amongst neuron outputs computed on different maps.</span></span> <span data-ttu-id="ae093-309">Eşlemeleri normalleştirme arasında tanımlamak için ilk koordinat birden büyük ve haritalar sayısından daha büyük bir tamsayı olmalıdır ve koordinatları kalan 1 değeri olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-309">To define across maps normalization, the first coordinate must be an integer greater than one and no greater than the number of maps, and the rest of the coordinates must have the value 1.</span></span>  

<span data-ttu-id="ae093-310">Yanıt normalleştirme paketleri önceden tanımlanmış bir işlev hedef düğüm değeri belirlemek için kaynak düğüm değerleri için geçerli olduğundan, bunlar trainable durum yok (ağırlıkları veya stratejimizdeki) sahip.</span><span class="sxs-lookup"><span data-stu-id="ae093-310">Because response normalization bundles apply a predefined function to source node values to determine the destination node value, they have no trainable state (weights or biases).</span></span>   

<span data-ttu-id="ae093-311">**Uyarı**: Hedef katmanı düğümlerin tekrar merkezi düğümler neurons karşılık gelir.</span><span class="sxs-lookup"><span data-stu-id="ae093-311">**Alert**: The nodes in the destination layer correspond to neurons that are the central nodes of the kernels.</span></span> <span data-ttu-id="ae093-312">Örneğin, KernelShape [d] tek, ise, *KernelShape [d] / 2* merkezi çekirdek düğüme karşılık gelir.</span><span class="sxs-lookup"><span data-stu-id="ae093-312">For example, if KernelShape[d] is odd, then *KernelShape[d]/2* corresponds to the central kernel node.</span></span> <span data-ttu-id="ae093-313">Varsa *KernelShape [d]* olsa bile, merkezi düğümdür adresindeki *KernelShape [d] / 2-1*.</span><span class="sxs-lookup"><span data-stu-id="ae093-313">If *KernelShape[d]* is even, the central node is at *KernelShape[d]/2 - 1*.</span></span> <span data-ttu-id="ae093-314">Bu nedenle, varsa **doldurma**[d] is False, ilk ve son *KernelShape [d] / 2* düğümleri hedef katmanda ilgili düğümleri gerekmez.</span><span class="sxs-lookup"><span data-stu-id="ae093-314">Therefore, if **Padding**[d] is False, the first and the last *KernelShape[d]/2* nodes do not have corresponding nodes in the destination layer.</span></span> <span data-ttu-id="ae093-315">Bu durumu önlemek için tanımlamak **doldurma** olarak [true, true,..., true].</span><span class="sxs-lookup"><span data-stu-id="ae093-315">To avoid this situation, define **Padding** as [true, true, …, true].</span></span>  

<span data-ttu-id="ae093-316">Daha önce açıklanan dört öznitelikleri yanı sıra yanıt normalleştirme paketleri ayrıca aşağıdaki özniteliklere destekler:</span><span class="sxs-lookup"><span data-stu-id="ae093-316">In addition to the four attributes described earlier, response normalization bundles also support the following attributes:</span></span>  

* <span data-ttu-id="ae093-317">**Alpha**: (gerekli) belirtir karşılık gelen bir kayan nokta değer ***α*** önceki formülünde.</span><span class="sxs-lookup"><span data-stu-id="ae093-317">**Alpha**: (required) Specifies a floating-point value that corresponds to ***α*** in the previous formula.</span></span> 
* <span data-ttu-id="ae093-318">**Beta**: (gerekli) belirtir karşılık gelen bir kayan nokta değer ***β*** önceki formülünde.</span><span class="sxs-lookup"><span data-stu-id="ae093-318">**Beta**: (required) Specifies a floating-point value that corresponds to ***β*** in the previous formula.</span></span> 
* <span data-ttu-id="ae093-319">**Uzaklık**: (isteğe bağlı) belirtir karşılık gelen bir kayan nokta değer ***k*** önceki formülünde.</span><span class="sxs-lookup"><span data-stu-id="ae093-319">**Offset**: (optional) Specifies a floating-point value that corresponds to ***k*** in the previous formula.</span></span> <span data-ttu-id="ae093-320">Bu varsayılan olarak 1.</span><span class="sxs-lookup"><span data-stu-id="ae093-320">It defaults to 1.</span></span>  

<span data-ttu-id="ae093-321">Aşağıdaki örnek, bu öznitelikler kullanarak bir yanıt normalleştirme paketini tanımlar:</span><span class="sxs-lookup"><span data-stu-id="ae093-321">The following example defines a response normalization bundle using these attributes:</span></span>  

    hidden RN1 [5, 10, 10]
      from P1 response norm {
        InputShape  = [ 5, 12, 12];
        KernelShape = [ 1,  3,  3];
        Alpha = 0.001;
        Beta = 0.75;
      }  

* <span data-ttu-id="ae093-322">Kaynak katmanın her 12 x 12, 1440 düğümler toplamda aof boyutla beş eşlemeleri içerir.</span><span class="sxs-lookup"><span data-stu-id="ae093-322">The source layer includes five maps, each with aof dimension of 12x12, totaling in 1440 nodes.</span></span> 
* <span data-ttu-id="ae093-323">Değeri **KernelShape** bu Komşuları 3 x 3 dikdörtgen olduğu aynı bir harita normalleştirme katman olduğunu gösterir.</span><span class="sxs-lookup"><span data-stu-id="ae093-323">The value of **KernelShape** indicates that this is a same map normalization layer, where the neighborhood is a 3x3 rectangle.</span></span> 
* <span data-ttu-id="ae093-324">Varsayılan değer olan **doldurma** false, böylece Hedef katmanı her boyut yalnızca 10 düğüm yok.</span><span class="sxs-lookup"><span data-stu-id="ae093-324">The default value of **Padding** is False, thus the destination layer has only 10 nodes in each dimension.</span></span> <span data-ttu-id="ae093-325">Kaynak katman kümedeki her düğüm için karşılık gelen hedef katmandaki tek bir düğüm eklemek için dolgu ekleme [true, true, true] =; ve [5, 12, 12] RN1 boyutunu değiştirin.</span><span class="sxs-lookup"><span data-stu-id="ae093-325">To include one node in the destination layer that corresponds to every node in the source layer, add Padding = [true, true, true]; and change the size of RN1 to [5, 12, 12].</span></span>  

## <a name="share-declaration"></a><span data-ttu-id="ae093-326">Paylaşım bildirimi</span><span class="sxs-lookup"><span data-stu-id="ae093-326">Share declaration</span></span>
<span data-ttu-id="ae093-327">NET # isteğe bağlı olarak paylaşılan ağırlıklara sahip birden çok paket tanımlama destekler.</span><span class="sxs-lookup"><span data-stu-id="ae093-327">Net# optionally supports defining multiple bundles with shared weights.</span></span> <span data-ttu-id="ae093-328">Kendi yapıları aynıysa herhangi iki paket ağırlıkları paylaşılabilir.</span><span class="sxs-lookup"><span data-stu-id="ae093-328">The weights of any two bundles can be shared if their structures are the same.</span></span> <span data-ttu-id="ae093-329">Aşağıdaki söz dizimini paylaşılan ağırlıklara sahip paketleri tanımlar:</span><span class="sxs-lookup"><span data-stu-id="ae093-329">The following syntax defines bundles with shared weights:</span></span>  

    share-declaration:
        share    {    layer-list    }
        share    {    bundle-list    }
       share    {    bias-list    }

    layer-list:
        layer-name    ,    layer-name
        layer-list    ,    layer-name

    bundle-list:
       bundle-spec    ,    bundle-spec
        bundle-list    ,    bundle-spec

    bundle-spec:
       layer-name    =>     layer-name

    bias-list:
        bias-spec    ,    bias-spec
        bias-list    ,    bias-spec

    bias-spec:
        1    =>    layer-name

    layer-name:
        identifier  

<span data-ttu-id="ae093-330">Örneğin, aşağıdaki paylaşım bildirimi ağırlıkları ve stratejimizdeki paylaşılan olduğunu gösteren katman adlarını belirtir:</span><span class="sxs-lookup"><span data-stu-id="ae093-330">For example, the following share-declaration specifies the layer names, indicating that both weights and biases should be shared:</span></span>  

    Const {
      InputSize = 37;
      HiddenSize = 50;
    }
    input {
      Data1 [InputSize];
      Data2 [InputSize];
    }
    hidden {
      H1 [HiddenSize] from Data1 all;
      H2 [HiddenSize] from Data2 all;
    }
    output Result [2] {
      from H1 all;
      from H2 all;
    }
    share { H1, H2 } // share both weights and biases  

* <span data-ttu-id="ae093-331">Giriş özellikleri iki eşit boyutta giriş katmanlara bölümlenir.</span><span class="sxs-lookup"><span data-stu-id="ae093-331">The input features are partitioned into two equal sized input layers.</span></span> 
* <span data-ttu-id="ae093-332">Gizli katmanları sonra iki giriş katmanlardaki daha yüksek düzey özelliklerinin işlem.</span><span class="sxs-lookup"><span data-stu-id="ae093-332">The hidden layers then compute higher level features on the two input layers.</span></span> 
* <span data-ttu-id="ae093-333">Paylaşım bildirimi belirleyen *H1* ve *H2* kendi ilgili girişler aynı biçimde hesaplanan gerekir.</span><span class="sxs-lookup"><span data-stu-id="ae093-333">The share-declaration specifies that *H1* and *H2* must be computed in the same way from their respective inputs.</span></span>  

<span data-ttu-id="ae093-334">Alternatif olarak, bu iki ayrı paylaşımı-bildirimlerle gibi belirtilebilir:</span><span class="sxs-lookup"><span data-stu-id="ae093-334">Alternatively, this could be specified with two separate share-declarations as follows:</span></span>  

    share { Data1 => H1, Data2 => H2 } // share weights  

<!-- -->

    share { 1 => H1, 1 => H2 } // share biases  

<span data-ttu-id="ae093-335">Yalnızca tek bir paket katmanları içeriyorsa, kısa biçimi kullanabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="ae093-335">You can use the short form only when the layers contain a single bundle.</span></span> <span data-ttu-id="ae093-336">Yalnızca ilgili yapısı aynı boyut, aynı convolutional geometri ve benzeri olduğunu yani aynı genel olarak, paylaşımı mümkün olur.</span><span class="sxs-lookup"><span data-stu-id="ae093-336">In general, sharing is possible only when the relevant structure is identical, meaning that they have the same size, same convolutional geometry, and so forth.</span></span>  

## <a name="examples-of-net-usage"></a><span data-ttu-id="ae093-337">Net # kullanım örnekleri</span><span class="sxs-lookup"><span data-stu-id="ae093-337">Examples of Net# usage</span></span>
<span data-ttu-id="ae093-338">Bu bölümde nasıl Net # gizli katmanları eklemek için gizli katmanları diğer katmanları ile etkileşim kurmanızı ve convolutional ağlar oluşturmak şekilde tanımlamak için kullanabileceğiniz bazı örnekler sağlar.</span><span class="sxs-lookup"><span data-stu-id="ae093-338">This section provides some examples of how you can use Net# to add hidden layers, define the way that hidden layers interact with other layers, and build convolutional networks.</span></span>   

### <a name="define-a-simple-custom-neural-network-hello-world-example"></a><span data-ttu-id="ae093-339">Basit bir özel sinir ağı tanımlar: "Hello World" örnek</span><span class="sxs-lookup"><span data-stu-id="ae093-339">Define a simple custom neural network: "Hello World" example</span></span>
<span data-ttu-id="ae093-340">Bu basit örnekte, tek bir gizli katmanın sahip olduğu bir sinir ağı model oluşturmak gösterilmiştir.</span><span class="sxs-lookup"><span data-stu-id="ae093-340">This simple example demonstrates how to create a neural network model that has a single hidden layer.</span></span>  

    input Data auto;
    hidden H [200] from Data all;
    output Out [10] sigmoid from H all;  

<span data-ttu-id="ae093-341">Örnek gibi bazı temel komutları gösterir:</span><span class="sxs-lookup"><span data-stu-id="ae093-341">The example illustrates some basic commands as follows:</span></span>  

* <span data-ttu-id="ae093-342">İlk satırı giriş katman tanımlar (adlı *veri*).</span><span class="sxs-lookup"><span data-stu-id="ae093-342">The first line defines the input layer (named *Data*).</span></span> <span data-ttu-id="ae093-343">Kullandığınızda **otomatik** anahtar sözcüğü, sinir ağı giriş örneklerde otomatik olarak tüm özellik sütunları içerir.</span><span class="sxs-lookup"><span data-stu-id="ae093-343">When you use the  **auto** keyword, the neural network automatically includes all feature columns in the input examples.</span></span> 
* <span data-ttu-id="ae093-344">İkinci satır gizli katman oluşturur.</span><span class="sxs-lookup"><span data-stu-id="ae093-344">The second line creates the hidden layer.</span></span> <span data-ttu-id="ae093-345">Adı *H* 200 düğümü olan bir gizli katmana atanır.</span><span class="sxs-lookup"><span data-stu-id="ae093-345">The name *H* is assigned to the hidden layer, which has 200 nodes.</span></span> <span data-ttu-id="ae093-346">Bu katman tam giriş katmanına bağlıdır.</span><span class="sxs-lookup"><span data-stu-id="ae093-346">This layer is fully connected to the input layer.</span></span>
* <span data-ttu-id="ae093-347">Üçüncü satır çıktı katman tanımlar (adlı *O*), 10 çıkış düğümlerini içerir.</span><span class="sxs-lookup"><span data-stu-id="ae093-347">The third line defines the output layer (named *O*), which contains 10 output nodes.</span></span> <span data-ttu-id="ae093-348">Sinir ağı için sınıflandırma kullanılırsa, bir çıktı düğüm başına sınıfı yok.</span><span class="sxs-lookup"><span data-stu-id="ae093-348">If the neural network is used for classification, there is one output node per class.</span></span> <span data-ttu-id="ae093-349">Anahtar sözcüğü **sigmoid** çıkış işlevi çıktı katmana uygulandığını gösterir.</span><span class="sxs-lookup"><span data-stu-id="ae093-349">The keyword **sigmoid** indicates that the output function is applied to the output layer.</span></span>   

### <a name="define-multiple-hidden-layers-computer-vision-example"></a><span data-ttu-id="ae093-350">Birden çok gizli katmanları tanımlayın: bilgisayar görme örneği</span><span class="sxs-lookup"><span data-stu-id="ae093-350">Define multiple hidden layers: computer vision example</span></span>
<span data-ttu-id="ae093-351">Aşağıdaki örnek, birden çok özel gizli katmanlarıyla biraz daha karmaşık bir sinir ağı tanımlamak gösterilmiştir.</span><span class="sxs-lookup"><span data-stu-id="ae093-351">The following example demonstrates how to define a slightly more complex neural network, with multiple custom hidden layers.</span></span>  

    // Define the input layers 
    input Pixels [10, 20];
    input MetaData [7];

    // Define the first two hidden layers, using data only from the Pixels input
    hidden ByRow [10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol [5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;

    // Define the third hidden layer, which uses as source the hidden layers ByRow and ByCol
    hidden Gather [100] 
    {
      from ByRow all;
      from ByCol all;
    }

    // Define the output layer and its sources
    output Result [10]  
    {
      from Gather all;
      from MetaData all;
    }  

<span data-ttu-id="ae093-352">Bu örnek sinir ağları belirtimi dil çeşitli özellikleri gösterir:</span><span class="sxs-lookup"><span data-stu-id="ae093-352">This example illustrates several features of the neural networks specification language:</span></span>  

* <span data-ttu-id="ae093-353">İki giriş Katmanlar yapısının *piksel* ve *meta verileri*.</span><span class="sxs-lookup"><span data-stu-id="ae093-353">The structure has two input layers, *Pixels* and *MetaData*.</span></span>
* <span data-ttu-id="ae093-354">*Piksel* katmanıdır hedef katmanlarıyla iki bağlantı paketleri için bir kaynak katman *ByRow* ve *ByCol*.</span><span class="sxs-lookup"><span data-stu-id="ae093-354">The *Pixels* layer is a source layer for two connection bundles, with destination layers, *ByRow* and *ByCol*.</span></span>
* <span data-ttu-id="ae093-355">Katmanları *toplamak* ve *sonuç* birden çok bağlantı paket hedef katmanlarda olan.</span><span class="sxs-lookup"><span data-stu-id="ae093-355">The layers *Gather* and *Result* are destination layers in multiple connection bundles.</span></span>
* <span data-ttu-id="ae093-356">Çıktı katman *sonuç*, bir hedef katmandaki iki bağlantı paketleri; ikinci sahip bir hedef katmanı olarak gizli (toplama) ve hedef katmanı olarak giriş katman (meta verileri) ile diğer düzey.</span><span class="sxs-lookup"><span data-stu-id="ae093-356">The output layer, *Result*, is a destination layer in two connection bundles; one with the second level hidden (Gather) as a destination layer, and the other with the input layer (MetaData) as a destination layer.</span></span>
* <span data-ttu-id="ae093-357">Gizli katmanları *ByRow* ve *ByCol*, filtrelenmiş bağlantı koşullu ifadeler kullanarak belirtin.</span><span class="sxs-lookup"><span data-stu-id="ae093-357">The hidden layers, *ByRow* and *ByCol*, specify filtered connectivity by using predicate expressions.</span></span> <span data-ttu-id="ae093-358">Daha hassas bir şekilde düğümünde *ByRow* adresindeki [x, y] düğümlerin bağlı *piksel* kullanıcının ilk koordinat, x sahip ilk dizin koordine, düğüm eşittir.</span><span class="sxs-lookup"><span data-stu-id="ae093-358">More precisely, the node in *ByRow* at [x, y] is connected to the nodes in *Pixels* that have the first index coordinate equal to the node's first coordinate, x.</span></span> <span data-ttu-id="ae093-359">Benzer şekilde, düğümünde *[x, y] konumundaki ByCol _Pixels düğümlerin bağlı* sahip ikinci bir dizin koordine etmek, bir düğüm kullanıcının ikinci koordinat, y.</span><span class="sxs-lookup"><span data-stu-id="ae093-359">Similarly, the node in *ByCol at [x, y] is connected to the nodes in _Pixels* that have the second index coordinate within one of the node's second coordinate, y.</span></span>  

### <a name="define-a-convolutional-network-for-multiclass-classification-digit-recognition-example"></a><span data-ttu-id="ae093-360">Çok sınıflı sınıflandırma convolutional ağ tanımlayın: rakam tanıma örneği</span><span class="sxs-lookup"><span data-stu-id="ae093-360">Define a convolutional network for multiclass classification: digit recognition example</span></span>
<span data-ttu-id="ae093-361">Aşağıdaki ağ tanımını numaraları tanımak için tasarlanmıştır ve sinir ağı özelleştirmek için Gelişmiş bazı teknikleri göstermektedir.</span><span class="sxs-lookup"><span data-stu-id="ae093-361">The definition of the following network is designed to recognize numbers, and it illustrates some advanced techniques for customizing a neural network.</span></span>  

    input Image [29, 29];
    hidden Conv1 [5, 13, 13] from Image convolve 
    {
       InputShape  = [29, 29];
       KernelShape = [ 5,  5];
       Stride      = [ 2,  2];
       MapCount    = 5;
    }
    hidden Conv2 [50, 5, 5]
    from Conv1 convolve 
    {
       InputShape  = [ 5, 13, 13];
       KernelShape = [ 1,  5,  5];
       Stride      = [ 1,  2,  2];
       Sharing     = [false, true, true];
       MapCount    = 10;
    }
    hidden Hid3 [100] from Conv2 all;
    output Digit [10] from Hid3 all;  


* <span data-ttu-id="ae093-362">Tek bir giriş katman yapısının *görüntü*.</span><span class="sxs-lookup"><span data-stu-id="ae093-362">The structure has a single input layer, *Image*.</span></span>
* <span data-ttu-id="ae093-363">Anahtar sözcüğü **convolve** katmanları adlı gösterir *Conv1* ve *Conv2* convolutional katmanlardır.</span><span class="sxs-lookup"><span data-stu-id="ae093-363">The keyword **convolve** indicates that the layers named *Conv1* and *Conv2* are convolutional layers.</span></span> <span data-ttu-id="ae093-364">Bu katman bildirimleri her evrişim özniteliklerin bir listesi tarafından izlenir.</span><span class="sxs-lookup"><span data-stu-id="ae093-364">Each of these layer declarations is followed by a list of the convolution attributes.</span></span>
* <span data-ttu-id="ae093-365">Net üçüncü katman, gizlenmiş *Hid3*, hangi tam olarak bağlı olan ikinci gizli katmana *Conv2*.</span><span class="sxs-lookup"><span data-stu-id="ae093-365">The net has a third hidden layer, *Hid3*, which is fully connected to the second hidden layer, *Conv2*.</span></span>
* <span data-ttu-id="ae093-366">Çıktı katman *basamaklı*, yalnızca üçüncü gizli katmana, bağlı *Hid3*.</span><span class="sxs-lookup"><span data-stu-id="ae093-366">The output layer, *Digit*, is connected only to the third hidden layer, *Hid3*.</span></span> <span data-ttu-id="ae093-367">Anahtar sözcüğü **tüm** için çıktı katmanı tam olarak bağlı olduğunu belirtiyor *Hid3*.</span><span class="sxs-lookup"><span data-stu-id="ae093-367">The keyword **all** indicates that the output layer is fully connected to *Hid3*.</span></span>
* <span data-ttu-id="ae093-368">Evrişim kapsamalıdır üç olan (başlıklar uzunluğu **InputShape**, **KernelShape**, **STRIDE**, ve **paylaşım**).</span><span class="sxs-lookup"><span data-stu-id="ae093-368">The arity of the convolution is three (the length of the tuples **InputShape**, **KernelShape**, **Stride**, and **Sharing**).</span></span> 
* <span data-ttu-id="ae093-369">Çekirdek başına ağırlıkları sayısı *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape** \[ 2] = 1 + 1 * 5 * 5 = 26 oluşturun. Veya 26 * 50 = 1300*.</span><span class="sxs-lookup"><span data-stu-id="ae093-369">The number of weights per kernel is *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape**\[2] = 1 + 1 * 5 * 5 = 26. Or 26 * 50 = 1300*.</span></span>
* <span data-ttu-id="ae093-370">Her Gizli katmandaki düğüm şu şekilde hesaplayabilirsiniz:</span><span class="sxs-lookup"><span data-stu-id="ae093-370">You can calculate the nodes in each hidden layer as follows:</span></span>
  * <span data-ttu-id="ae093-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="ae093-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span></span>
  * <span data-ttu-id="ae093-372">**NodeCount**\[= 1] (13-5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="ae093-372">**NodeCount**\[1] = (13 - 5) / 2 + 1 = 5.</span></span> 
  * <span data-ttu-id="ae093-373">**NodeCount**\[2] (13-5) = / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="ae093-373">**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5.</span></span> 
* <span data-ttu-id="ae093-374">Toplam düğümlerin sayısının katmanının bildirilen boyut kullanılarak hesaplanabilir [50, 5, 5], şu şekilde:  ***MapCount** * **NodeCount**\[0] * **NodeCount**\[1] * **NodeCount**\[= 2] 10 * 5 * 5 * 5*</span><span class="sxs-lookup"><span data-stu-id="ae093-374">The total number of nodes can be calculated by using the declared dimensionality of the layer, [50, 5, 5], as follows: ***MapCount** * **NodeCount**\[0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span></span>
* <span data-ttu-id="ae093-375">Çünkü **paylaşım**[d] değeri: False yalnızca *d 0 ==*, tekrar sayısı  ***MapCount** * **NodeCount** \[0] = 10 * 5 = 50*.</span><span class="sxs-lookup"><span data-stu-id="ae093-375">Because **Sharing**[d] is False only for *d == 0*, the number of kernels is ***MapCount** * **NodeCount**\[0] = 10 * 5 = 50*.</span></span> 

## <a name="acknowledgements"></a><span data-ttu-id="ae093-376">Katkıda Bulunanlar</span><span class="sxs-lookup"><span data-stu-id="ae093-376">Acknowledgements</span></span>
<span data-ttu-id="ae093-377">Sinir ağları mimarisini özelleştirmek için Net # dili Microsoft'taki Shon Katzenberger (Mimarı, Machine Learning) ve Alexey Kamenev (yazılım mühendisi, Microsoft Research) tarafından geliştirilmiştir.</span><span class="sxs-lookup"><span data-stu-id="ae093-377">The Net# language for customizing the architecture of neural networks was developed at Microsoft by Shon Katzenberger (Architect, Machine Learning) and Alexey Kamenev (Software Engineer, Microsoft Research).</span></span> <span data-ttu-id="ae093-378">Machine learning projeleri ve görüntü algılama metin analizi arasında değişen uygulamalar için dahili olarak kullanılır.</span><span class="sxs-lookup"><span data-stu-id="ae093-378">It is used internally for machine learning projects and applications ranging from image detection to text analytics.</span></span> <span data-ttu-id="ae093-379">Daha fazla bilgi için bkz: [sinir ağ Azure ML - giriş Net # içinde](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span><span class="sxs-lookup"><span data-stu-id="ae093-379">For more information, see [Neural Nets in Azure ML - Introduction to Net#](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span></span>

<span data-ttu-id="ae093-380">[1]:./media/machine-learning-azure-ml-netsharp-reference-guide/formula_large.gif</span><span class="sxs-lookup"><span data-stu-id="ae093-380">[1]:./media/machine-learning-azure-ml-netsharp-reference-guide/formula_large.gif</span></span>

