---
title: "Etkinlik performans ve ayarlama Kılavuzu kopyalama | Microsoft Docs"
description: "Kopyalama etkinliği kullandığınızda, Azure Data factory'de veri taşımayı performansını etkileyen anahtar Etkenler hakkında bilgi edinin."
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 4b9a6a4f-8cf5-4e0a-a06f-8133a2b7bc58
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/10/2017
ms.author: jingwang
ms.openlocfilehash: 2779655aee3af3a351b30f18b4c9d9918e9f2210
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: tr-TR
ms.lasthandoff: 08/29/2017
---
# <a name="copy-activity-performance-and-tuning-guide"></a><span data-ttu-id="48eea-103">Etkinlik performans ve ayarlama Kılavuzu kopyalayın</span><span class="sxs-lookup"><span data-stu-id="48eea-103">Copy Activity performance and tuning guide</span></span>
<span data-ttu-id="48eea-104">Azure Data Factory kopyalama etkinliği çözümü bir birinci sınıf güvenli, güvenilir ve yüksek performanslı veri yükleme sunar.</span><span class="sxs-lookup"><span data-stu-id="48eea-104">Azure Data Factory Copy Activity delivers a first-class secure, reliable, and high-performance data loading solution.</span></span> <span data-ttu-id="48eea-105">Zengin bulut çeşitli her gün terabayt veri onlarca kopyaya sağlar ve şirket içi veri depolarına.</span><span class="sxs-lookup"><span data-stu-id="48eea-105">It enables you to copy tens of terabytes of data every day across a rich variety of cloud and on-premises data stores.</span></span> <span data-ttu-id="48eea-106">Üstün hızlı veri performans yükleme anahtarıdır odaklanmak çekirdek "büyük veri" sorunu emin olmak için: Gelişmiş analiz çözümleri oluşturmak ve tüm bu verilerden ayrıntılı Öngörüler alma.</span><span class="sxs-lookup"><span data-stu-id="48eea-106">Blazing-fast data loading performance is key to ensure you can focus on the core “big data” problem: building advanced analytics solutions and getting deep insights from all that data.</span></span>

<span data-ttu-id="48eea-107">Azure veri depolama ve veri ambarı çözümleri Kurumsal düzeyde bir dizi sağlar ve yüksek oranda iyileştirilmiş bir veri yapılandırmak ve ayarlamak kolay deneyimi yükleme kopyalama etkinliği sunar.</span><span class="sxs-lookup"><span data-stu-id="48eea-107">Azure provides a set of enterprise-grade data storage and data warehouse solutions, and Copy Activity offers a highly optimized data loading experience that is easy to configure and set up.</span></span> <span data-ttu-id="48eea-108">Yalnızca tek kopyalama etkinliği ile elde edebilirsiniz:</span><span class="sxs-lookup"><span data-stu-id="48eea-108">With just a single copy activity, you can achieve:</span></span>

* <span data-ttu-id="48eea-109">Verileri yükleme **Azure SQL Data Warehouse** adresindeki **1,2 GB/sn**.</span><span class="sxs-lookup"><span data-stu-id="48eea-109">Loading data into **Azure SQL Data Warehouse** at **1.2 GBps**.</span></span> <span data-ttu-id="48eea-110">Kullanım örneği ile bir anlatım için bkz: [1 TB altında 15 dakika Azure Data Factory ile Azure SQL Data Warehouse'a veri yükleme](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="48eea-110">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
* <span data-ttu-id="48eea-111">Verileri yükleme **Azure Blob Depolama** adresindeki **1.0 GB/sn**</span><span class="sxs-lookup"><span data-stu-id="48eea-111">Loading data into **Azure Blob storage** at **1.0 GBps**</span></span>
* <span data-ttu-id="48eea-112">Verileri yükleme **Azure Data Lake Store** adresindeki **1.0 GB/sn**</span><span class="sxs-lookup"><span data-stu-id="48eea-112">Loading data into **Azure Data Lake Store** at **1.0 GBps**</span></span>

<span data-ttu-id="48eea-113">Bu makalede açıklanır:</span><span class="sxs-lookup"><span data-stu-id="48eea-113">This article describes:</span></span>

* <span data-ttu-id="48eea-114">[Performans referans numaraları](#performance-reference) desteklenen projenizi; planlamanıza yardımcı olması için kaynak ve havuz veri depoları</span><span class="sxs-lookup"><span data-stu-id="48eea-114">[Performance reference numbers](#performance-reference) for supported source and sink data stores to help you plan your project;</span></span>
* <span data-ttu-id="48eea-115">Kopya işleme dahil olmak üzere farklı senaryolarda artırabilir özellikleri [bulut veri taşıma birimleri](#cloud-data-movement-units), [paralel kopyalama](#parallel-copy), ve [kopyalama hazırlanan](#staged-copy);</span><span class="sxs-lookup"><span data-stu-id="48eea-115">Features that can boost the copy throughput in different scenarios, including [cloud data movement units](#cloud-data-movement-units), [parallel copy](#parallel-copy), and [staged Copy](#staged-copy);</span></span>
* <span data-ttu-id="48eea-116">[Performans ayarlama yönergeleri](#performance-tuning-steps) performans ve kopyalama performansını etkileyebilir anahtar Etkenler ayarlama konusunda.</span><span class="sxs-lookup"><span data-stu-id="48eea-116">[Performance tuning guidance](#performance-tuning-steps) on how to tune the performance and the key factors that can impact copy performance.</span></span>

> [!NOTE]
> <span data-ttu-id="48eea-117">Genel kopyalama etkinliği ile bilmiyorsanız, bkz: [Kopyala etkinliğini kullanarak veri taşıma](data-factory-data-movement-activities.md) bu makaleyi okumadan önce.</span><span class="sxs-lookup"><span data-stu-id="48eea-117">If you are not familiar with Copy Activity in general, see [Move data by using Copy Activity](data-factory-data-movement-activities.md) before reading this article.</span></span>
>

## <a name="performance-reference"></a><span data-ttu-id="48eea-118">Performans başvurusu</span><span class="sxs-lookup"><span data-stu-id="48eea-118">Performance reference</span></span>

<span data-ttu-id="48eea-119">Bir başvuru olarak aşağıdaki tabloyu şirket içi testlere göre verilen kaynak ve havuz çiftleri için MB/sn olarak kopyalama üretilen iş sayısını gösterir.</span><span class="sxs-lookup"><span data-stu-id="48eea-119">As a reference, below table shows the copy throughput number in MBps for the given source and sink pairs based on in-house testing.</span></span> <span data-ttu-id="48eea-120">Karşılaştırma için ayrıca farklı ayarlarını gösterir [bulut veri taşıma birimleri](#cloud-data-movement-units) veya [veri yönetimi ağ geçidi ölçeklenebilirlik](data-factory-data-management-gateway-high-availability-scalability.md) (birden çok ağ geçidi düğümler) kopyalama performansına yardımcı olabilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-120">For comparison, it also demonstrates how different settings of [cloud data movement units](#cloud-data-movement-units) or [Data Management Gateway scalability](data-factory-data-management-gateway-high-availability-scalability.md) (multiple gateway nodes) can help on copy performance.</span></span>

![Performans Matrisi](./media/data-factory-copy-activity-performance/CopyPerfRef.png)


<span data-ttu-id="48eea-122">**Dikkat edilecek noktalar:**</span><span class="sxs-lookup"><span data-stu-id="48eea-122">**Points to note:**</span></span>
* <span data-ttu-id="48eea-123">Verimlilik, aşağıdaki formül kullanılarak hesaplanır: [verilerin boyutu okuma kaynağından] / [kopyalama çalışma süresini etkinliği].</span><span class="sxs-lookup"><span data-stu-id="48eea-123">Throughput is calculated by using the following formula: [size of data read from source]/[Copy Activity run duration].</span></span>
* <span data-ttu-id="48eea-124">Tabloda yer alan performans başvuru numaralarını kullanarak ölçülen [TPC-H](http://www.tpc.org/tpch/) veri kümesi bir tek kopyalama etkinliğinde çalıştırın.</span><span class="sxs-lookup"><span data-stu-id="48eea-124">The performance reference numbers in the table were measured using [TPC-H](http://www.tpc.org/tpch/) data set in a single copy activity run.</span></span>
* <span data-ttu-id="48eea-125">Azure veri depolarında kaynak ve havuz aynı Azure bölgesinde ' dir.</span><span class="sxs-lookup"><span data-stu-id="48eea-125">In Azure data stores, the source and sink are in the same Azure region.</span></span>
* <span data-ttu-id="48eea-126">Karma kopyalama şirket içi ve bulut arasında veri depolarına, her ağ geçidi düğümü altındaki belirtimi ile şirket içi veri deposundan ayrı bir makinede çalışıyordu.</span><span class="sxs-lookup"><span data-stu-id="48eea-126">For hybrid copy between on-premises and cloud data stores, each gateway node was running on a machine that was separate from the on-premises data store with below specification.</span></span> <span data-ttu-id="48eea-127">Tek bir etkinliğin ağ geçidinde çalıştırırken, kopyalama işlemi yalnızca küçük bir bölümü test makinenin CPU, bellek veya ağ bant genişliği tüketilen.</span><span class="sxs-lookup"><span data-stu-id="48eea-127">When a single activity was running on gateway, the copy operation consumed only a small portion of the test machine's CPU, memory, or network bandwidth.</span></span> <span data-ttu-id="48eea-128">' Dan daha fazla bilgi edinin [göz önünde bulundurarak veri yönetimi ağ geçidi için](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="48eea-128">Learn more from [consideration for Data Management Gateway](#considerations-for-data-management-gateway).</span></span>
    <table>
    <tr>
        <td><span data-ttu-id="48eea-129">CPU</span><span class="sxs-lookup"><span data-stu-id="48eea-129">CPU</span></span></td>
        <td><span data-ttu-id="48eea-130">32 2.20 GHz Intel Xeon E5-2660 v2 çekirdek</span><span class="sxs-lookup"><span data-stu-id="48eea-130">32 cores 2.20 GHz Intel Xeon E5-2660 v2</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="48eea-131">Bellek</span><span class="sxs-lookup"><span data-stu-id="48eea-131">Memory</span></span></td>
        <td><span data-ttu-id="48eea-132">128 GB</span><span class="sxs-lookup"><span data-stu-id="48eea-132">128 GB</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="48eea-133">Ağ</span><span class="sxs-lookup"><span data-stu-id="48eea-133">Network</span></span></td>
        <td><span data-ttu-id="48eea-134">Internet arabirimi: 10 GB/sn; intranet arabiriminde: 40 GB/sn</span><span class="sxs-lookup"><span data-stu-id="48eea-134">Internet interface: 10 Gbps; intranet interface: 40 Gbps</span></span></td>
    </tr>
    </table>


> [!TIP]
> <span data-ttu-id="48eea-135">Varsayılandan daha fazla veri taşıma birimleri (DMUs) yararlanarak daha yüksek verimlilik elde edebilirsiniz 32 Bulut Bulut kopyalama etkinliği çalıştırmak için en fazla DMUs.</span><span class="sxs-lookup"><span data-stu-id="48eea-135">You can achieve higher throughput by leveraging more data movement units (DMUs) than the default maximum DMUs, which is 32 for a cloud-to-cloud copy activity run.</span></span> <span data-ttu-id="48eea-136">Örneğin, 100 DMUs ile Azure Blob kopyalama verileri Azure Data Lake Store içine elde edebilirsiniz **1.0GBps**.</span><span class="sxs-lookup"><span data-stu-id="48eea-136">For example, with 100 DMUs, you can achieve copying data from Azure Blob into Azure Data Lake Store at **1.0GBps**.</span></span> <span data-ttu-id="48eea-137">Bkz: [bulut veri taşıma birimleri](#cloud-data-movement-units) bu özellik ve desteklenen senaryo hakkındaki ayrıntılar için bölüm.</span><span class="sxs-lookup"><span data-stu-id="48eea-137">See the [Cloud data movement units](#cloud-data-movement-units) section for details about this feature and the supported scenario.</span></span> <span data-ttu-id="48eea-138">Kişi [Azure Destek](https://azure.microsoft.com/support/) daha fazla DMUs istemek için.</span><span class="sxs-lookup"><span data-stu-id="48eea-138">Contact [Azure support](https://azure.microsoft.com/support/) to request more DMUs.</span></span>

## <a name="parallel-copy"></a><span data-ttu-id="48eea-139">Paralel kopyalama</span><span class="sxs-lookup"><span data-stu-id="48eea-139">Parallel copy</span></span>
<span data-ttu-id="48eea-140">Veri kaynağından okumak veya hedef veri yazma **çalıştırmak kopyalama etkinliği içinde paralel**.</span><span class="sxs-lookup"><span data-stu-id="48eea-140">You can read data from the source or write data to the destination **in parallel within a Copy Activity run**.</span></span> <span data-ttu-id="48eea-141">Bu özellik, bir kopyalama işlemi verimliliğini artırır ve verilerin taşınması için gereken süreyi azaltır.</span><span class="sxs-lookup"><span data-stu-id="48eea-141">This feature enhances the throughput of a copy operation and reduces the time it takes to move data.</span></span>

<span data-ttu-id="48eea-142">Bu ayar farklıdır **eşzamanlılık** etkinlik tanımının bir özellik.</span><span class="sxs-lookup"><span data-stu-id="48eea-142">This setting is different from the **concurrency** property in the activity definition.</span></span> <span data-ttu-id="48eea-143">**Eşzamanlılık** özelliği sayısını belirler **eşzamanlı kopyalama etkinliği çalışır** farklı etkinlik Windows (1 AM için 2: 00, 2 AM 3 AM, AM 3 ve 4 AM vb.) verileri işlemek için.</span><span class="sxs-lookup"><span data-stu-id="48eea-143">The **concurrency** property determines the number of **concurrent Copy Activity runs** to process data from different activity windows (1 AM to 2 AM, 2 AM to 3 AM, 3 AM to 4 AM, and so on).</span></span> <span data-ttu-id="48eea-144">Bu özellik, geçmiş bir yükleme gerçekleştirmek yararlıdır.</span><span class="sxs-lookup"><span data-stu-id="48eea-144">This capability is helpful when you perform a historical load.</span></span> <span data-ttu-id="48eea-145">Paralel kopyasını yetenek uygulandığı bir **tek Etkinlik**.</span><span class="sxs-lookup"><span data-stu-id="48eea-145">The parallel copy capability applies to a **single activity run**.</span></span>

<span data-ttu-id="48eea-146">Bir örnek senaryo bakalım.</span><span class="sxs-lookup"><span data-stu-id="48eea-146">Let's look at a sample scenario.</span></span> <span data-ttu-id="48eea-147">Aşağıdaki örnekte, birden çok dilim Geçmişten işlenmesi gerekir.</span><span class="sxs-lookup"><span data-stu-id="48eea-147">In the following example, multiple slices from the past need to be processed.</span></span> <span data-ttu-id="48eea-148">Data Factory kopyalama etkinliği (etkinlik Çalıştır) bir örneği her dilim için çalışır:</span><span class="sxs-lookup"><span data-stu-id="48eea-148">Data Factory runs an instance of Copy Activity (an activity run) for each slice:</span></span>

* <span data-ttu-id="48eea-149">Veri dilimi ilk etkinliği penceresinden (1 AM için 2: 00) == > etkinliği çalıştırmak 1</span><span class="sxs-lookup"><span data-stu-id="48eea-149">The data slice from the first activity window (1 AM to 2 AM) ==> Activity run 1</span></span>
* <span data-ttu-id="48eea-150">Veri dilimi ikinci etkinliği penceresinden (2: 00 için 3 AM) == > etkinliği çalıştırmak 2</span><span class="sxs-lookup"><span data-stu-id="48eea-150">The data slice from the second activity window (2 AM to 3 AM) ==> Activity run 2</span></span>
* <span data-ttu-id="48eea-151">Veri dilimi ikinci etkinliği penceresinden (3 AM için 4 AM) == > etkinliği çalıştırmak 3</span><span class="sxs-lookup"><span data-stu-id="48eea-151">The data slice from the second activity window (3 AM to 4 AM) ==> Activity run 3</span></span>

<span data-ttu-id="48eea-152">Etki alanları bu hiyerarşi sıralamasıyla devam eder.</span><span class="sxs-lookup"><span data-stu-id="48eea-152">And so on.</span></span>

<span data-ttu-id="48eea-153">Bu örnekte, zaman **eşzamanlılık** değeri 2'ye ayarlanır **etkinliği çalıştırmak 1** ve **etkinliği çalıştırmak 2** iki etkinlik Windows'dan veri kopyalama **eşzamanlı olarak** veri taşıma performansını artırmak için.</span><span class="sxs-lookup"><span data-stu-id="48eea-153">In this example, when the **concurrency** value is set to 2, **Activity run 1** and **Activity run 2** copy data from two activity windows **concurrently** to improve data movement performance.</span></span> <span data-ttu-id="48eea-154">Birden çok dosya 1 Çalıştır etkinliği ile ilişkiliyse, ancak veri taşıma hizmeti dosyaları kaynak sunucudan hedef bir dosya için birer birer kopyalar.</span><span class="sxs-lookup"><span data-stu-id="48eea-154">However, if multiple files are associated with Activity run 1, the data movement service copies files from the source to the destination one file at a time.</span></span>

### <a name="cloud-data-movement-units"></a><span data-ttu-id="48eea-155">Bulut veri taşıma birimleri</span><span class="sxs-lookup"><span data-stu-id="48eea-155">Cloud data movement units</span></span>
<span data-ttu-id="48eea-156">A **bulut veri taşıma birimi (DMU)** veri fabrikası'nda tek bir birimi (CPU, bellek ve ağ kaynağı ayırma birleşimi) gücünü temsil eden bir ölçüdür.</span><span class="sxs-lookup"><span data-stu-id="48eea-156">A **cloud data movement unit (DMU)** is a measure that represents the power (a combination of CPU, memory, and network resource allocation) of a single unit in Data Factory.</span></span> <span data-ttu-id="48eea-157">Bir DMU Bulut Bulut kopyalama işlemi, ancak bir karma kopyalama kullanılıyor olabilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-157">A DMU might be used in a cloud-to-cloud copy operation, but not in a hybrid copy.</span></span>

<span data-ttu-id="48eea-158">Varsayılan olarak, veri fabrikası çalıştıran tek bir kopyalama etkinliği gerçekleştirmek için tek bulut DMU kullanır.</span><span class="sxs-lookup"><span data-stu-id="48eea-158">By default, Data Factory uses a single cloud DMU to perform a single Copy Activity run.</span></span> <span data-ttu-id="48eea-159">Bu varsayılanı geçersiz kılmak için için bir değer belirtin **cloudDataMovementUnits** şekilde özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-159">To override this default, specify a value for the **cloudDataMovementUnits** property as follows.</span></span> <span data-ttu-id="48eea-160">Daha fazla birimi belirli kopya kaynak ve havuz için yapılandırdığınızda alabilirsiniz performans kazancı düzeyi hakkında bilgi için bkz [Performans başvurusu](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="48eea-160">For information about the level of performance gain you might get when you configure more units for a specific copy source and sink, see the [performance reference](#performance-reference).</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```
<span data-ttu-id="48eea-161">**İzin verilen değerler** için **cloudDataMovementUnits** özelliği olan 1 (varsayılan), 2, 4, 8, 16 ve 32.</span><span class="sxs-lookup"><span data-stu-id="48eea-161">The **allowed values** for the **cloudDataMovementUnits** property are 1 (default), 2, 4, 8, 16, 32.</span></span> <span data-ttu-id="48eea-162">**Bulut DMUs gerçek sayısını** eşit veya bu değerden azsa yapılandırılan, veri deseni bağlı olarak, kopyalama işlemini çalışma zamanında kullanır.</span><span class="sxs-lookup"><span data-stu-id="48eea-162">The **actual number of cloud DMUs** that the copy operation uses at run time is equal to or less than the configured value, depending on your data pattern.</span></span>

> [!NOTE]
> <span data-ttu-id="48eea-163">Daha fazla bulut DMUs için daha yüksek işleme gerekiyorsa başvurun [Azure Destek](https://azure.microsoft.com/support/).</span><span class="sxs-lookup"><span data-stu-id="48eea-163">If you need more cloud DMUs for a higher throughput, contact [Azure support](https://azure.microsoft.com/support/).</span></span> <span data-ttu-id="48eea-164">8 ayarlama ve yukarıdaki şu anda yalnızca çalışır, **Blob Depolama/Data Lake Store/Azure için Blob Depolama/Data Lake Store/Amazon S3/bulut FTP/bulut SFTP birden çok dosya kopyalama SQL veritabanı**.</span><span class="sxs-lookup"><span data-stu-id="48eea-164">Setting of 8 and above currently works only when you **copy multiple files from Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP to Blob storage/Data Lake Store/Azure SQL Database**.</span></span>
>

### <a name="parallelcopies"></a><span data-ttu-id="48eea-165">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="48eea-165">parallelCopies</span></span>
<span data-ttu-id="48eea-166">Kullanabileceğiniz **parallelCopies** kullanmak için kopyalama etkinliği istediğiniz paralellik belirtmek için özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-166">You can use the **parallelCopies** property to indicate the parallelism that you want Copy Activity to use.</span></span> <span data-ttu-id="48eea-167">Bu özelliğin kaynağınızdan okuma veya paralel, havuz veri depolarında yazma kopyalama etkinliği içinde iş parçacığı sayısı olarak düşünebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-167">You can think of this property as the maximum number of threads within Copy Activity that can read from your source or write to your sink data stores in parallel.</span></span>

<span data-ttu-id="48eea-168">Her kopya Çalıştır etkinliği için veri fabrikası veri depolamak ve hedef veri depolamak kaynaktan veri kopyalamak için kullanılacak paralel kopya sayısını belirler.</span><span class="sxs-lookup"><span data-stu-id="48eea-168">For each Copy Activity run, Data Factory determines the number of parallel copies to use to copy data from the source data store and to the destination data store.</span></span> <span data-ttu-id="48eea-169">Kullandığı paralel kopya varsayılan sayısını kaynak ve kullandığınız havuz türüne bağlıdır.</span><span class="sxs-lookup"><span data-stu-id="48eea-169">The default number of parallel copies that it uses depends on the type of source and sink that you are using.</span></span>  

| <span data-ttu-id="48eea-170">Kaynak ve havuz</span><span class="sxs-lookup"><span data-stu-id="48eea-170">Source and sink</span></span> | <span data-ttu-id="48eea-171">Hizmeti tarafından belirlenen varsayılan paralel kopya sayısı</span><span class="sxs-lookup"><span data-stu-id="48eea-171">Default parallel copy count determined by service</span></span> |
| --- | --- |
| <span data-ttu-id="48eea-172">Dosya tabanlı depolar (Blob storage; arasında veri kopyalama Data Lake Store; Amazon S3; bir şirket içi dosya sistemi; bir şirket içi HDFS)</span><span class="sxs-lookup"><span data-stu-id="48eea-172">Copy data between file-based stores (Blob storage; Data Lake Store; Amazon S3; an on-premises file system; an on-premises HDFS)</span></span> |<span data-ttu-id="48eea-173">1 ile 32 arasında.</span><span class="sxs-lookup"><span data-stu-id="48eea-173">Between 1 and 32.</span></span> <span data-ttu-id="48eea-174">İki bulut veri depolarını veya fiziksel yapılandırma (veya bir şirket içi veri deposundaki verileri kopyalamak için) bir karma kopyalama için kullanılan ağ geçidi makinesinin arasında veri kopyalamak için kullanılan dosyalarının boyutunu ve bulut veri taşıma birimlerinin (DMUs) bağlıdır.</span><span class="sxs-lookup"><span data-stu-id="48eea-174">Depends on the size of the files and the number of cloud data movement units (DMUs) used to copy data between two cloud data stores, or the physical configuration of the Gateway machine used for a hybrid copy (to copy data to or from an on-premises data store).</span></span> |
| <span data-ttu-id="48eea-175">Veri kopyalamak **tüm kaynak veri deposu Azure tablo depolaması**</span><span class="sxs-lookup"><span data-stu-id="48eea-175">Copy data from **any source data store to Azure Table storage**</span></span> |<span data-ttu-id="48eea-176">4</span><span class="sxs-lookup"><span data-stu-id="48eea-176">4</span></span> |
| <span data-ttu-id="48eea-177">Diğer tüm kaynak ve havuz çiftleri</span><span class="sxs-lookup"><span data-stu-id="48eea-177">All other source and sink pairs</span></span> |<span data-ttu-id="48eea-178">1</span><span class="sxs-lookup"><span data-stu-id="48eea-178">1</span></span> |

<span data-ttu-id="48eea-179">Genellikle, varsayılan davranışı en iyi verimlilik vermesi gerekir.</span><span class="sxs-lookup"><span data-stu-id="48eea-179">Usually, the default behavior should give you the best throughput.</span></span> <span data-ttu-id="48eea-180">Ancak, verilerinizi barındıran makineler üzerindeki yükü denetlemek için depolar veya kopya performansı ayarlamak için varsayılan değeri geçersiz kılmak ve için bir değer belirtmek seçebilirsiniz **parallelCopies** özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-180">However, to control the load on machines that host your data stores, or to tune copy performance, you may choose to override the default value and specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="48eea-181">Değer 1 ile 32 (her ikisi de dahil) arasında olmalıdır.</span><span class="sxs-lookup"><span data-stu-id="48eea-181">The value must be between 1 and 32 (both inclusive).</span></span> <span data-ttu-id="48eea-182">Çalışma zamanında, en iyi performans için kopyalama etkinliği ayarladığınız değerine eşit veya daha küçük bir değer kullanır.</span><span class="sxs-lookup"><span data-stu-id="48eea-182">At run time, for the best performance, Copy Activity uses a value that is less than or equal to the value that you set.</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 8
        }
    }
]
```
<span data-ttu-id="48eea-183">Dikkat edilecek noktalar:</span><span class="sxs-lookup"><span data-stu-id="48eea-183">Points to note:</span></span>

* <span data-ttu-id="48eea-184">Veri depoları, dosya tabanlı arasında kopyaladığınızda **parallelCopies** dosya düzeyinde paralellik belirleyin.</span><span class="sxs-lookup"><span data-stu-id="48eea-184">When you copy data between file-based stores, the **parallelCopies** determine the parallelism at the file level.</span></span> <span data-ttu-id="48eea-185">Tek bir dosyada Öbekleme altında otomatik ve şeffaf şekilde olacağını ve verileri paralel ve parallelCopies resme yüklemek için belirtilen kaynak veri deposu türü için en iyi uygun öbek boyutu kullanmak için tasarlanmıştır.</span><span class="sxs-lookup"><span data-stu-id="48eea-185">The chunking within a single file would happen underneath automatically and transparently, and it's designed to use the best suitable chunk size for a given source data store type to load data in parallel and orthogonal to parallelCopies.</span></span> <span data-ttu-id="48eea-186">Gerçek çalışma zamanında kopyalama işlemi için veri taşıma hizmeti kullanan paralel kopyaları sahip dosyaların sayısı en çok sayısıdır.</span><span class="sxs-lookup"><span data-stu-id="48eea-186">The actual number of parallel copies the data movement service uses for the copy operation at run time is no more than the number of files you have.</span></span> <span data-ttu-id="48eea-187">Kopyalama davranışını ise **mergeFile**, kopyalama etkinliği, dosya düzeyinde paralellik avantajlarından alamaz.</span><span class="sxs-lookup"><span data-stu-id="48eea-187">If the copy behavior is **mergeFile**, Copy Activity cannot take advantage of file-level parallelism.</span></span>
* <span data-ttu-id="48eea-188">İçin bir değer belirtirseniz **parallelCopies** özelliği, bir karma kopyalama ise yük arttıkça, kaynak ve havuz veri depoları ve ağ geçidi için göz önünde bulundurun.</span><span class="sxs-lookup"><span data-stu-id="48eea-188">When you specify a value for the **parallelCopies** property, consider the load increase on your source and sink data stores, and to gateway if it is a hybrid copy.</span></span> <span data-ttu-id="48eea-189">Bu, özellikle birden çok etkinlikleri veya aynı veri deposu karşı çalıştırmak aynı etkinliklerin eşzamanlı çalışır olduğunda gerçekleşir.</span><span class="sxs-lookup"><span data-stu-id="48eea-189">This happens especially when you have multiple activities or concurrent runs of the same activities that run against the same data store.</span></span> <span data-ttu-id="48eea-190">Veri deposu ya da ağ geçidi yük ile doludur fark ederseniz, azaltma **parallelCopies** yük hafifletmek için değer.</span><span class="sxs-lookup"><span data-stu-id="48eea-190">If you notice that either the data store or Gateway is overwhelmed with the load, decrease the **parallelCopies** value to relieve the load.</span></span>
* <span data-ttu-id="48eea-191">Dosya tabanlı depoları için dosya tabanlı olmayan depoları veri kopyalama, veri taşıma Hizmeti'nde yoksayar **parallelCopies** özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-191">When you copy data from stores that are not file-based to stores that are file-based, the data movement service ignores the **parallelCopies** property.</span></span> <span data-ttu-id="48eea-192">Paralellik belirtilmiş olsa bile, bu durumda uygulanmıyor.</span><span class="sxs-lookup"><span data-stu-id="48eea-192">Even if parallelism is specified, it's not applied in this case.</span></span>

> [!NOTE]
> <span data-ttu-id="48eea-193">Kullanmak için veri yönetimi ağ geçidi 1.11 veya sonraki bir sürümü kullanmanız gerekir **parallelCopies** karma kopyalama yaptığınızda özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-193">You must use Data Management Gateway version 1.11 or later to use the **parallelCopies** feature when you do a hybrid copy.</span></span>
>
>

<span data-ttu-id="48eea-194">Bu iki özellik daha iyi kullanımı ve veri taşıma verimliliği artırmak için bkz: [örnek kullanım durumları](#case-study-use-parallel-copy).</span><span class="sxs-lookup"><span data-stu-id="48eea-194">To better use these two properties, and to enhance your data movement throughput, see the [sample use cases](#case-study-use-parallel-copy).</span></span> <span data-ttu-id="48eea-195">Yapılandırmanız gerekmez **parallelCopies** varsayılan davranışı yararlanmak için.</span><span class="sxs-lookup"><span data-stu-id="48eea-195">You don't need to configure **parallelCopies** to take advantage of the default behavior.</span></span> <span data-ttu-id="48eea-196">Yapılandırırsanız ve **parallelCopies** birden çok bulut DMUs değil tam olarak kullanılan çok küçük.</span><span class="sxs-lookup"><span data-stu-id="48eea-196">If you do configure and **parallelCopies** is too small, multiple cloud DMUs might not be fully utilized.</span></span>  

### <a name="billing-impact"></a><span data-ttu-id="48eea-197">Faturalama etkisi</span><span class="sxs-lookup"><span data-stu-id="48eea-197">Billing impact</span></span>
<span data-ttu-id="48eea-198">Bunun **önemli** tabanlı kopyalama işlemi toplam zamanında ücretlendirilen unutmayın.</span><span class="sxs-lookup"><span data-stu-id="48eea-198">It's **important** to remember that you are charged based on the total time of the copy operation.</span></span> <span data-ttu-id="48eea-199">Bir kopyalama işi bir saat bir bulut birimle çekmek için kullanılan ve şimdi dört bulut birimleri ile 15 dakika sürer, genel fatura neredeyse aynı kalır.</span><span class="sxs-lookup"><span data-stu-id="48eea-199">If a copy job used to take one hour with one cloud unit and now it takes 15 minutes with four cloud units, the overall bill remains almost the same.</span></span> <span data-ttu-id="48eea-200">Örneğin, dört bulut birimleri kullanın.</span><span class="sxs-lookup"><span data-stu-id="48eea-200">For example, you use four cloud units.</span></span> <span data-ttu-id="48eea-201">İlk bulut birimi 10 dakika, ikincisi harcadığı 10 dakika, 5 dakika, üçüncü bir ve 5 dakika, dördüncü bir tüm bir kopyalama etkinliğinde çalıştırın.</span><span class="sxs-lookup"><span data-stu-id="48eea-201">The first cloud unit spends 10 minutes, the second one, 10 minutes, the third one, 5 minutes, and the fourth one, 5 minutes, all in one Copy Activity run.</span></span> <span data-ttu-id="48eea-202">10 + 10 + 5 + 5 = 30 dakika toplam copy (veri taşıma) saat için sizden ücret kesilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-202">You are charged for the total copy (data movement) time, which is 10 + 10 + 5 + 5 = 30 minutes.</span></span> <span data-ttu-id="48eea-203">Kullanarak **parallelCopies** faturalama etkilemez.</span><span class="sxs-lookup"><span data-stu-id="48eea-203">Using **parallelCopies** does not affect billing.</span></span>

## <a name="staged-copy"></a><span data-ttu-id="48eea-204">Hazırlanan kopyalama</span><span class="sxs-lookup"><span data-stu-id="48eea-204">Staged copy</span></span>
<span data-ttu-id="48eea-205">Bir havuz veri deposu için bir kaynak veri deposundan verileri kopyaladığınızda, geçici bir hazırlama deposu olarak Blob storage kullanmayı seçebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-205">When you copy data from a source data store to a sink data store, you might choose to use Blob storage as an interim staging store.</span></span> <span data-ttu-id="48eea-206">Hazırlama aşağıdaki durumlarda kullanışlıdır:</span><span class="sxs-lookup"><span data-stu-id="48eea-206">Staging is especially useful in the following cases:</span></span>

1. <span data-ttu-id="48eea-207">**PolyBase aracılığıyla SQL veri ambarında verileri çeşitli veri depoları alma istediğiniz**.</span><span class="sxs-lookup"><span data-stu-id="48eea-207">**You want to ingest data from various data stores into SQL Data Warehouse via PolyBase**.</span></span> <span data-ttu-id="48eea-208">SQL veri ambarı PolyBase büyük miktarda veri SQL Data Warehouse'a veri yükleme için yüksek verimlilik mekanizması olarak kullanır.</span><span class="sxs-lookup"><span data-stu-id="48eea-208">SQL Data Warehouse uses PolyBase as a high-throughput mechanism to load a large amount of data into SQL Data Warehouse.</span></span> <span data-ttu-id="48eea-209">Ancak, veri kaynağını Blob depolama alanına olmalıdır ve ek ölçütleri karşılaması gerekir.</span><span class="sxs-lookup"><span data-stu-id="48eea-209">However, the source data must be in Blob storage, and it must meet additional criteria.</span></span> <span data-ttu-id="48eea-210">Dışında bir Blob Depolama veri deposundan veri yüklediğinizde, verileri aracılığıyla geçici hazırlama Blob depolamaya kopyalama etkinleştirebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-210">When you load data from a data store other than Blob storage, you can activate data copying via interim staging Blob storage.</span></span> <span data-ttu-id="48eea-211">Bu durumda, veri fabrikası PolyBase gereksinimlerini karşıladığından emin olmak için gerekli veri dönüşümleri gerçekleştirir.</span><span class="sxs-lookup"><span data-stu-id="48eea-211">In that case, Data Factory performs the required data transformations to ensure that it meets the requirements of PolyBase.</span></span> <span data-ttu-id="48eea-212">Ardından SQL Data Warehouse'a veri yüklemek için PolyBase kullanır.</span><span class="sxs-lookup"><span data-stu-id="48eea-212">Then it uses PolyBase to load data into SQL Data Warehouse.</span></span> <span data-ttu-id="48eea-213">Daha fazla ayrıntı için bkz: [kullanım Azure SQL Data Warehouse'a veri yüklemek için PolyBase](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span><span class="sxs-lookup"><span data-stu-id="48eea-213">For more details, see [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span></span> <span data-ttu-id="48eea-214">Kullanım örneği ile bir anlatım için bkz: [1 TB altında 15 dakika Azure Data Factory ile Azure SQL Data Warehouse'a veri yükleme](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="48eea-214">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
2. <span data-ttu-id="48eea-215">**Bazen bir karma veri taşımayı gerçekleştirmek için biraz zaman alır (diğer bir deyişle, arasında bir şirket içi veri kopyalamak için depolama ve bulut verilerini depolama) bir yavaş ağ bağlantısı üzerinden**.</span><span class="sxs-lookup"><span data-stu-id="48eea-215">**Sometimes it takes a while to perform a hybrid data movement (that is, to copy between an on-premises data store and a cloud data store) over a slow network connection**.</span></span> <span data-ttu-id="48eea-216">Performansı artırmak için bulut hazırlama veri deposunda veri taşımak için daha az zaman alır, verileri şirket içi sıkıştırabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-216">To improve performance, you can compress the data on-premises so that it takes less time to move data to the staging data store in the cloud.</span></span> <span data-ttu-id="48eea-217">Hedef veri deposuna yükleme önce hazırlama deposundaki verileri sıkıştırmasını.</span><span class="sxs-lookup"><span data-stu-id="48eea-217">Then you can decompress the data in the staging store before you load it into the destination data store.</span></span>
3. <span data-ttu-id="48eea-218">**Bağlantı noktası 80 dışındaki bağlantı noktaları açın ve kurumsal BT ilkeleri nedeniyle, Güvenlik Duvarı'nda 443 numaralı bağlantı istemediğiniz**.</span><span class="sxs-lookup"><span data-stu-id="48eea-218">**You don't want to open ports other than port 80 and port 443 in your firewall, because of corporate IT policies**.</span></span> <span data-ttu-id="48eea-219">Örneğin, bir Azure SQL veritabanı havuz veya bir Azure SQL Data Warehouse havuz için bir şirket içi veri deposundan veri kopyaladığınızda, hem Windows Güvenlik Duvarı hem de kurumsal güvenlik ağınızın 1433 numaralı bağlantı noktasında giden TCP iletişimi etkinleştirmeniz gerekir.</span><span class="sxs-lookup"><span data-stu-id="48eea-219">For example, when you copy data from an on-premises data store to an Azure SQL Database sink or an Azure SQL Data Warehouse sink, you need to activate outbound TCP communication on port 1433 for both the Windows firewall and your corporate firewall.</span></span> <span data-ttu-id="48eea-220">Bu senaryoda, ilk veri Kopyala ağ geçidine bir Blob Depolama hazırlama örneğine HTTP veya HTTPS üzerinden bağlantı noktası 443 üzerinde yararlanın.</span><span class="sxs-lookup"><span data-stu-id="48eea-220">In this scenario, take advantage of the gateway to first copy data to a Blob storage staging instance over HTTP or HTTPS on port 443.</span></span> <span data-ttu-id="48eea-221">Sonra verileri Blob Depolama hazırlamadan SQL Database veya SQL Data Warehouse yüklemek.</span><span class="sxs-lookup"><span data-stu-id="48eea-221">Then, load the data into SQL Database or SQL Data Warehouse from Blob storage staging.</span></span> <span data-ttu-id="48eea-222">Bu akışta 1433 numaralı bağlantı noktasını etkinleştirmek gerekmez.</span><span class="sxs-lookup"><span data-stu-id="48eea-222">In this flow, you don't need to enable port 1433.</span></span>

### <a name="how-staged-copy-works"></a><span data-ttu-id="48eea-223">Nasıl hazırlanmış kopyalama çalışır</span><span class="sxs-lookup"><span data-stu-id="48eea-223">How staged copy works</span></span>
<span data-ttu-id="48eea-224">Hazırlama özelliği etkinleştirdiğinizde, ilk veri kaynağı veri deposundan hazırlama veri deposuna kopyalanır (Getir kendi).</span><span class="sxs-lookup"><span data-stu-id="48eea-224">When you activate the staging feature, first the data is copied from the source data store to the staging data store (bring your own).</span></span> <span data-ttu-id="48eea-225">Ardından, verileri hazırlama veri deposundan havuz veri deposuna kopyalanır.</span><span class="sxs-lookup"><span data-stu-id="48eea-225">Next, the data is copied from the staging data store to the sink data store.</span></span> <span data-ttu-id="48eea-226">Veri Fabrikası iki aşamalı akış sizin için otomatik olarak yönetir.</span><span class="sxs-lookup"><span data-stu-id="48eea-226">Data Factory automatically manages the two-stage flow for you.</span></span> <span data-ttu-id="48eea-227">Veri taşıma işlemi tamamlandıktan sonra veri fabrikası aynı zamanda hazırlama depolama biriminden geçici verileri temizler.</span><span class="sxs-lookup"><span data-stu-id="48eea-227">Data Factory also cleans up temporary data from the staging storage after the data movement is complete.</span></span>

<span data-ttu-id="48eea-228">Bulut kopyalama senaryosunda (bulutta depoları olan kaynak ve havuz veri) ağ geçidi kullanılmaz.</span><span class="sxs-lookup"><span data-stu-id="48eea-228">In the cloud copy scenario (both source and sink data stores are in the cloud), gateway is not used.</span></span> <span data-ttu-id="48eea-229">Data Factory hizmetinin kopyalama işlemleri gerçekleştirir.</span><span class="sxs-lookup"><span data-stu-id="48eea-229">The Data Factory service performs the copy operations.</span></span>

![Kopya hazırlanan: Bulut senaryosu](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

<span data-ttu-id="48eea-231">Karma kopyalama senaryoda (şirket içi bir kaynaktır ve havuz olduğu bulutta), ağ geçidi veri kaynağına veri deposundan hazırlama bir veri deposuna taşır.</span><span class="sxs-lookup"><span data-stu-id="48eea-231">In the hybrid copy scenario (source is on-premises and sink is in the cloud), the gateway moves data from the source data store to a staging data store.</span></span> <span data-ttu-id="48eea-232">Data Factory Hizmeti'ne havuz veri deposuna hazırlama veri deposundan verileri taşır.</span><span class="sxs-lookup"><span data-stu-id="48eea-232">Data Factory service moves data from the staging data store to the sink data store.</span></span> <span data-ttu-id="48eea-233">Bir şirket içi veri depolama hazırlama yoluyla bir bulut veri deposundan veri kopyalama ile ters akışını de desteklenir.</span><span class="sxs-lookup"><span data-stu-id="48eea-233">Copying data from a cloud data store to an on-premises data store via staging also is supported with the reversed flow.</span></span>

![Kopya hazırlanan: karma senaryo](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

<span data-ttu-id="48eea-235">Hazırlama depolama kullanarak veri taşıma etkinleştirdiğinizde, verileri veri kaynağına veri deposundan bir geçiş veya hazırlama veri deposuna taşımadan önce sıkıştırılır ve bir geçiş verilerini taşıma veya veri deposu havuz veri deposuna hazırlama önce sıkıştırması açılmış isteyip istemediğinizi belirtebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-235">When you activate data movement by using a staging store, you can specify whether you want the data to be compressed before moving data from the source data store to an interim or staging data store, and then decompressed before moving data from an interim or staging data store to the sink data store.</span></span>

<span data-ttu-id="48eea-236">Şu anda, bir hazırlama deposu kullanarak iki şirket içi veri depoları arasında veri kopyalanamıyor.</span><span class="sxs-lookup"><span data-stu-id="48eea-236">Currently, you can't copy data between two on-premises data stores by using a staging store.</span></span> <span data-ttu-id="48eea-237">Hemen kullanılabilir olması için bu seçeneği bekliyoruz.</span><span class="sxs-lookup"><span data-stu-id="48eea-237">We expect this option to be available soon.</span></span>

### <a name="configuration"></a><span data-ttu-id="48eea-238">Yapılandırma</span><span class="sxs-lookup"><span data-stu-id="48eea-238">Configuration</span></span>
<span data-ttu-id="48eea-239">Yapılandırma **enableStaging** bir hedef veri deposuna yükleme önce Blob depolama alanına aşamalı için verileri isteyip istemediğinizi belirtmek için kopyalama etkinliği ayarlama.</span><span class="sxs-lookup"><span data-stu-id="48eea-239">Configure the **enableStaging** setting in Copy Activity to specify whether you want the data to be staged in Blob storage before you load it into a destination data store.</span></span> <span data-ttu-id="48eea-240">Ayarladığınızda **enableStaging** TRUE, sonraki tabloda listelenen ek özellikler belirtmek için.</span><span class="sxs-lookup"><span data-stu-id="48eea-240">When you set **enableStaging** to TRUE, specify the additional properties listed in the next table.</span></span> <span data-ttu-id="48eea-241">Yoksa, depolama paylaşılan erişim imzası bağlantılı hizmeti hazırlama için veya bir Azure Storage oluşturmak gerekir.</span><span class="sxs-lookup"><span data-stu-id="48eea-241">If you don’t have one, you also need to create an Azure Storage or Storage shared access signature-linked service for staging.</span></span>

| <span data-ttu-id="48eea-242">Özellik</span><span class="sxs-lookup"><span data-stu-id="48eea-242">Property</span></span> | <span data-ttu-id="48eea-243">Açıklama</span><span class="sxs-lookup"><span data-stu-id="48eea-243">Description</span></span> | <span data-ttu-id="48eea-244">Varsayılan değer</span><span class="sxs-lookup"><span data-stu-id="48eea-244">Default value</span></span> | <span data-ttu-id="48eea-245">Gerekli</span><span class="sxs-lookup"><span data-stu-id="48eea-245">Required</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="48eea-246">**enableStaging**</span><span class="sxs-lookup"><span data-stu-id="48eea-246">**enableStaging**</span></span> |<span data-ttu-id="48eea-247">Veri deposu hazırlama bir geçiş aracılığıyla kopyalamak isteyip istemediğinizi belirtin.</span><span class="sxs-lookup"><span data-stu-id="48eea-247">Specify whether you want to copy data via an interim staging store.</span></span> |<span data-ttu-id="48eea-248">False</span><span class="sxs-lookup"><span data-stu-id="48eea-248">False</span></span> |<span data-ttu-id="48eea-249">Hayır</span><span class="sxs-lookup"><span data-stu-id="48eea-249">No</span></span> |
| <span data-ttu-id="48eea-250">**linkedServiceName**</span><span class="sxs-lookup"><span data-stu-id="48eea-250">**linkedServiceName**</span></span> |<span data-ttu-id="48eea-251">Adını belirtin bir [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) veya [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) bağlı bir geçici hazırlama deposu olarak kullanmak depolama örneğinin başvurduğu hizmeti.</span><span class="sxs-lookup"><span data-stu-id="48eea-251">Specify the name of an [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) or [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) linked service, which refers to the instance of Storage that you use as an interim staging store.</span></span> <br/><br/> <span data-ttu-id="48eea-252">PolyBase aracılığıyla SQL veri ambarında verileri yüklemek için depolama ile paylaşılan erişim imzası kullanamazsınız.</span><span class="sxs-lookup"><span data-stu-id="48eea-252">You cannot use Storage with a shared access signature to load data into SQL Data Warehouse via PolyBase.</span></span> <span data-ttu-id="48eea-253">Diğer tüm senaryolarda kullanabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-253">You can use it in all other scenarios.</span></span> |<span data-ttu-id="48eea-254">Yok</span><span class="sxs-lookup"><span data-stu-id="48eea-254">N/A</span></span> |<span data-ttu-id="48eea-255">Evet, ne zaman **enableStaging** TRUE olarak ayarlayın</span><span class="sxs-lookup"><span data-stu-id="48eea-255">Yes, when **enableStaging** is set to TRUE</span></span> |
| <span data-ttu-id="48eea-256">**yol**</span><span class="sxs-lookup"><span data-stu-id="48eea-256">**path**</span></span> |<span data-ttu-id="48eea-257">Hazırlanmış verinin içermesini istediğiniz Blob Depolama yolunu belirtin.</span><span class="sxs-lookup"><span data-stu-id="48eea-257">Specify the Blob storage path that you want to contain the staged data.</span></span> <span data-ttu-id="48eea-258">Bir yol belirtmezseniz, hizmet geçici verileri depolamak için bir kapsayıcı oluşturur.</span><span class="sxs-lookup"><span data-stu-id="48eea-258">If you do not provide a path, the service creates a container to store temporary data.</span></span> <br/><br/> <span data-ttu-id="48eea-259">Yalnızca depolama ile paylaşılan erişim imzası kullanın veya geçici verilerin belirli bir konumda olmasını gerektiren bir yol belirtin.</span><span class="sxs-lookup"><span data-stu-id="48eea-259">Specify a path only if you use Storage with a shared access signature, or you require temporary data to be in a specific location.</span></span> |<span data-ttu-id="48eea-260">Yok</span><span class="sxs-lookup"><span data-stu-id="48eea-260">N/A</span></span> |<span data-ttu-id="48eea-261">Hayır</span><span class="sxs-lookup"><span data-stu-id="48eea-261">No</span></span> |
| <span data-ttu-id="48eea-262">**Aracılığıyla**</span><span class="sxs-lookup"><span data-stu-id="48eea-262">**enableCompression**</span></span> |<span data-ttu-id="48eea-263">Hedefe kopyalamadan önce verilerin sıkıştırılmasının gerekli olup olmadığını belirtir.</span><span class="sxs-lookup"><span data-stu-id="48eea-263">Specifies whether data should be compressed before it is copied to the destination.</span></span> <span data-ttu-id="48eea-264">Bu ayar aktarılan veri hacmini azaltır.</span><span class="sxs-lookup"><span data-stu-id="48eea-264">This setting reduces the volume of data being transferred.</span></span> |<span data-ttu-id="48eea-265">False</span><span class="sxs-lookup"><span data-stu-id="48eea-265">False</span></span> |<span data-ttu-id="48eea-266">Hayır</span><span class="sxs-lookup"><span data-stu-id="48eea-266">No</span></span> |

<span data-ttu-id="48eea-267">Kopyalama etkinliği yukarıdaki tabloda açıklanan özelliklere sahip bir örnek tanımı aşağıda verilmiştir:</span><span class="sxs-lookup"><span data-stu-id="48eea-267">Here's a sample definition of Copy Activity with the properties that are described in the preceding table:</span></span>

```json
"activities":[  
{
    "name": "Sample copy activity",
    "type": "Copy",
    "inputs": [{ "name": "OnpremisesSQLServerInput" }],
    "outputs": [{ "name": "AzureSQLDBOutput" }],
    "typeProperties": {
        "source": {
            "type": "SqlSource",
        },
        "sink": {
            "type": "SqlSink"
        },
        "enableStaging": true,
        "stagingSettings": {
            "linkedServiceName": "MyStagingBlob",
            "path": "stagingcontainer/path",
            "enableCompression": true
        }
    }
}
]
```

### <a name="billing-impact"></a><span data-ttu-id="48eea-268">Faturalama etkisi</span><span class="sxs-lookup"><span data-stu-id="48eea-268">Billing impact</span></span>
<span data-ttu-id="48eea-269">Temel alınarak iki adımı ücretlendirilen: süresi kopyalama ve kopyalama türü.</span><span class="sxs-lookup"><span data-stu-id="48eea-269">You are charged based on two steps: copy duration and copy type.</span></span>

* <span data-ttu-id="48eea-270">(Verileri bir bulut veri deposundan başka bir bulut veri deposuna kopyalama) bulut kopyalama sırasında Hazırlama [kopyalama sürenin toplamı adım 1 ve 2. adım] [bulut kopya Birim Fiyat] x kullandığınızda ücretlendirilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-270">When you use staging during a cloud copy (copying data from a cloud data store to another cloud data store), you are charged the [sum of copy duration for step 1 and step 2] x [cloud copy unit price].</span></span>
* <span data-ttu-id="48eea-271">Kullandığınızda (bir bulut veri deposuna bir şirket içi veri deposundan veri kopyalama) karma kopyalama sırasında hazırlama, [karma kopyalama süresince] ücretlendirilen x [karma kopya Birim Fiyat] + [bulut kopyalama süre] [bulut kopya Birim Fiyat] x.</span><span class="sxs-lookup"><span data-stu-id="48eea-271">When you use staging during a hybrid copy (copying data from an on-premises data store to a cloud data store), you are charged for [hybrid copy duration] x [hybrid copy unit price] + [cloud copy duration] x [cloud copy unit price].</span></span>

## <a name="performance-tuning-steps"></a><span data-ttu-id="48eea-272">Performans ayarlama adımları</span><span class="sxs-lookup"><span data-stu-id="48eea-272">Performance tuning steps</span></span>
<span data-ttu-id="48eea-273">Veri Fabrikası hizmetiniz kopyalama etkinliği ile performansı ayarlamak için şu adımları uygulamanız öneririz:</span><span class="sxs-lookup"><span data-stu-id="48eea-273">We suggest that you take these steps to tune the performance of your Data Factory service with Copy Activity:</span></span>

1. <span data-ttu-id="48eea-274">**Bir taban çizgisi oluşturma**.</span><span class="sxs-lookup"><span data-stu-id="48eea-274">**Establish a baseline**.</span></span> <span data-ttu-id="48eea-275">Geliştirme aşamasında, temsili veri örneği karşı kopyalama etkinliği kullanarak hattınızı sınayın.</span><span class="sxs-lookup"><span data-stu-id="48eea-275">During the development phase, test your pipeline by using Copy Activity against a representative data sample.</span></span> <span data-ttu-id="48eea-276">Veri Fabrikası kullanabilirsiniz [modeli dilimleme](data-factory-scheduling-and-execution.md) ile çalışırsınız veri miktarını sınırlamak için.</span><span class="sxs-lookup"><span data-stu-id="48eea-276">You can use the Data Factory [slicing model](data-factory-scheduling-and-execution.md) to limit the amount of data you work with.</span></span>

   <span data-ttu-id="48eea-277">Yürütme süresi ve performans özelliklerini kullanarak toplamak **izleme ve yönetim uygulaması**.</span><span class="sxs-lookup"><span data-stu-id="48eea-277">Collect execution time and performance characteristics by using the **Monitoring and Management App**.</span></span> <span data-ttu-id="48eea-278">Seçin **İzleyici & Yönet** Data Factory giriş sayfası.</span><span class="sxs-lookup"><span data-stu-id="48eea-278">Choose **Monitor & Manage** on your Data Factory home page.</span></span> <span data-ttu-id="48eea-279">Ağaç görünümünde seçin **çıkış dataset**.</span><span class="sxs-lookup"><span data-stu-id="48eea-279">In the tree view, choose the **output dataset**.</span></span> <span data-ttu-id="48eea-280">İçinde **etkinlik Windows** listesinde, çalıştırmak kopyalama etkinliği seçin.</span><span class="sxs-lookup"><span data-stu-id="48eea-280">In the **Activity Windows** list, choose the Copy Activity run.</span></span> <span data-ttu-id="48eea-281">**Etkinlik pencerelerine** kopyalama etkinlik süresi ve kopyalanan verilerin boyutuna göre listeler.</span><span class="sxs-lookup"><span data-stu-id="48eea-281">**Activity Windows** lists the Copy Activity duration and the size of the data that's copied.</span></span> <span data-ttu-id="48eea-282">Üretilen iş listelenen **etkinlik penceresini Explorer**.</span><span class="sxs-lookup"><span data-stu-id="48eea-282">The throughput is listed in **Activity Window Explorer**.</span></span> <span data-ttu-id="48eea-283">Uygulama hakkında daha fazla bilgi için bkz: [İzleyici ve Azure Data Factory işlem hatlarını izleme ve yönetim uygulaması kullanarak yönetme](data-factory-monitor-manage-app.md).</span><span class="sxs-lookup"><span data-stu-id="48eea-283">To learn more about the app, see [Monitor and manage Azure Data Factory pipelines by using the Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

   ![Etkinlik çalışma ayrıntıları](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

   <span data-ttu-id="48eea-285">Makalenin sonraki bölümlerinde, performans ve senaryonuz için kopyalama etkinliği'nin yapılandırılmasını karşılaştırabilirsiniz [Performans başvurusu](#performance-reference) bizim testlerden.</span><span class="sxs-lookup"><span data-stu-id="48eea-285">Later in the article, you can compare the performance and configuration of your scenario to Copy Activity’s [performance reference](#performance-reference) from our tests.</span></span>
2. <span data-ttu-id="48eea-286">**Tanılama ve performansı en iyi duruma**.</span><span class="sxs-lookup"><span data-stu-id="48eea-286">**Diagnose and optimize performance**.</span></span> <span data-ttu-id="48eea-287">Gözlemlemek performans beklentilerinizi karşılamıyorsa, performans sorunlarını tanımlamak gerekir.</span><span class="sxs-lookup"><span data-stu-id="48eea-287">If the performance you observe doesn't meet your expectations, you need to identify performance bottlenecks.</span></span> <span data-ttu-id="48eea-288">Ardından, kaldırmak veya performans etkisini azaltmak için performansı en iyi duruma.</span><span class="sxs-lookup"><span data-stu-id="48eea-288">Then, optimize performance to remove or reduce the effect of bottlenecks.</span></span> <span data-ttu-id="48eea-289">Performans Tanılama ilgili tam açıklama için bu makalenin kapsamı dışındadır olsa da, bazı ortak noktalar şunlardır:</span><span class="sxs-lookup"><span data-stu-id="48eea-289">A full description of performance diagnosis is beyond the scope of this article, but here are some common considerations:</span></span>

   * <span data-ttu-id="48eea-290">Performans özellikleri:</span><span class="sxs-lookup"><span data-stu-id="48eea-290">Performance features:</span></span>
     * [<span data-ttu-id="48eea-291">Paralel kopyalama</span><span class="sxs-lookup"><span data-stu-id="48eea-291">Parallel copy</span></span>](#parallel-copy)
     * [<span data-ttu-id="48eea-292">Bulut veri taşıma birimleri</span><span class="sxs-lookup"><span data-stu-id="48eea-292">Cloud data movement units</span></span>](#cloud-data-movement-units)
     * [<span data-ttu-id="48eea-293">Hazırlanan kopyalama</span><span class="sxs-lookup"><span data-stu-id="48eea-293">Staged copy</span></span>](#staged-copy)
     * [<span data-ttu-id="48eea-294">Veri Yönetimi ağ geçidi ölçeklenebilirlik</span><span class="sxs-lookup"><span data-stu-id="48eea-294">Data Management Gateway scalability</span></span>](data-factory-data-management-gateway-high-availability-scalability.md)
   * [<span data-ttu-id="48eea-295">Veri Yönetimi Ağ Geçidi</span><span class="sxs-lookup"><span data-stu-id="48eea-295">Data Management Gateway</span></span>](#considerations-for-data-management-gateway)
   * [<span data-ttu-id="48eea-296">Kaynak</span><span class="sxs-lookup"><span data-stu-id="48eea-296">Source</span></span>](#considerations-for-the-source)
   * [<span data-ttu-id="48eea-297">Havuz</span><span class="sxs-lookup"><span data-stu-id="48eea-297">Sink</span></span>](#considerations-for-the-sink)
   * [<span data-ttu-id="48eea-298">Seri hale getirme ve seri durumdan çıkarma</span><span class="sxs-lookup"><span data-stu-id="48eea-298">Serialization and deserialization</span></span>](#considerations-for-serialization-and-deserialization)
   * [<span data-ttu-id="48eea-299">Sıkıştırma</span><span class="sxs-lookup"><span data-stu-id="48eea-299">Compression</span></span>](#considerations-for-compression)
   * [<span data-ttu-id="48eea-300">Sütun eşlemesi</span><span class="sxs-lookup"><span data-stu-id="48eea-300">Column mapping</span></span>](#considerations-for-column-mapping)
   * [<span data-ttu-id="48eea-301">Diğer konular</span><span class="sxs-lookup"><span data-stu-id="48eea-301">Other considerations</span></span>](#other-considerations)
3. <span data-ttu-id="48eea-302">**Tüm Veri kümenizi Yapılandırması**.</span><span class="sxs-lookup"><span data-stu-id="48eea-302">**Expand the configuration to your entire data set**.</span></span> <span data-ttu-id="48eea-303">Yürütme sonuçları ve performans ile memnun kaldığınızda, tanım ve ardışık düzen etkin süresini, tüm veri kümelerinin kapsayacak şekilde genişletebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-303">When you're satisfied with the execution results and performance, you can expand the definition and pipeline active period to cover your entire data set.</span></span>

## <a name="considerations-for-data-management-gateway"></a><span data-ttu-id="48eea-304">Veri Yönetimi ağ geçidi için ilgili önemli noktalar</span><span class="sxs-lookup"><span data-stu-id="48eea-304">Considerations for Data Management Gateway</span></span>
<span data-ttu-id="48eea-305">**Ağ geçidi Kurulum**: ana bilgisayar veri yönetimi ağ geçidi için ayrılmış bir makine kullanmanızı öneririz.</span><span class="sxs-lookup"><span data-stu-id="48eea-305">**Gateway setup**: We recommend that you use a dedicated machine to host Data Management Gateway.</span></span> <span data-ttu-id="48eea-306">Bkz: [veri yönetimi ağ geçidi kullanarak dikkat edilmesi gereken noktalar](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span><span class="sxs-lookup"><span data-stu-id="48eea-306">See [Considerations for using Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span></span>  

<span data-ttu-id="48eea-307">**Ağ geçidi izleme ve yukarı/genişleme**: tek bir mantıksal ağ geçidi ile bir veya daha fazla ağ geçidi düğümleri aynı anda aynı anda birden çok kopya etkinliği çalıştırır hizmet verebilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-307">**Gateway monitoring and scale-up/out**: A single logical gateway with one or more gateway nodes can serve multiple Copy Activity runs at the same time concurrently.</span></span> <span data-ttu-id="48eea-308">Bir ağ geçidi makinesi sınırı Azure portalında karşı çalışan eşzamanlı iş sayısını görmek olarak iyi kaynak kullanımı (CPU, bellek, network(in/out), vb.) neredeyse gerçek zamanlı görüntüsünü görüntüleyebilirsiniz [İzleyici ağ geçidi portalında](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span><span class="sxs-lookup"><span data-stu-id="48eea-308">You can view near-real time snapshot of resource utilization (CPU, memory, network(in/out), etc.) on a gateway machine as well as the number of concurrent jobs running versus limit in the Azure portal, see [Monitor gateway in the portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span></span> <span data-ttu-id="48eea-309">İçin çok sayıda eş zamanlı kopyalama etkinliği çalışır veya büyük miktarda veri kopyalamak için karma veri taşıma üzerinde ağır gereksiniminiz varsa göz önünde bulundurun [ölçeği veya ağ geçidi ölçeklendirmek](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) kopyalama güçlendirmeniz daha fazla kaynak sağlamak için ya da daha iyi kaynağınız kullanmalarını amacıyla.</span><span class="sxs-lookup"><span data-stu-id="48eea-309">If you have heavy need on hybrid data movement either with large number of concurrent copy activity runs or with large volume of data to copy, consider to [scale up or scale out gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) so as to better utilize your resource or to provision more resource to empower copy.</span></span> 

## <a name="considerations-for-the-source"></a><span data-ttu-id="48eea-310">Kaynak için ilgili önemli noktalar</span><span class="sxs-lookup"><span data-stu-id="48eea-310">Considerations for the source</span></span>
### <a name="general"></a><span data-ttu-id="48eea-311">Genel</span><span class="sxs-lookup"><span data-stu-id="48eea-311">General</span></span>
<span data-ttu-id="48eea-312">Temel alınan veri deposu veya onu karşı çalışan diğer iş yükleri tarafından doludur değil olduğunu unutmayın.</span><span class="sxs-lookup"><span data-stu-id="48eea-312">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="48eea-313">Microsoft veri depoları için bkz: [izleme ve konuları ayarlama](#performance-reference) özgü veri depoları ve veri performans özellikleri depolamak, yanıt sürelerini en aza indirmek ve üretilen işi en üst düzeye anlamanıza yardım.</span><span class="sxs-lookup"><span data-stu-id="48eea-313">For Microsoft data stores, see [monitoring and tuning topics](#performance-reference) that are specific to data stores, and help you understand data store performance characteristics, minimize response times, and maximize throughput.</span></span>

<span data-ttu-id="48eea-314">SQL veri ambarı için Blob depolama alanından verileri kopyalarsanız, kullanmayı **PolyBase** performansını artırma.</span><span class="sxs-lookup"><span data-stu-id="48eea-314">If you copy data from Blob storage to SQL Data Warehouse, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="48eea-315">Bkz: [kullanım Azure SQL Data Warehouse'a veri yüklemek için PolyBase](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) Ayrıntılar için.</span><span class="sxs-lookup"><span data-stu-id="48eea-315">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="48eea-316">Kullanım örneği ile bir anlatım için bkz: [1 TB altında 15 dakika Azure Data Factory ile Azure SQL Data Warehouse'a veri yükleme](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="48eea-316">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="48eea-317">Dosya tabanlı veri depoları</span><span class="sxs-lookup"><span data-stu-id="48eea-317">File-based data stores</span></span>
<span data-ttu-id="48eea-318">*(Blob Depolama, Data Lake Store, Amazon S3, şirket içi dosya sistemleri ve şirket içi HDFS içerir)*</span><span class="sxs-lookup"><span data-stu-id="48eea-318">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="48eea-319">**Ortalama dosya boyutu ve dosya sayısı**: kopyalama etkinliği, aynı anda bir veri dosyası aktarır.</span><span class="sxs-lookup"><span data-stu-id="48eea-319">**Average file size and file count**: Copy Activity transfers data one file at a time.</span></span> <span data-ttu-id="48eea-320">İle aynı taşınacak veri miktarı, genel üretilen işi verileri her dosya için önyükleme aşaması nedeniyle birkaç büyük dosyalar yerine pek çok küçük dosya oluşuyorsa düşüktür.</span><span class="sxs-lookup"><span data-stu-id="48eea-320">With the same amount of data to be moved, the overall throughput is lower if the data consists of many small files rather than a few large files due to the bootstrap phase for each file.</span></span> <span data-ttu-id="48eea-321">Bu nedenle, mümkünse, küçük dosyalar daha yüksek verimlilik elde etmek için daha büyük dosyalar birleştirin.</span><span class="sxs-lookup"><span data-stu-id="48eea-321">Therefore, if possible, combine small files into larger files to gain higher throughput.</span></span>
* <span data-ttu-id="48eea-322">**Dosya biçimi ve sıkıştırma**: performansını artırmak diğer yolları için bkz: [seri hale getirme ve seri durumundan çıkarma için ilgili önemli noktalar](#considerations-for-serialization-and-deserialization) ve [sıkıştırma için ilgili önemli noktalar](#considerations-for-compression) bölümler.</span><span class="sxs-lookup"><span data-stu-id="48eea-322">**File format and compression**: For more ways to improve performance, see the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections.</span></span>
* <span data-ttu-id="48eea-323">İçin **şirket içi dosya sistemi** senaryosunda, hangi **veri yönetimi ağ geçidi** olan gerekli bkz [veri yönetimi ağ geçidi için ilgili önemli noktalar](#considerations-for-data-management-gateway) bölümü.</span><span class="sxs-lookup"><span data-stu-id="48eea-323">For the **on-premises file system** scenario, in which **Data Management Gateway** is required, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="48eea-324">İlişkisel veri depoları</span><span class="sxs-lookup"><span data-stu-id="48eea-324">Relational data stores</span></span>
<span data-ttu-id="48eea-325">*(SQL veritabanı içerir; SQL veri ambarı; Amazon Redshift; SQL Server veritabanları; ve Oracle, MySQL, DB2, Teradata, Sybase ve PostgreSQL veritabanları, vs.)*</span><span class="sxs-lookup"><span data-stu-id="48eea-325">*(Includes SQL Database; SQL Data Warehouse; Amazon Redshift; SQL Server databases; and Oracle, MySQL, DB2, Teradata, Sybase, and PostgreSQL databases, etc.)*</span></span>

* <span data-ttu-id="48eea-326">**Veri deseni**: Tablo şemanızı kopyalama verimlilik etkiler.</span><span class="sxs-lookup"><span data-stu-id="48eea-326">**Data pattern**: Your table schema affects copy throughput.</span></span> <span data-ttu-id="48eea-327">Büyük satır boyutu küçük satır boyutu, aynı miktarda veri kopyalamak için daha iyi performans sağlar.</span><span class="sxs-lookup"><span data-stu-id="48eea-327">A large row size gives you a better performance than small row size, to copy the same amount of data.</span></span> <span data-ttu-id="48eea-328">Veritabanında daha az sayıda satır içeren veri daha az toplu daha verimli bir şekilde alabilir nedenidir.</span><span class="sxs-lookup"><span data-stu-id="48eea-328">The reason is that the database can more efficiently retrieve fewer batches of data that contain fewer rows.</span></span>
* <span data-ttu-id="48eea-329">**Sorgu veya saklı yordam**: sorgu veya saklı yordam verileri daha verimli bir şekilde getirmek için kopyalama etkinliği kaynağında belirttiğiniz mantığını en iyi duruma getirme.</span><span class="sxs-lookup"><span data-stu-id="48eea-329">**Query or stored procedure**: Optimize the logic of the query or stored procedure you specify in the Copy Activity source to fetch data more efficiently.</span></span>
* <span data-ttu-id="48eea-330">İçin **içi ilişkisel veritabanları**, SQL Server ve kullanılmasını Oracle gibi **veri yönetimi ağ geçidi**, bkz: [veri yönetimi ağ geçidi için ilgili önemli noktalar](#considerations-on-data-management-gateway) bölümü.</span><span class="sxs-lookup"><span data-stu-id="48eea-330">For **on-premises relational databases**, such as SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-on-data-management-gateway) section.</span></span>

## <a name="considerations-for-the-sink"></a><span data-ttu-id="48eea-331">Havuz için ilgili önemli noktalar</span><span class="sxs-lookup"><span data-stu-id="48eea-331">Considerations for the sink</span></span>
### <a name="general"></a><span data-ttu-id="48eea-332">Genel</span><span class="sxs-lookup"><span data-stu-id="48eea-332">General</span></span>
<span data-ttu-id="48eea-333">Temel alınan veri deposu veya onu karşı çalışan diğer iş yükleri tarafından doludur değil olduğunu unutmayın.</span><span class="sxs-lookup"><span data-stu-id="48eea-333">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="48eea-334">Microsoft veri depoları için başvurmak [izleme ve konuları ayarlama](#performance-reference) özgü verileri depolar.</span><span class="sxs-lookup"><span data-stu-id="48eea-334">For Microsoft data stores, refer to [monitoring and tuning topics](#performance-reference) that are specific to data stores.</span></span> <span data-ttu-id="48eea-335">Bu konularda veri deposu performans özellikleri ve yanıt sürelerini en aza indirmek ve üretilen işi en üst düzeye çıkarmak nasıl anlamanıza yardımcı olabilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-335">These topics can help you understand data store performance characteristics and how to minimize response times and maximize throughput.</span></span>

<span data-ttu-id="48eea-336">Verileri kopyalıyorsanız **Blob storage** için **SQL veri ambarı**, kullanmayı **PolyBase** performansını artırma.</span><span class="sxs-lookup"><span data-stu-id="48eea-336">If you are copying data from **Blob storage** to **SQL Data Warehouse**, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="48eea-337">Bkz: [kullanım Azure SQL Data Warehouse'a veri yüklemek için PolyBase](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) Ayrıntılar için.</span><span class="sxs-lookup"><span data-stu-id="48eea-337">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="48eea-338">Kullanım örneği ile bir anlatım için bkz: [1 TB altında 15 dakika Azure Data Factory ile Azure SQL Data Warehouse'a veri yükleme](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="48eea-338">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="48eea-339">Dosya tabanlı veri depoları</span><span class="sxs-lookup"><span data-stu-id="48eea-339">File-based data stores</span></span>
<span data-ttu-id="48eea-340">*(Blob Depolama, Data Lake Store, Amazon S3, şirket içi dosya sistemleri ve şirket içi HDFS içerir)*</span><span class="sxs-lookup"><span data-stu-id="48eea-340">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="48eea-341">**Kopyalama davranışı**: farklı dosya tabanlı veri deposundan verileri kopyalarsanız, kopyalama etkinliği ile üç seçenek vardır **copyBehavior** özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-341">**Copy behavior**: If you copy data from a different file-based data store, Copy Activity has three options via the **copyBehavior** property.</span></span> <span data-ttu-id="48eea-342">Hiyerarşi korur, hiyerarşi düzleştirir veya dosyaları birleştirir.</span><span class="sxs-lookup"><span data-stu-id="48eea-342">It preserves hierarchy, flattens hierarchy, or merges files.</span></span> <span data-ttu-id="48eea-343">Koruma veya hiyerarşi düzleştirme çok az kayıpla veya hiç performans yüküne sahiptir, ancak dosyaları birleştirme artırmak performansa neden olur.</span><span class="sxs-lookup"><span data-stu-id="48eea-343">Either preserving or flattening hierarchy has little or no performance overhead, but merging files causes performance overhead to increase.</span></span>
* <span data-ttu-id="48eea-344">**Dosya biçimi ve sıkıştırma**: bkz [seri hale getirme ve seri durumundan çıkarma için ilgili önemli noktalar](#considerations-for-serialization-and-deserialization) ve [sıkıştırma için ilgili önemli noktalar](#considerations-for-compression) performansını artırmak diğer yolları için bölümler.</span><span class="sxs-lookup"><span data-stu-id="48eea-344">**File format and compression**: See the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections for more ways to improve performance.</span></span>
* <span data-ttu-id="48eea-345">**BLOB Depolama**: şu anda, Blob Depolama destekler yalnızca en iyi duruma getirilmiş veri aktarımı ve verimlilik için blok.</span><span class="sxs-lookup"><span data-stu-id="48eea-345">**Blob storage**: Currently, Blob storage supports only block blobs for optimized data transfer and throughput.</span></span>
* <span data-ttu-id="48eea-346">İçin **şirket içi dosya sistemleri** kullanımını gerektiren senaryolar **veri yönetimi ağ geçidi**, bkz: [veri yönetimi ağ geçidi için ilgili önemli noktalar](#considerations-for-data-management-gateway) bölümü.</span><span class="sxs-lookup"><span data-stu-id="48eea-346">For **on-premises file systems** scenarios that require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="48eea-347">İlişkisel veri depoları</span><span class="sxs-lookup"><span data-stu-id="48eea-347">Relational data stores</span></span>
<span data-ttu-id="48eea-348">*(SQL veritabanı, SQL Data Warehouse, SQL Server veritabanları ve Oracle veritabanları içerir)*</span><span class="sxs-lookup"><span data-stu-id="48eea-348">*(Includes SQL Database, SQL Data Warehouse, SQL Server databases, and Oracle databases)*</span></span>

* <span data-ttu-id="48eea-349">**Davranış kopyalama**: özellikleri için ayarlanmış bağlı olarak **sqlSink**, kopyalama etkinliği farklı şekillerde hedef veritabanına veri yazar.</span><span class="sxs-lookup"><span data-stu-id="48eea-349">**Copy behavior**: Depending on the properties you've set for **sqlSink**, Copy Activity writes data to the destination database in different ways.</span></span>
  * <span data-ttu-id="48eea-350">Varsayılan olarak, veri taşıma hizmeti kullanan veri eklemek için toplu kopyalama API en iyi performans sağlayan moda ekleyin.</span><span class="sxs-lookup"><span data-stu-id="48eea-350">By default, the data movement service uses the Bulk Copy API to insert data in append mode, which provides the best performance.</span></span>
  * <span data-ttu-id="48eea-351">Saklı yordam havuzunda yapılandırırsanız, veritabanı veri bir satır yerine bir anda bir toplu yükleme olarak uygulanır.</span><span class="sxs-lookup"><span data-stu-id="48eea-351">If you configure a stored procedure in the sink, the database applies the data one row at a time instead of as a bulk load.</span></span> <span data-ttu-id="48eea-352">Performansı önemli ölçüde bırakır.</span><span class="sxs-lookup"><span data-stu-id="48eea-352">Performance drops significantly.</span></span> <span data-ttu-id="48eea-353">Veri kümenizi uygulanabilir olduğunda büyükse, kullanmaya geçmeniz önerilir **sqlWriterCleanupScript** özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-353">If your data set is large, when applicable, consider switching to using the **sqlWriterCleanupScript** property.</span></span>
  * <span data-ttu-id="48eea-354">Yapılandırırsanız, **sqlWriterCleanupScript** özelliği her kopyalama etkinliği için çalıştırabilir, hizmet betik tetikler ve sonra toplu kopyalama API veri eklemek için kullanın.</span><span class="sxs-lookup"><span data-stu-id="48eea-354">If you configure the **sqlWriterCleanupScript** property for each Copy Activity run, the service triggers the script, and then you use the Bulk Copy API to insert the data.</span></span> <span data-ttu-id="48eea-355">Örneğin, tüm tablo en son verilerle üzerine yazmak için ilk önce toplu yeni veri kaynağından yükleme önce tüm kayıtları silmek için bir betik belirtebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-355">For example, to overwrite the entire table with the latest data, you can specify a script to first delete all records before bulk-loading the new data from the source.</span></span>
* <span data-ttu-id="48eea-356">**Veri düzeni ve toplu işlem boyutu**:</span><span class="sxs-lookup"><span data-stu-id="48eea-356">**Data pattern and batch size**:</span></span>
  * <span data-ttu-id="48eea-357">Tablo şemasını kopyalama verimlilik etkiler.</span><span class="sxs-lookup"><span data-stu-id="48eea-357">Your table schema affects copy throughput.</span></span> <span data-ttu-id="48eea-358">Veritabanı daha verimli bir şekilde daha az veri toplu yürütme çünkü aynı miktarda veri kopyalayın, bir büyük satır boyutu, küçük satır boyutu daha iyi performans sağlar.</span><span class="sxs-lookup"><span data-stu-id="48eea-358">To copy the same amount of data, a large row size gives you better performance than a small row size because the database can more efficiently commit fewer batches of data.</span></span>
  * <span data-ttu-id="48eea-359">Kopyalama etkinliği, toplu bir dizi veri ekler.</span><span class="sxs-lookup"><span data-stu-id="48eea-359">Copy Activity inserts data in a series of batches.</span></span> <span data-ttu-id="48eea-360">Kullanarak bir toplu işlemde satır sayısını ayarlayabilirsiniz **writeBatchSize** özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-360">You can set the number of rows in a batch by using the **writeBatchSize** property.</span></span> <span data-ttu-id="48eea-361">Verilerinizi küçük satırları varsa, ayarlayabileceğiniz **writeBatchSize** daha az toplu iş yükü ve daha yüksek verimlilik yararlanmak için daha yüksek bir değere sahip özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-361">If your data has small rows, you can set the **writeBatchSize** property with a higher value to benefit from lower batch overhead and higher throughput.</span></span> <span data-ttu-id="48eea-362">Verilerinizin satır boyutu büyükse, artırmanız dikkatli olun **writeBatchSize**.</span><span class="sxs-lookup"><span data-stu-id="48eea-362">If the row size of your data is large, be careful when you increase **writeBatchSize**.</span></span> <span data-ttu-id="48eea-363">Yüksek bir değer veritabanı aşırı yüklemesi nedeniyle bir kopyalama hatası neden.</span><span class="sxs-lookup"><span data-stu-id="48eea-363">A high value might lead to a copy failure caused by overloading the database.</span></span>
* <span data-ttu-id="48eea-364">İçin **içi ilişkisel veritabanları** SQL Server ve kullanılmasını Oracle gibi **veri yönetimi ağ geçidi**, bkz: [veri yönetimi ağ geçidi için ilgili önemli noktalar](#considerations-for-data-management-gateway) bölümü.</span><span class="sxs-lookup"><span data-stu-id="48eea-364">For **on-premises relational databases** like SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="nosql-stores"></a><span data-ttu-id="48eea-365">NoSQL depoları</span><span class="sxs-lookup"><span data-stu-id="48eea-365">NoSQL stores</span></span>
<span data-ttu-id="48eea-366">*(Tablo depolama ve Azure Cosmos DB içerir)*</span><span class="sxs-lookup"><span data-stu-id="48eea-366">*(Includes Table storage and Azure Cosmos DB )*</span></span>

* <span data-ttu-id="48eea-367">İçin **tablo depolama**:</span><span class="sxs-lookup"><span data-stu-id="48eea-367">For **Table storage**:</span></span>
  * <span data-ttu-id="48eea-368">**Bölüm**: veri araya eklemeli bölümlere önemli ölçüde yazma performansı düşürür.</span><span class="sxs-lookup"><span data-stu-id="48eea-368">**Partition**: Writing data to interleaved partitions dramatically degrades performance.</span></span> <span data-ttu-id="48eea-369">Veri kaynağınızı bölüm anahtarı tarafından Sırala veriler verimli bir şekilde bir bölüme sonra başka bir eklenir veya tek bir bölüm için veri yazmak için mantığı ayarlayın.</span><span class="sxs-lookup"><span data-stu-id="48eea-369">Sort your source data by partition key so that the data is inserted efficiently into one partition after another, or adjust the logic to write the data to a single partition.</span></span>
* <span data-ttu-id="48eea-370">İçin **Azure Cosmos DB**:</span><span class="sxs-lookup"><span data-stu-id="48eea-370">For **Azure Cosmos DB**:</span></span>
  * <span data-ttu-id="48eea-371">**Yığın boyutu**: **writeBatchSize** özelliği belgeleri oluşturmak için Azure Cosmos DB hizmetine paralel istek sayısını ayarlar.</span><span class="sxs-lookup"><span data-stu-id="48eea-371">**Batch size**: The **writeBatchSize** property sets the number of parallel requests to the Azure Cosmos DB service to create documents.</span></span> <span data-ttu-id="48eea-372">Artırdığınızda, daha iyi performans düşüklüğü görebilir **writeBatchSize** çünkü daha fazla paralel istekler için Azure Cosmos DB gönderilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-372">You can expect better performance when you increase **writeBatchSize** because more parallel requests are sent to Azure Cosmos DB.</span></span> <span data-ttu-id="48eea-373">Ancak, Azure Cosmos (hata iletisi "istek hızı büyük" olur) DB yazdığınızda azaltma izleyin.</span><span class="sxs-lookup"><span data-stu-id="48eea-373">However, watch for throttling when you write to Azure Cosmos DB (the error message is "Request rate is large").</span></span> <span data-ttu-id="48eea-374">Azaltma, belge boyutu dahil olmak üzere belgeler ve dizin oluşturma ilkesini hedef koleksiyonun terimleri sayısı çeşitli etkenler neden olabilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-374">Various factors can cause throttling, including document size, the number of terms in the documents, and the target collection's indexing policy.</span></span> <span data-ttu-id="48eea-375">Daha yüksek kopyalama verimlilik elde etmek için daha iyi bir koleksiyon, örneğin, S3 kullanmayı düşünün.</span><span class="sxs-lookup"><span data-stu-id="48eea-375">To achieve higher copy throughput, consider using a better collection, for example, S3.</span></span>

## <a name="considerations-for-serialization-and-deserialization"></a><span data-ttu-id="48eea-376">Serileştirme ve seri durumundan çıkarma için ilgili önemli noktalar</span><span class="sxs-lookup"><span data-stu-id="48eea-376">Considerations for serialization and deserialization</span></span>
<span data-ttu-id="48eea-377">Giriş veri kümesini veya çıkış veri kümesi bir dosyadır seri hale getirme ve seri durumdan çıkarma ortaya çıkabilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-377">Serialization and deserialization can occur when your input data set or output data set is a file.</span></span> <span data-ttu-id="48eea-378">Bkz: [desteklenen dosya ve sıkıştırma biçimleri](data-factory-supported-file-and-compression-formats.md) kopyalama etkinliği tarafından desteklenen dosya biçimleri hakkında ayrıntılarla.</span><span class="sxs-lookup"><span data-stu-id="48eea-378">See [Supported file and compression formats](data-factory-supported-file-and-compression-formats.md) with details on supported file formats by Copy Activity.</span></span>

<span data-ttu-id="48eea-379">**Davranış kopyalama**:</span><span class="sxs-lookup"><span data-stu-id="48eea-379">**Copy behavior**:</span></span>

* <span data-ttu-id="48eea-380">Dosya tabanlı veri depoları arasında dosyaları kopyalanıyor:</span><span class="sxs-lookup"><span data-stu-id="48eea-380">Copying files between file-based data stores:</span></span>
  * <span data-ttu-id="48eea-381">Aynı veya hiçbir dosya biçimi ayarları, veri taşıma Hizmeti'nde girdi ve çıktı veri kümeleri hem olduğunda ikili kopyasını herhangi bir seri hale getirme veya seri durumdan çıkarma olmadan yürütür.</span><span class="sxs-lookup"><span data-stu-id="48eea-381">When input and output data sets both have the same or no file format settings, the data movement service executes a binary copy without any serialization or deserialization.</span></span> <span data-ttu-id="48eea-382">Kaynak ve havuz dosya biçimi ayarları birbirinden farklı senaryo ile karşılaştırıldığında daha yüksek verimlilik bakın.</span><span class="sxs-lookup"><span data-stu-id="48eea-382">You see a higher throughput compared to the scenario, in which the source and sink file format settings are different from each other.</span></span>
  * <span data-ttu-id="48eea-383">Ne zaman giriş ve çıkış veri kümeleri hem metin biçimi ve yalnızca kodlama olan türü farklı olan, veri taşıma hizmeti yalnızca kodlama dönüştürme yapar.</span><span class="sxs-lookup"><span data-stu-id="48eea-383">When input and output data sets both are in text format and only the encoding type is different, the data movement service only does encoding conversion.</span></span> <span data-ttu-id="48eea-384">Tüm serileştirme yapmaz ve seri durumdan yükü ikili kopyasını karşılaştırıldığında bazı performans neden olur.</span><span class="sxs-lookup"><span data-stu-id="48eea-384">It doesn't do any serialization and deserialization, which causes some performance overhead compared to a binary copy.</span></span>
  * <span data-ttu-id="48eea-385">Farklı dosya biçimleri veya sınırlayıcıları gibi farklı yapılandırmaları, veri taşıma Hizmeti'nde girdi ve çıktı veri kümeleri hem olduğunda akış, dönüştürme ve belirttiğiniz çıkış biçimine serileştirmek için kaynak verileri seri durumdan çıkarır.</span><span class="sxs-lookup"><span data-stu-id="48eea-385">When input and output data sets both have different file formats or different configurations, like delimiters, the data movement service deserializes source data to stream, transform, and then serialize it into the output format you indicated.</span></span> <span data-ttu-id="48eea-386">Bu işlem yükü diğer senaryolar için kıyasla daha önemli bir performans sonuçlanır.</span><span class="sxs-lookup"><span data-stu-id="48eea-386">This operation results in a much more significant performance overhead compared to other scenarios.</span></span>
* <span data-ttu-id="48eea-387">Dosyaları (örneğin, bir dosya tabanlı depolama alanından bir ilişkisel deposuna) dosya tabanlı olmayan bir veri deposu/gruptan kopyaladığınızda, seri hale getirme veya seri durumdan çıkarma adım gereklidir.</span><span class="sxs-lookup"><span data-stu-id="48eea-387">When you copy files to/from a data store that is not file-based (for example, from a file-based store to a relational store), the serialization or deserialization step is required.</span></span> <span data-ttu-id="48eea-388">Bu adım, önemli performans ek yükü sonuçlanır.</span><span class="sxs-lookup"><span data-stu-id="48eea-388">This step results in significant performance overhead.</span></span>

<span data-ttu-id="48eea-389">**Dosya biçimi**: seçtiğiniz dosya biçimi kopyalama performansını etkileyebilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-389">**File format**: The file format you choose might affect copy performance.</span></span> <span data-ttu-id="48eea-390">Örneğin, Avro meta verilerle depolar sıkıştırılmış bir ikili biçimi ' dir.</span><span class="sxs-lookup"><span data-stu-id="48eea-390">For example, Avro is a compact binary format that stores metadata with data.</span></span> <span data-ttu-id="48eea-391">İşleme ve sorgulama için Hadoop ekosistemindeki geniş bir desteğe sahiptir.</span><span class="sxs-lookup"><span data-stu-id="48eea-391">It has broad support in the Hadoop ecosystem for processing and querying.</span></span> <span data-ttu-id="48eea-392">Ancak, Avro seri hale getirme ve metin biçimine kıyasla daha düşük kopyalama üretilen iş sonuçları seri durumdan için daha pahalı olması.</span><span class="sxs-lookup"><span data-stu-id="48eea-392">However, Avro is more expensive for serialization and deserialization, which results in lower copy throughput compared to text format.</span></span> <span data-ttu-id="48eea-393">Seçtiğiniz dosya biçimi işleme akışı boyunca bütünsel olun.</span><span class="sxs-lookup"><span data-stu-id="48eea-393">Make your choice of file format throughout the processing flow holistically.</span></span> <span data-ttu-id="48eea-394">Hangi veri form ile başlangıç, kaynak veri depolarını veya dış sistemlerden ayıklanacak depolanır; Depolama, analitik işleme ve sorgulama için en iyi biçimi; ve hangi biçiminde raporlama ve görselleştirme araçları için data Mart içinde veri verilmesi.</span><span class="sxs-lookup"><span data-stu-id="48eea-394">Start with what form the data is stored in, source data stores or to be extracted from external systems; the best format for storage, analytical processing, and querying; and in what format the data should be exported into data marts for reporting and visualization tools.</span></span> <span data-ttu-id="48eea-395">Bazen için uygun olmayan bir dosya biçimi okuma ve yazma performansı genel analitik işlemi göz önüne aldığınızda iyi bir seçimdir olabilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-395">Sometimes a file format that is suboptimal for read and write performance might be a good choice when you consider the overall analytical process.</span></span>

## <a name="considerations-for-compression"></a><span data-ttu-id="48eea-396">Sıkıştırma için ilgili önemli noktalar</span><span class="sxs-lookup"><span data-stu-id="48eea-396">Considerations for compression</span></span>
<span data-ttu-id="48eea-397">Giriş veya çıkış Veri kümenizi bir dosyası olduğunda, hedef veri yazar gibi sıkıştırma veya açma işlemi gerçekleştirmek için kopyalama etkinliği ayarlayabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-397">When your input or output data set is a file, you can set Copy Activity to perform compression or decompression as it writes data to the destination.</span></span> <span data-ttu-id="48eea-398">Sıkıştırma seçtiğinizde, giriş/çıkış (g/ç) arasında bir kolaylığını yapmak ve CPU.</span><span class="sxs-lookup"><span data-stu-id="48eea-398">When you choose compression, you make a tradeoff between input/output (I/O) and CPU.</span></span> <span data-ttu-id="48eea-399">İşlem kaynakları ek veri maliyetleri sıkıştırma.</span><span class="sxs-lookup"><span data-stu-id="48eea-399">Compressing the data costs extra in compute resources.</span></span> <span data-ttu-id="48eea-400">Ancak buna karşılık, ağ g/ç ve depolama azaltır.</span><span class="sxs-lookup"><span data-stu-id="48eea-400">But in return, it reduces network I/O and storage.</span></span> <span data-ttu-id="48eea-401">Verilerinizi bağlı olarak artırma genel kopyalama üretilen işi de görebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-401">Depending on your data, you may see a boost in overall copy throughput.</span></span>

<span data-ttu-id="48eea-402">**Codec**: GZIP, bzıp2 ve Deflate sıkıştırma türleri kopyalama etkinliği destekler.</span><span class="sxs-lookup"><span data-stu-id="48eea-402">**Codec**: Copy Activity supports gzip, bzip2, and Deflate compression types.</span></span> <span data-ttu-id="48eea-403">Azure Hdınsight, tüm üç tür işleme için kullanabilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-403">Azure HDInsight can consume all three types for processing.</span></span> <span data-ttu-id="48eea-404">Her bir sıkıştırma codec avantajları vardır.</span><span class="sxs-lookup"><span data-stu-id="48eea-404">Each compression codec has advantages.</span></span> <span data-ttu-id="48eea-405">Örneğin, bzıp2 düşük kopyalama üretilen işi olan, ancak işleme için bölmek için bzıp2 ile en iyi Hive sorgu performansı alırsınız.</span><span class="sxs-lookup"><span data-stu-id="48eea-405">For example, bzip2 has the lowest copy throughput, but you get the best Hive query performance with bzip2 because you can split it for processing.</span></span> <span data-ttu-id="48eea-406">Gzip en dengeli bir seçenektir ve en sık kullanılır.</span><span class="sxs-lookup"><span data-stu-id="48eea-406">Gzip is the most balanced option, and it is used the most often.</span></span> <span data-ttu-id="48eea-407">Uçtan uca senaryonuza uygun codec seçin.</span><span class="sxs-lookup"><span data-stu-id="48eea-407">Choose the codec that best suits your end-to-end scenario.</span></span>

<span data-ttu-id="48eea-408">**Düzey**: her bir sıkıştırma codec için iki seçenek arasından seçim yapabilirsiniz: hızlı sıkıştırılmış ve verimli sıkıştırılmış.</span><span class="sxs-lookup"><span data-stu-id="48eea-408">**Level**: You can choose from two options for each compression codec: fastest compressed and optimally compressed.</span></span> <span data-ttu-id="48eea-409">Sonuç dosyası en iyi şekilde sıkıştırılmaz olsa bile Hızlı sıkıştırılmış seçeneği veri mümkün olan en kısa sürede sıkıştırır.</span><span class="sxs-lookup"><span data-stu-id="48eea-409">The fastest compressed option compresses the data as quickly as possible, even if the resulting file is not optimally compressed.</span></span> <span data-ttu-id="48eea-410">En iyi şekilde sıkıştırılmış seçenek sıkıştırmayı daha fazla zaman harcayan ve en az miktarda veri ortaya çıkarır.</span><span class="sxs-lookup"><span data-stu-id="48eea-410">The optimally compressed option spends more time on compression and yields a minimal amount of data.</span></span> <span data-ttu-id="48eea-411">Çalışmanızın daha iyi genel performans sağlayan görmek için her iki seçenek test edebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-411">You can test both options to see which provides better overall performance in your case.</span></span>

<span data-ttu-id="48eea-412">**Önemli bir unsur**: büyük miktarda bir şirket içi depolama ve bulut arasında veri kopyalamak için geçici blob depolama sıkıştırması ile kullanmayı düşünün.</span><span class="sxs-lookup"><span data-stu-id="48eea-412">**A consideration**: To copy a large amount of data between an on-premises store and the cloud, consider using interim blob storage with compression.</span></span> <span data-ttu-id="48eea-413">Geçici depolama kullanarak şirket ağınıza ve Azure hizmetlerinizi bant genişliği sınırlayıcı faktördür ve girdi veri kümesi hem de çıkış veri kümesi sıkıştırılmamış formunda olacak şekilde istediğinizde yararlıdır.</span><span class="sxs-lookup"><span data-stu-id="48eea-413">Using interim storage is helpful when the bandwidth of your corporate network and your Azure services is the limiting factor, and you want the input data set and output data set both to be in uncompressed form.</span></span> <span data-ttu-id="48eea-414">Daha açık belirtmek gerekirse, iki kopyalama etkinliklerine tek kopyalama etkinliği bozulabilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-414">More specifically, you can break a single copy activity into two copy activities.</span></span> <span data-ttu-id="48eea-415">İlk kopyalama etkinliği bir geçiş veya hazırlama blob sıkıştırılmış biçimde kaynaktan kopyalar.</span><span class="sxs-lookup"><span data-stu-id="48eea-415">The first copy activity copies from the source to an interim or staging blob in compressed form.</span></span> <span data-ttu-id="48eea-416">İkinci kopyalama etkinliği hazırlamadan sıkıştırılmış verileri kopyalar ve havuz için yazarken sonra açar.</span><span class="sxs-lookup"><span data-stu-id="48eea-416">The second copy activity copies the compressed data from staging, and then decompresses while it writes to the sink.</span></span>

## <a name="considerations-for-column-mapping"></a><span data-ttu-id="48eea-417">Sütun eşlemesi için ilgili önemli noktalar</span><span class="sxs-lookup"><span data-stu-id="48eea-417">Considerations for column mapping</span></span>
<span data-ttu-id="48eea-418">Ayarlayabileceğiniz **columnMappings** tüm harita veya çıktı sütunları için bir giriş sütun alt kümesini kopyalama etkinliğinde özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-418">You can set the **columnMappings** property in Copy Activity to map all or a subset of the input columns to the output columns.</span></span> <span data-ttu-id="48eea-419">Veri Taşıma hizmeti veri kaynağından okuduktan sonra havuz için verileri yazar önce sütun eşlemesi verileri gerçekleştirmek gerekir.</span><span class="sxs-lookup"><span data-stu-id="48eea-419">After the data movement service reads the data from the source, it needs to perform column mapping on the data before it writes the data to the sink.</span></span> <span data-ttu-id="48eea-420">Bu ek işleme kopyalama performansını düşürür.</span><span class="sxs-lookup"><span data-stu-id="48eea-420">This extra processing reduces copy throughput.</span></span>

<span data-ttu-id="48eea-421">Kaynak veri deposu sorgulanabilir ise, örneğin, SQL Database veya SQL Server gibi ilişkisel bir mağaza ise ya da bir NoSQL deposu Table storage veya Azure Cosmos DB gibi ise sütun filtreleme dağıtmaya ve mantığı yeniden sıralama göz önünde bulundurun **sorgu** sütun eşlemesi kullanmak yerine özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-421">If your source data store is queryable, for example, if it's a relational store like SQL Database or SQL Server, or if it's a NoSQL store like Table storage or Azure Cosmos DB, consider pushing the column filtering and reordering logic to the **query** property instead of using column mapping.</span></span> <span data-ttu-id="48eea-422">Veri Taşıma hizmeti çok daha verimli olduğu kaynak veri deposundan verileri okurken bu şekilde, projeksiyon oluşur.</span><span class="sxs-lookup"><span data-stu-id="48eea-422">This way, the projection occurs while the data movement service reads data from the source data store, where it is much more efficient.</span></span>

## <a name="other-considerations"></a><span data-ttu-id="48eea-423">Diğer konular</span><span class="sxs-lookup"><span data-stu-id="48eea-423">Other considerations</span></span>
<span data-ttu-id="48eea-424">Kopyalamak istediğiniz verilerin boyutu büyükse, veri fabrikasında dilimleme mekanizmasını kullanarak verileri iş mantığınızı başka bölüme göre ayarlayabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-424">If the size of data you want to copy is large, you can adjust your business logic to further partition the data using the slicing mechanism in Data Factory.</span></span> <span data-ttu-id="48eea-425">Daha sonra her kopya etkinliği çalıştırmak için verilerin boyutunu küçültmek için daha sık çalıştırmak için kopyalama etkinliği zamanlayın.</span><span class="sxs-lookup"><span data-stu-id="48eea-425">Then, schedule Copy Activity to run more frequently to reduce the data size for each Copy Activity run.</span></span>

<span data-ttu-id="48eea-426">Veri kümeleri ve aynı anda aynı veri deposu bağlayıcıya veri fabrikası gerektiren kopyalama etkinliklerin sayısını dikkatli olun.</span><span class="sxs-lookup"><span data-stu-id="48eea-426">Be cautious about the number of data sets and copy activities requiring Data Factory to connector to the same data store at the same time.</span></span> <span data-ttu-id="48eea-427">Çok sayıda eş zamanlı kopyalama iş bir veri deposu kısıtlama ve performans, kopyalama işi iç yeniden denemeleri ve bazı durumlarda, yürütme hataları neden olabilir.</span><span class="sxs-lookup"><span data-stu-id="48eea-427">Many concurrent copy jobs might throttle a data store and lead to degraded performance, copy job internal retries, and in some cases, execution failures.</span></span>

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a><span data-ttu-id="48eea-428">Örnek senaryo: bir şirket içi SQL Server bir kopyasından Blob Depolama</span><span class="sxs-lookup"><span data-stu-id="48eea-428">Sample scenario: Copy from an on-premises SQL Server to Blob storage</span></span>
<span data-ttu-id="48eea-429">**Senaryo**: Blob Depolama birimine CSV biçiminde bir şirket içi SQL Server'dan veri kopyalamak için bir işlem hattı oluşturulmuştur.</span><span class="sxs-lookup"><span data-stu-id="48eea-429">**Scenario**: A pipeline is built to copy data from an on-premises SQL Server to Blob storage in CSV format.</span></span> <span data-ttu-id="48eea-430">Kopyalama işini hızlandırmak için CSV dosyaları bzıp2 biçime sıkıştırılmış.</span><span class="sxs-lookup"><span data-stu-id="48eea-430">To make the copy job faster, the CSV files should be compressed into bzip2 format.</span></span>

<span data-ttu-id="48eea-431">**Test ve analiz**: performans Kıyaslama çok daha yavaş olduğu kopyalama etkinliği verimini değerinden 2 MB/sn, açık.</span><span class="sxs-lookup"><span data-stu-id="48eea-431">**Test and analysis**: The throughput of Copy Activity is less than 2 MBps, which is much slower than the performance benchmark.</span></span>

<span data-ttu-id="48eea-432">**Performans Analizi ve ayarlama**: performans sorunu gidermek için nasıl veri işlenen taşınır ve konumundaki bakalım.</span><span class="sxs-lookup"><span data-stu-id="48eea-432">**Performance analysis and tuning**: To troubleshoot the performance issue, let’s look at how the data is processed and moved.</span></span>

1. <span data-ttu-id="48eea-433">**Veri Okuma**: ağ geçidi SQL Server için bir bağlantı açar ve sorgu gönderir.</span><span class="sxs-lookup"><span data-stu-id="48eea-433">**Read data**: Gateway opens a connection to SQL Server and sends the query.</span></span> <span data-ttu-id="48eea-434">SQL Server veri akışı için ağ geçidi intranet göndererek yanıt verir.</span><span class="sxs-lookup"><span data-stu-id="48eea-434">SQL Server responds by sending the data stream to Gateway via the intranet.</span></span>
2. <span data-ttu-id="48eea-435">**Seri hale getirmek ve verileri sıkıştırmak**: ağ geçidi, CSV biçiminde veri akışa serileştirir ve bir bzıp2 akış verileri sıkıştırır.</span><span class="sxs-lookup"><span data-stu-id="48eea-435">**Serialize and compress data**: Gateway serializes the data stream to CSV format, and compresses the data to a bzip2 stream.</span></span>
3. <span data-ttu-id="48eea-436">**Veri yazma**: ağ geçidi bzıp2 akış Internet üzerinden Blob depolama alanına yükler.</span><span class="sxs-lookup"><span data-stu-id="48eea-436">**Write data**: Gateway uploads the bzip2 stream to Blob storage via the Internet.</span></span>

<span data-ttu-id="48eea-437">Gördüğünüz gibi veri okunduğunu işlenir ve bir akış sıralı şekilde taşındı: SQL Server > LAN > ağ geçidi > WAN > Blob Depolama.</span><span class="sxs-lookup"><span data-stu-id="48eea-437">As you can see, the data is being processed and moved in a streaming sequential manner: SQL Server > LAN > Gateway > WAN > Blob storage.</span></span> <span data-ttu-id="48eea-438">**Genel performansı göre en düşük işleme ardışık düzeni geçişli**.</span><span class="sxs-lookup"><span data-stu-id="48eea-438">**The overall performance is gated by the minimum throughput across the pipeline**.</span></span>

![Veri akışı](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

<span data-ttu-id="48eea-440">Bir veya daha fazla bilgi için aşağıdaki etkenleri performans düşüklüğü neden olabilir:</span><span class="sxs-lookup"><span data-stu-id="48eea-440">One or more of the following factors might cause the performance bottleneck:</span></span>

* <span data-ttu-id="48eea-441">**Kaynak**: SQL Server kendisini nedeniyle ağır yük düşük işleme sahiptir.</span><span class="sxs-lookup"><span data-stu-id="48eea-441">**Source**: SQL Server itself has low throughput because of heavy loads.</span></span>
* <span data-ttu-id="48eea-442">**Veri Yönetimi ağ geçidi**:</span><span class="sxs-lookup"><span data-stu-id="48eea-442">**Data Management Gateway**:</span></span>
  * <span data-ttu-id="48eea-443">**LAN**: ağ geçidi gölgeden uzak SQL Server makinesinde bulunur ve düşük bant genişlikli bağlantısı vardır.</span><span class="sxs-lookup"><span data-stu-id="48eea-443">**LAN**: Gateway is located far from the SQL Server machine and has a low-bandwidth connection.</span></span>
  * <span data-ttu-id="48eea-444">**Ağ geçidi**: ağ geçidi, aşağıdaki işlemleri gerçekleştirmek için yük kısıtlamalarını ulaştı:</span><span class="sxs-lookup"><span data-stu-id="48eea-444">**Gateway**: Gateway has reached its load limitations to perform the following operations:</span></span>
    * <span data-ttu-id="48eea-445">**Seri hale getirme**: veri akışı CSV biçiminde seri hale getirme yavaş işleme sahiptir.</span><span class="sxs-lookup"><span data-stu-id="48eea-445">**Serialization**: Serializing the data stream to CSV format has slow throughput.</span></span>
    * <span data-ttu-id="48eea-446">**Sıkıştırma**: yavaş sıkıştırma codec (2.8 MB/sn Çekirdek i7 ile olan Örneğin, bzıp2,) seçtiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-446">**Compression**: You chose a slow compression codec (for example, bzip2, which is 2.8 MBps with Core i7).</span></span>
  * <span data-ttu-id="48eea-447">**WAN**: şirket ağına ve Azure hizmetlerinizi arasında bant genişliği düşükse (örneğin, T1 1,544 kbps; = T2 6,312 kbps =).</span><span class="sxs-lookup"><span data-stu-id="48eea-447">**WAN**: The bandwidth between the corporate network and your Azure services is low (for example, T1 = 1,544 kbps; T2 = 6,312 kbps).</span></span>
* <span data-ttu-id="48eea-448">**Havuz**: Blob depolama alanına sahip düşük işleme.</span><span class="sxs-lookup"><span data-stu-id="48eea-448">**Sink**: Blob storage has low throughput.</span></span> <span data-ttu-id="48eea-449">(Bu senaryoda en az 60 MB/sn SLA'sını güvence altına alır çünkü düşüktür.)</span><span class="sxs-lookup"><span data-stu-id="48eea-449">(This scenario is unlikely because its SLA guarantees a minimum of 60 MBps.)</span></span>

<span data-ttu-id="48eea-450">Bu durumda, bzıp2 veri sıkıştırma tüm ardışık yavaşlamasının.</span><span class="sxs-lookup"><span data-stu-id="48eea-450">In this case, bzip2 data compression might be slowing down the entire pipeline.</span></span> <span data-ttu-id="48eea-451">Gzip sıkıştırma codec için geçiş bu performans sorunu kolaylaştırır.</span><span class="sxs-lookup"><span data-stu-id="48eea-451">Switching to a gzip compression codec might ease this bottleneck.</span></span>

## <a name="sample-scenarios-use-parallel-copy"></a><span data-ttu-id="48eea-452">Örnek senaryo: paralel kopyasını kullanın</span><span class="sxs-lookup"><span data-stu-id="48eea-452">Sample scenarios: Use parallel copy</span></span>
<span data-ttu-id="48eea-453">**Senaryo I:** 1.000 1 MB dosyaların kopyalanacağı şirket içi dosya sistemi için Blob Depolama.</span><span class="sxs-lookup"><span data-stu-id="48eea-453">**Scenario I:** Copy 1,000 1-MB files from the on-premises file system to Blob storage.</span></span>

<span data-ttu-id="48eea-454">**Çözümleme ve performans ayarlama**: dört çekirdekli makine üzerinde ağ geçidi yüklediyseniz, bir örnek için veri fabrikası 16 paralel kopyaları dosyaları dosya sisteminden Blob depolama alanına eşzamanlı olarak taşımak için kullanır.</span><span class="sxs-lookup"><span data-stu-id="48eea-454">**Analysis and performance tuning**: For an example, if you have installed gateway on a quad core machine, Data Factory uses 16 parallel copies to move files from the file system to Blob storage concurrently.</span></span> <span data-ttu-id="48eea-455">Bu paralel yürütme yüksek performans neden olur.</span><span class="sxs-lookup"><span data-stu-id="48eea-455">This parallel execution should result in high throughput.</span></span> <span data-ttu-id="48eea-456">Paralel kopya sayısı da açıkça belirtebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-456">You also can explicitly specify the parallel copies count.</span></span> <span data-ttu-id="48eea-457">Çok sayıda küçük dosya kopyaladığınızda, paralel kopyaları önemli ölçüde işleme kaynakları daha verimli şekilde kullanarak yardımcı olur.</span><span class="sxs-lookup"><span data-stu-id="48eea-457">When you copy many small files, parallel copies dramatically help throughput by using resources more effectively.</span></span>

![Senaryo 1](./media/data-factory-copy-activity-performance/scenario-1.png)

<span data-ttu-id="48eea-459">**Senaryo II**: 20 BLOB'lar 500 MB'lık Data Lake deposu Analytics için Blob depolama alanından kopyalayın ve performansı ayarlamak.</span><span class="sxs-lookup"><span data-stu-id="48eea-459">**Scenario II**: Copy 20 blobs of 500 MB each from Blob storage to Data Lake Store Analytics, and then tune performance.</span></span>

<span data-ttu-id="48eea-460">**Çözümleme ve performans ayarlama**: Bu senaryoda, veri fabrikası verileri Blob depolama alanından Data Lake Store'a tek kopya kullanarak kopyalar (**parallelCopies** 1 olarak ayarlayın) ve tek bulut veri taşıma birimleri.</span><span class="sxs-lookup"><span data-stu-id="48eea-460">**Analysis and performance tuning**: In this scenario, Data Factory copies the data from Blob storage to Data Lake Store by using single-copy (**parallelCopies** set to 1) and single-cloud data movement units.</span></span> <span data-ttu-id="48eea-461">Gözlemlemek verimlilik, yakın içinde açıklanacaktır [performans başvuru bölümünde](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="48eea-461">The throughput you observe will be close to that described in the [performance reference section](#performance-reference).</span></span>   

![Senaryo 2](./media/data-factory-copy-activity-performance/scenario-2.png)

<span data-ttu-id="48eea-463">**Senaryo III**: tek tek dosya boyutu MB düzinelerce büyük ve toplam birim büyük değil.</span><span class="sxs-lookup"><span data-stu-id="48eea-463">**Scenario III**: Individual file size is greater than dozens of MBs and total volume is large.</span></span>

<span data-ttu-id="48eea-464">**Çözümleme ve performans dönüş**: artırma **parallelCopies** tek bulut DMU kaynak sınırlamaları nedeniyle kopyalama daha iyi performans elde edemezseniz.</span><span class="sxs-lookup"><span data-stu-id="48eea-464">**Analysis and performance turning**: Increasing **parallelCopies** doesn't result in better copy performance because of the resource limitations of a single-cloud DMU.</span></span> <span data-ttu-id="48eea-465">Bunun yerine, daha fazla bulut veri taşımayı gerçekleştirmek için daha fazla kaynak almak için DMUs belirtmeniz gerekir.</span><span class="sxs-lookup"><span data-stu-id="48eea-465">Instead, you should specify more cloud DMUs to get more resources to perform the data movement.</span></span> <span data-ttu-id="48eea-466">İçin bir değer belirtmezseniz **parallelCopies** özelliği.</span><span class="sxs-lookup"><span data-stu-id="48eea-466">Do not specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="48eea-467">Veri Fabrikası paralellik işler.</span><span class="sxs-lookup"><span data-stu-id="48eea-467">Data Factory handles the parallelism for you.</span></span> <span data-ttu-id="48eea-468">Bu durumda, ayarlarsanız **cloudDataMovementUnits** 4'e bir verimini hakkında dört kez oluşur.</span><span class="sxs-lookup"><span data-stu-id="48eea-468">In this case, if you set **cloudDataMovementUnits** to 4, a throughput of about four times occurs.</span></span>

![Senaryo 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## <a name="reference"></a><span data-ttu-id="48eea-470">Başvuru</span><span class="sxs-lookup"><span data-stu-id="48eea-470">Reference</span></span>
<span data-ttu-id="48eea-471">İzleme ve bazı desteklenen veri depoları için başvuru ayarlama performans şunlardır:</span><span class="sxs-lookup"><span data-stu-id="48eea-471">Here are performance monitoring and tuning references for some of the supported data stores:</span></span>

* <span data-ttu-id="48eea-472">Azure Storage (Blob Depolama ve tablo depolama dahil): [Azure Storage ölçeklenebilirlik hedefleri](../storage/common/storage-scalability-targets.md) ve [Azure Storage performans ve ölçeklenebilirlik Yapılacaklar listesi](../storage/common/storage-performance-checklist.md)</span><span class="sxs-lookup"><span data-stu-id="48eea-472">Azure Storage (including Blob storage and Table storage): [Azure Storage scalability targets](../storage/common/storage-scalability-targets.md) and [Azure Storage performance and scalability checklist](../storage/common/storage-performance-checklist.md)</span></span>
* <span data-ttu-id="48eea-473">Azure SQL Database: Yapabilecekleriniz [performansını izlemek](../sql-database/sql-database-single-database-monitor.md) ve veritabanı işlem birimi (DTU) yüzde denetleyin</span><span class="sxs-lookup"><span data-stu-id="48eea-473">Azure SQL Database: You can [monitor the performance](../sql-database/sql-database-single-database-monitor.md) and check the database transaction unit (DTU) percentage</span></span>
* <span data-ttu-id="48eea-474">Azure SQL Data Warehouse: Veri ambarı birimlerini (Dwu'lar); kendi yeteneği ölçülür bkz: [Yönet işlem güç Azure SQL Data warehouse'da (genel bakış)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span><span class="sxs-lookup"><span data-stu-id="48eea-474">Azure SQL Data Warehouse: Its capability is measured in data warehouse units (DWUs); see [Manage compute power in Azure SQL Data Warehouse (Overview)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span></span>
* <span data-ttu-id="48eea-475">Azure Cosmos DB: [Azure Cosmos veritabanı performans düzeyleri](../documentdb/documentdb-performance-levels.md)</span><span class="sxs-lookup"><span data-stu-id="48eea-475">Azure Cosmos DB: [Performance levels in Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span></span>
* <span data-ttu-id="48eea-476">Şirket içi SQL Server: [İzleyici ve performans ayarlama](https://msdn.microsoft.com/library/ms189081.aspx)</span><span class="sxs-lookup"><span data-stu-id="48eea-476">On-premises SQL Server: [Monitor and tune for performance](https://msdn.microsoft.com/library/ms189081.aspx)</span></span>
* <span data-ttu-id="48eea-477">Şirket içi dosya sunucusu: [dosya sunucuları için performans ayarlama](https://msdn.microsoft.com/library/dn567661.aspx)</span><span class="sxs-lookup"><span data-stu-id="48eea-477">On-premises file server: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)</span></span>
