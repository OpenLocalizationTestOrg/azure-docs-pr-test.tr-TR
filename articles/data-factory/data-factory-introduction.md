---
title: "Bir veri tümleştirme hizmeti olan Data Factory’ye giriş | Microsoft Belgeleri"
description: "Azure Data Factory’nin ne olduğunu öğrenin: verilerin taşınmasını ve dönüştürülmesini düzenleyen ve otomatikleştiren bir bulut veri tümleştirme hizmetidir."
keywords: "veri tümleştirme, bulut veri tümleştirme, azure data factory nedir"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: bc72c4d58b98f6521dbb7420a5d05a121b0ddbda
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: tr-TR
ms.lasthandoff: 08/18/2017
---
# <a name="introduction-to-azure-data-factory"></a><span data-ttu-id="f4608-104">Azure Data Factory'ye giriş</span><span class="sxs-lookup"><span data-stu-id="f4608-104">Introduction to Azure Data Factory</span></span> 
## <a name="what-is-azure-data-factory"></a><span data-ttu-id="f4608-105">Azure Data Factory nedir?</span><span class="sxs-lookup"><span data-stu-id="f4608-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="f4608-106">Büyük veri dünyasında, işletmede mevcut verilerden nasıl yararlanılır?</span><span class="sxs-lookup"><span data-stu-id="f4608-106">In the world of big data, how is existing data leveraged in business?</span></span> <span data-ttu-id="f4608-107">Şirket içi veri kaynaklarından veya diğer dağınık veri kaynaklarından elde edilen başvuru verilerini kullanarak bulutta oluşturulan verileri zenginleştirmek mümkün mü?</span><span class="sxs-lookup"><span data-stu-id="f4608-107">Is it possible to enrich data generated in the cloud by using reference data from on-premises data sources or other disparate data sources?</span></span> <span data-ttu-id="f4608-108">Örneğin, bir oyun şirketi, oyunlar tarafından üretilen çok sayıda günlüğü bulutta toplamaktadır.</span><span class="sxs-lookup"><span data-stu-id="f4608-108">For example, a gaming company collects many logs produced by games in the cloud.</span></span> <span data-ttu-id="f4608-109">Müşteri tercihleri, demografik bilgileri, kullanım davranışı, vb. konusunda fikir edinmek, yukarı satış ve çapraz satış fırsatlarını belirlemek, iş büyümesi sağlamak üzere yeni çekici özellikler geliştirmek ve müşterilere daha iyi bir deneyim sunmak üzere bu günlükleri analiz etmek istemektedir.</span><span class="sxs-lookup"><span data-stu-id="f4608-109">It wants to analyze these logs to gain insights in to customer preferences, demographics, usage behavior etc. to identify up-sell and cross-sell opportunities, develop new compelling features to drive business growth, and provide a better experience to customers.</span></span> 

<span data-ttu-id="f4608-110">Bu günlükleri analiz etmek için, şirketin şirket içi veri deposunda bulunan müşteri bilgileri, oyun bilgileri, pazarlama kampanyası bilgileri gibi başvuru verilerini kullanması gerekir.</span><span class="sxs-lookup"><span data-stu-id="f4608-110">To analyze these logs, the company needs to use the reference data such as customer information, game information, marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="f4608-111">Bu nedenle, şirket bulut veri deposundan günlük verilerini ve şirket içi veri deposundan başvuru verilerini almak istemektedir.</span><span class="sxs-lookup"><span data-stu-id="f4608-111">Therefore, the company wants to ingest log data from the cloud data store and reference data from the on-premises data store.</span></span> <span data-ttu-id="f4608-112">Ardından, bulutta (Azure HDInsight) Hadoop kullanarak verileri işleyip, sonuç verilerini Azure SQL Veri Ambarı gibi bir bulut veri ambarında veya SQL Server gibi bir şirket içi veri deposunda yayımlamak ister.</span><span class="sxs-lookup"><span data-stu-id="f4608-112">Then, process the data by using Hadoop in the cloud (Azure HDInsight) and publish the result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span></span> <span data-ttu-id="f4608-113">Bu iş akışının haftada bir kez gerçekleştirilmesini ister.</span><span class="sxs-lookup"><span data-stu-id="f4608-113">It wants this workflow to run weekly once.</span></span> 

<span data-ttu-id="f4608-114">Gerekli olan şey, şirketin hem şirket içindeki hem de buluttaki veri depolarından veri alabilen bir iş akışı oluşturmasına, Hadoop gibi mevcut işlem hizmetlerini kullanarak verileri dönüştürmesine ya da işlemesine ve sonuçları BI uygulamalarının kullanması için şirket içi veya bulut veri deposunda yayımlamaya olanak tanıyan bir platformdur.</span><span class="sxs-lookup"><span data-stu-id="f4608-114">What is needed is a platform that allows the company to create a workflow that can ingest data from both on-premises and cloud data stores, and transform or process data by using existing compute services such as Hadoop, and publish the results to an on-premises or cloud data store for BI applications to consume.</span></span> 

![Data Factory'ye genel bakış](media/data-factory-introduction/what-is-azure-data-factory.png) 

<span data-ttu-id="f4608-116">Azure Data Factory, bu tür senaryolara yönelik bir platformdur.</span><span class="sxs-lookup"><span data-stu-id="f4608-116">Azure Data Factory is the platform for this kind of scenarios.</span></span> <span data-ttu-id="f4608-117">**Bulutta veri hareketi ve veri dönüştürmeyi düzenleyip otomatikleştirmek için veri odaklı iş akışları oluşturmanıza olanak tanıyan, bulut tabanlı bir veri tümleştirme hizmetidir**.</span><span class="sxs-lookup"><span data-stu-id="f4608-117">It is a **cloud-based data integration service that allows you to create data-driven workflows in the cloud for orchestrating and automating data movement and data transformation**.</span></span> <span data-ttu-id="f4608-118">Azure Data Factory’yi kullanarak, farklı veri depolarından veri alabilen, Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics ve Azure Machine Learning gibi işlem hizmetlerini kullanarak verileri işleyebilen/dönüştürebilen ve çıktı verilerini iş zekası (BI) uygulamaları tarafından kullanılabilmesi için Azure SQL Veri Ambarı gibi veri depolarında yayımlayabilen veri odaklı iş akışları (işlem hatları olarak adlandırılır) oluşturup zamanlayabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="f4608-118">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores, process/transform the data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning, and publish output data to data stores such as Azure SQL Data Warehouse for business intelligence (BI) applications to consume.</span></span>  

<span data-ttu-id="f4608-119">Bu, geleneksel bir Ayıklama-Dönüştürme-Yükleme (ETL) platformu yerine daha çok Ayıklama-Dönüştürme (EL) ve sonra Dönüştürme-Yükleme (TL) platformudur.</span><span class="sxs-lookup"><span data-stu-id="f4608-119">It's more of an Extract-and-Load (EL) and then Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span></span> <span data-ttu-id="f4608-120">Gerçekleştirilen dönüşümler; türetilmiş sütunlar ekleme, satır sayısını sayma, verileri sıralama, vb. dönüşümleri gerçekleştirmek yerine işlem hizmetlerini kullanarak verileri dönüştürmek/işlemek için gerçekleştirilir.</span><span class="sxs-lookup"><span data-stu-id="f4608-120">The transformations that are performed are to transform/process data by using compute services rather than to perform transformations like the ones for adding derived columns, counting number of rows, sorting data, etc.</span></span> 

<span data-ttu-id="f4608-121">Şu anda Azure Data Factory’de iş akışları tarafından tüketilen ve üretilen veriler, **zaman dilimli verilerdir** (saatlik, günlük, haftalık, vb.).</span><span class="sxs-lookup"><span data-stu-id="f4608-121">Currently, in Azure Data Factory, the data that is consumed and produced by workflows is **time-sliced data** (hourly, daily, weekly, etc.).</span></span> <span data-ttu-id="f4608-122">Örneğin, bir işlem hattı günde bir kez giriş verilerini okuyabilir, verileri işleyebilir ve çıktı üretebilir.</span><span class="sxs-lookup"><span data-stu-id="f4608-122">For example, a pipeline may read input data, process data, and produce output data once a day.</span></span> <span data-ttu-id="f4608-123">Bir iş akışını yalnızca bir kez de çalıştırabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="f4608-123">You can also run a workflow just one time.</span></span>  
  

## <a name="how-does-it-work"></a><span data-ttu-id="f4608-124">Nasıl çalışır?</span><span class="sxs-lookup"><span data-stu-id="f4608-124">How does it work?</span></span> 
<span data-ttu-id="f4608-125">Azure Data Factory’deki işlem hatları (veri odaklı iş akışları) genellikle aşağıdaki üç adımı gerçekleştirir:</span><span class="sxs-lookup"><span data-stu-id="f4608-125">The pipelines (data-driven workflows) in Azure Data Factory typically perform the following three steps:</span></span>

![Azure Data Factory’nin üç aşaması](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a><span data-ttu-id="f4608-127">Bağlanma ve toplama</span><span class="sxs-lookup"><span data-stu-id="f4608-127">Connect and collect</span></span>
<span data-ttu-id="f4608-128">Kuruluşların dağınık kaynaklarda yer alan çeşitli türlerde verileri vardır.</span><span class="sxs-lookup"><span data-stu-id="f4608-128">Enterprises have data of various types located in disparate sources.</span></span> <span data-ttu-id="f4608-129">Bilgi üretim sistemi oluşturmanın ilk adımı SaaS hizmetleri, dosya paylaşımları, FTP, web hizmetleri gibi tüm gerekli veri kaynaklarına ve işleme çalışmalarına bağlanmak ve daha sonraki işleme çalışmaları için gerektiğinde verileri merkezi bir konuma taşımaktır.</span><span class="sxs-lookup"><span data-stu-id="f4608-129">The first step in building an information production system is to connect to all the required sources of data and processing, such as SaaS services, file shares, FTP, web services, and move the data as-needed to a centralized location for subsequent processing.</span></span>

<span data-ttu-id="f4608-130">Data Factory olmadığında, kuruluşların bu veri kaynaklarını ve işleme çalışmalarını tümleştirmek için özel veri taşıma bileşenleri oluşturması veya özel hizmetler yazması gerekir.</span><span class="sxs-lookup"><span data-stu-id="f4608-130">Without Data Factory, enterprises must build custom data movement components or write custom services to integrate these data sources and processing.</span></span> <span data-ttu-id="f4608-131">Bu tür sistemler pahalıdır, tümleştirmesi ve bakımı zordur; ayrıca tümüyle yönetilen bir hizmetin sağlayabileceği kurumsal sınıf izleme ve uyarılarla denetimlerden yoksundur.</span><span class="sxs-lookup"><span data-stu-id="f4608-131">It is expensive and hard to integrate and maintain such systems, and it often lacks the enterprise grade monitoring and alerting, and the controls that a fully managed service can offer.</span></span>

<span data-ttu-id="f4608-132">Data Factory ile, veri işlem hattında Kopyalama Etkinliği’ni kullanarak hem şirket içinde hem de buluttaki kaynak veri depolarını daha fazla analiz için merkezi bir veri deposuna taşıyabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="f4608-132">With Data Factory, you can use the Copy Activity in a data pipeline to move data from both on-premises and cloud source data stores to a centralization data store in the cloud for further analysis.</span></span> <span data-ttu-id="f4608-133">Örneğin, Azure Data Lake Store’da veri toplayabilir ve daha sonra Azure Data Lake Analytics işlem hizmetini kullanarak verileri dönüştürebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="f4608-133">For example, you can collect data in an Azure Data Lake Store and transform the data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="f4608-134">Öte yandan, verileri Azure Blob Depolama Alanı’ndan toplayıp daha sonra Azure HDInsight Hadoop kümesi kullanarak da dönüştürebilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="f4608-134">Or, collect data in an Azure Blob Storage and transform data later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="f4608-135">Dönüştürme ve zenginleştirme</span><span class="sxs-lookup"><span data-stu-id="f4608-135">Transform and enrich</span></span>
<span data-ttu-id="f4608-136">Veriler buluttaki merkezi bir veri deposuna sunulduktan sonra, toplanan verilerin HDInsight Hadoop, Spark, Data Lake Analytics ve Machine Learning gibi işlem hizmetleri kullanılarak işlenmesi veya dönüştürülmesi gerekir.</span><span class="sxs-lookup"><span data-stu-id="f4608-136">Once data is present in a centralized data store in the cloud, you want the collected data to be processed or transformed by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span></span> <span data-ttu-id="f4608-137">Üretim ortamlarının güvenilir verilerle beslenmesi için sürdürülebilir ve denetlenebilir bir zamanlamaya göre dönüştürülmüş verileri güvenilir bir şekilde üretmeniz gerekir.</span><span class="sxs-lookup"><span data-stu-id="f4608-137">You want to reliably produce transformed data on a maintainable and controlled schedule to feed production environments with trusted data.</span></span> 

### <a name="publish"></a><span data-ttu-id="f4608-138">Yayımlama</span><span class="sxs-lookup"><span data-stu-id="f4608-138">Publish</span></span> 
<span data-ttu-id="f4608-139">Dönüştürülen verileri buluttan SQL Server gibi şirket içi kaynaklara aktarın veya iş zekası (BI) uygulamaları, analiz araçları ya da diğer uygulamalar tarafından kullanılmak üzere bulut depolama kaynaklarınızda saklayın.</span><span class="sxs-lookup"><span data-stu-id="f4608-139">Deliver transformed data from the cloud to on-premises sources like SQL Server, or keep it in your cloud storage sources for consumption by business intelligence (BI) and analytics tools and other applications.</span></span>

## <a name="key-components"></a><span data-ttu-id="f4608-140">Başlıca bileşenler</span><span class="sxs-lookup"><span data-stu-id="f4608-140">Key components</span></span>
<span data-ttu-id="f4608-141">Azure aboneliğinin bir veya birden çok Azure Data Factory örneği (veya veri fabrikası) olabilir.</span><span class="sxs-lookup"><span data-stu-id="f4608-141">An Azure subscription may have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="f4608-142">Azure Data Factory, üzerinde veri taşıma ve dönüştürme adımları ile veri odaklı iş akışları oluşturabileceğiniz platformu sağlamak üzere birlikte çalışan başlıca dört bileşenden oluşur.</span><span class="sxs-lookup"><span data-stu-id="f4608-142">Azure Data Factory is composed of four key components that work together to provide the platform on which you can compose data-driven workflows with steps to move and transform data.</span></span> 

### <a name="pipeline"></a><span data-ttu-id="f4608-143">İşlem hattı</span><span class="sxs-lookup"><span data-stu-id="f4608-143">Pipeline</span></span>
<span data-ttu-id="f4608-144">Bir veri fabrikasında bir veya daha fazla işlem hattı olabilir.</span><span class="sxs-lookup"><span data-stu-id="f4608-144">A data factory may have one or more pipelines.</span></span> <span data-ttu-id="f4608-145">İşlem hattı bir grup etkinliktir.</span><span class="sxs-lookup"><span data-stu-id="f4608-145">A pipeline is a group of activities.</span></span> <span data-ttu-id="f4608-146">İşlem hattındaki etkinlikler birlikte bir görev gerçekleştirir.</span><span class="sxs-lookup"><span data-stu-id="f4608-146">Together, the activities in a pipeline perform a task.</span></span> <span data-ttu-id="f4608-147">Örneğin, bir işlem hattı Azure blobundan verileri alan ve ardından HDInsight kümesinde Hive sorgusu çalıştırarak verileri bölümlere ayıran bir grup etkinlik içerebilir.</span><span class="sxs-lookup"><span data-stu-id="f4608-147">For example, a pipeline could contain a group of activities that ingests data from an Azure blob, and then run a Hive query on an HDInsight cluster to partition the data.</span></span> <span data-ttu-id="f4608-148">İşlem hattının avantajı, etkinliklerin her birini tek tek yönetmek yerine bir küme olarak yönetmenize olanak tanımasıdır.</span><span class="sxs-lookup"><span data-stu-id="f4608-148">The benefit of this is that the pipeline allows you to manage the activities as a set instead of each one individually.</span></span> <span data-ttu-id="f4608-149">Örneğin, etkinlikleri bağımsız olarak dağıtmak ve zamanlamak yerine işlem hattını dağıtabilir ve zamanlayabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="f4608-149">For example, you can deploy and schedule the pipeline, instead of the activities independently.</span></span> 

### <a name="activity"></a><span data-ttu-id="f4608-150">Etkinlik</span><span class="sxs-lookup"><span data-stu-id="f4608-150">Activity</span></span>
<span data-ttu-id="f4608-151">İşlem hattında bir veya daha fazla etkinlik olabilir.</span><span class="sxs-lookup"><span data-stu-id="f4608-151">A pipeline may have one or more activities.</span></span> <span data-ttu-id="f4608-152">Etkinlikler, verilerinizde gerçekleştirilecek eylemleri tanımlayın.</span><span class="sxs-lookup"><span data-stu-id="f4608-152">Activities define the actions to perform on your data.</span></span> <span data-ttu-id="f4608-153">Örneğin, bir veri deposundan başka bir veri deposuna veri kopyalamak için Kopyalama etkinliğini kullanabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="f4608-153">For example, you may use a Copy activity to copy data from one data store to another data store.</span></span> <span data-ttu-id="f4608-154">Benzer şekilde, verilerinizi dönüştürmek veya analiz etmek amacıyla Azure HDInsight kümesinde bir Hive sorgusu çalıştıran bir Hive etkinliği kullanabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="f4608-154">Similarly, you may use a Hive activity, which runs a Hive query on an Azure HDInsight cluster to transform or analyze your data.</span></span> <span data-ttu-id="f4608-155">Data Factory iki tür etkinliği destekler: veri taşıma etkinlikleri ve veri dönüştürme etkinlikleri.</span><span class="sxs-lookup"><span data-stu-id="f4608-155">Data Factory supports two types of activities: data movement activities and data transformation activities.</span></span>

### <a name="data-movement-activities"></a><span data-ttu-id="f4608-156">Veri taşıma etkinlikleri</span><span class="sxs-lookup"><span data-stu-id="f4608-156">Data movement activities</span></span>
<span data-ttu-id="f4608-157">Data Factory’deki Kopyalama Etkinliği bir kaynak veri deposundan havuz veri deposuna verileri kopyalar.</span><span class="sxs-lookup"><span data-stu-id="f4608-157">Copy Activity in Data Factory copies data from a source data store to a sink data store.</span></span> <span data-ttu-id="f4608-158">Data Factory aşağıdaki veri depolarını destekler.</span><span class="sxs-lookup"><span data-stu-id="f4608-158">Data Factory supports the following data stores.</span></span> <span data-ttu-id="f4608-159">Herhangi bir kaynaktan gelen veriler herhangi bir havuza yazılabilir.</span><span class="sxs-lookup"><span data-stu-id="f4608-159">Data from any source can be written to any sink.</span></span> <span data-ttu-id="f4608-160">Bir depoya veya depodan veri kopyalama hakkında bilgi edinmek için veri deposuna tıklayın.</span><span class="sxs-lookup"><span data-stu-id="f4608-160">Click a data store to learn how to copy data to and from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="f4608-161">Daha fazla bilgi için [Veri Taşıma Etkinlikleri](data-factory-data-movement-activities.md) makalesine bakın.</span><span class="sxs-lookup"><span data-stu-id="f4608-161">For more information, see [Data Movement Activities](data-factory-data-movement-activities.md) article.</span></span>

### <a name="data-transformation-activities"></a><span data-ttu-id="f4608-162">Veri dönüştürme etkinlikleri</span><span class="sxs-lookup"><span data-stu-id="f4608-162">Data transformation activities</span></span>
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

<span data-ttu-id="f4608-163">Daha fazla bilgi için [Veri Dönüştürme Etkinlikleri](data-factory-data-transformation-activities.md) makalesine bakın.</span><span class="sxs-lookup"><span data-stu-id="f4608-163">For more information, see [Data Transformation Activities](data-factory-data-transformation-activities.md) article.</span></span>

### <a name="custom-net-activities"></a><span data-ttu-id="f4608-164">Özel .NET etkinlikleri</span><span class="sxs-lookup"><span data-stu-id="f4608-164">Custom .NET activities</span></span>
<span data-ttu-id="f4608-165">Kopyalama Etkinliğinin desteklemediği bir veri deposuna/veri deposundan veri taşımanız ya da kendi mantığınızı kullanarak verileri dönüştürmeniz gerekirse **özel bir .NET etkinliği** oluşturun.</span><span class="sxs-lookup"><span data-stu-id="f4608-165">If you need to move data to/from a data store that Copy Activity doesn't support, or transform data using your own logic, create a **custom .NET activity**.</span></span> <span data-ttu-id="f4608-166">Özel bir etkinlik oluşturma ve kullanma hakkında ayrıntılı bilgi için bkz. [Azure Data Factory işlem hattında özel etkinlikler kullanma](data-factory-use-custom-activities.md).</span><span class="sxs-lookup"><span data-stu-id="f4608-166">For details on creating and using a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span></span>

### <a name="datasets"></a><span data-ttu-id="f4608-167">Veri kümeleri</span><span class="sxs-lookup"><span data-stu-id="f4608-167">Datasets</span></span>
<span data-ttu-id="f4608-168">Bir etkinlik girdi olarak sıfır veya daha fazla veri kümesi ve çıktı olarak bir ya da daha fazla veri kümesi alır.</span><span class="sxs-lookup"><span data-stu-id="f4608-168">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span></span> <span data-ttu-id="f4608-169">Veri kümeleri, veri depoları içinde etkinliklerinizde giriş veya çıkış olarak kullanmak istediğiniz verilere işaret eden veya başvuruda bulunan veri yapılarını temsil eder.</span><span class="sxs-lookup"><span data-stu-id="f4608-169">Datasets represent data structures within the data stores, which simply point or reference the data you want to use in your activities as inputs or outputs.</span></span> <span data-ttu-id="f4608-170">Örneğin Azure Blob veri kümesi, işlem hattının verileri okuması gereken blob kapsayıcısını ve Azure Blob Depolama klasörünü belirtir.</span><span class="sxs-lookup"><span data-stu-id="f4608-170">For example, an Azure Blob dataset specifies the blob container and folder in the Azure Blob Storage from which the pipeline should read the data.</span></span> <span data-ttu-id="f4608-171">Veya bir Azure SQL Tablosu veri kümesi, çıktı verilerinin etkinlik tarafından yazılacağı tabloyu belirtir.</span><span class="sxs-lookup"><span data-stu-id="f4608-171">Or, an Azure SQL Table dataset specifies the table to which the output data is written by the activity.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="f4608-172">Bağlı hizmetler</span><span class="sxs-lookup"><span data-stu-id="f4608-172">Linked services</span></span>
<span data-ttu-id="f4608-173">Bağlı hizmetler, dış kaynaklara bağlanmak için Data Factory’ye gereken bağlantı bilgilerini tanımlayan bağlantı dizelerine çok benzer.</span><span class="sxs-lookup"><span data-stu-id="f4608-173">Linked services are much like connection strings, which define the connection information needed for Data Factory to connect to external resources.</span></span> <span data-ttu-id="f4608-174">Şöyle düşünün: bağlı bir hizmet, veri kaynağıyla bağlantıyı tanımlar ve veri kümesi verilerin yapısını temsil eder.</span><span class="sxs-lookup"><span data-stu-id="f4608-174">Think of it this way - a linked service defines the connection to the data source and a dataset represents the structure of the data.</span></span> <span data-ttu-id="f4608-175">Örneğin, Azure Depolama bağlı hizmeti Azure Depolama hesabına bağlanacak bağlantı dizesini belirtir.</span><span class="sxs-lookup"><span data-stu-id="f4608-175">For example, an Azure Storage linked service specifies connection string to connect to the Azure Storage account.</span></span> <span data-ttu-id="f4608-176">Ayrıca, bir Azure Blob veri kümesi blob kapsayıcıyı ve verileri içeren klasörü belirtir.</span><span class="sxs-lookup"><span data-stu-id="f4608-176">And, an Azure Blob dataset specifies the blob container and the folder that contains the data.</span></span>   

<span data-ttu-id="f4608-177">Bağlı hizmetler Data Factory’de iki amaçla kullanılır:</span><span class="sxs-lookup"><span data-stu-id="f4608-177">Linked services are used for two purposes in Data Factory:</span></span>

* <span data-ttu-id="f4608-178">Bir **veri deposunu**, buradakilerle, ancak bunlarla sınırlı olmamak şartıyla göstermek için: şirket içi SQL Server, Oracle veritabanı, dosya paylaşımı veya bir Azure Blob Depolama hesabı.</span><span class="sxs-lookup"><span data-stu-id="f4608-178">To represent a **data store** including, but not limited to, an on-premises SQL Server, Oracle database, file share, or an Azure Blob Storage account.</span></span> <span data-ttu-id="f4608-179">Desteklenen veri depolarının bir listesi için [Veri taşıma etkinlikleri](#data-movement-activities) bölümüne bakın.</span><span class="sxs-lookup"><span data-stu-id="f4608-179">See the [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span></span>
* <span data-ttu-id="f4608-180">Etkinlik yürütülmesini barındırabilen **işlem kaynağını** temsil etmek için.</span><span class="sxs-lookup"><span data-stu-id="f4608-180">To represent a **compute resource** that can host the execution of an activity.</span></span> <span data-ttu-id="f4608-181">Örneğin, HDInsightHive etkinliği bir HDInsight Hadoop kümesinde yürütülür.</span><span class="sxs-lookup"><span data-stu-id="f4608-181">For example, the HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="f4608-182">Desteklenen işlem ortamlarının listesi için [Veri dönüştürme etkinlikleri](#data-transformation-activities) bölümüne bakın.</span><span class="sxs-lookup"><span data-stu-id="f4608-182">See [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span></span>

### <a name="relationship-between-data-factory-entities"></a><span data-ttu-id="f4608-183">Data Factory varlıkları arasındaki ilişki</span><span class="sxs-lookup"><span data-stu-id="f4608-183">Relationship between Data Factory entities</span></span>
<span data-ttu-id="f4608-184">![Diyagram: Bir bulut veri tümleştirme hizmeti olan Data Factory ile ilgili Temel Kavramlar](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure2.**</span><span class="sxs-lookup"><span data-stu-id="f4608-184">![Diagram: Data Factory, a cloud data integration service - Key Concepts](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span></span> <span data-ttu-id="f4608-185">Veri kümesi, Etkinlik, İşlem Hattı ve Bağlı hizmet arasındaki ilişkiler</span><span class="sxs-lookup"><span data-stu-id="f4608-185">Relationships between Dataset, Activity, Pipeline, and Linked service</span></span>

## <a name="supported-regions"></a><span data-ttu-id="f4608-186">Desteklenen bölgeler</span><span class="sxs-lookup"><span data-stu-id="f4608-186">Supported regions</span></span>
<span data-ttu-id="f4608-187">Şu anda **Batı ABD**, **Doğu ABD** ve **Kuzey Avrupa** bölgelerinde veri fabrikaları oluşturabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="f4608-187">Currently, you can create data factories in the **West US**, **East US**, and **North Europe** regions.</span></span> <span data-ttu-id="f4608-188">Ancak, verileri veri depoları arasında taşımak ve işlem hizmetlerini kullanarak verileri işlemek amacıyla data factory başka Azure bölgelerindeki veri depolarına ve işlem hizmetlerine erişebilir.</span><span class="sxs-lookup"><span data-stu-id="f4608-188">However, a data factory can access data stores and compute services in other Azure regions to move data between data stores or process data using compute services.</span></span>

<span data-ttu-id="f4608-189">Azure Data Factory’nin kendisi verileri depolamaz.</span><span class="sxs-lookup"><span data-stu-id="f4608-189">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="f4608-190">Veri hareketini [desteklenen veri depoları](#data-movement-activities) arasında, verilerin işlenmesini de başka bölgelerde veya şirket içi bir ortamda [işlem hizmetleri](#data-transformation-activities) kullanarak düzenlemek için veri temelinde iş akışları oluşturmanızı sağlar.</span><span class="sxs-lookup"><span data-stu-id="f4608-190">It lets you create data-driven workflows to orchestrate movement of data between [supported data stores](#data-movement-activities) and processing of data using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span></span> <span data-ttu-id="f4608-191">Hem programlama, hem de kullanıcı arabirimi mekanizmalarını kullanarak [iş akışlarını izlemenizi ve yönetmenizi](data-factory-monitor-manage-pipelines.md) de sağlar.</span><span class="sxs-lookup"><span data-stu-id="f4608-191">It also allows you to [monitor and manage workflows](data-factory-monitor-manage-pipelines.md) using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="f4608-192">Data Factory yalnızca **Batı ABD**, **Doğu ABD** **Kuzey Avrupa** bölgelerinde kullanılabilir olsa da, Data Factory’de veri taşımayı destekleyen hizmet birçok bölgede [küresel olarak](data-factory-data-movement-activities.md#global) kullanılabilmektedir.</span><span class="sxs-lookup"><span data-stu-id="f4608-192">Even though Data Factory is available in only **West US**, **East US**, and **North Europe** regions, the service powering the data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span></span> <span data-ttu-id="f4608-193">Veri deposunun güvenlik duvarı ardında kaldığı durumlarda şirket içi ortamınızda yüklü bir [Veri Yönetimi Ağ Geçidi](data-factory-move-data-between-onprem-and-cloud.md) bunun yerine verileri taşır.</span><span class="sxs-lookup"><span data-stu-id="f4608-193">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) installed in your on-premises environment moves the data instead.</span></span>

<span data-ttu-id="f4608-194">Örneğin, Azure HDInsight kümesi ve Azure Machine Learning gibi işlem ortamlarınızın Batı Avrupa bölgesinde çalıştığını varsayalım.</span><span class="sxs-lookup"><span data-stu-id="f4608-194">For an example, let us assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of West Europe region.</span></span> <span data-ttu-id="f4608-195">Kuzey Avrupa’da bir Azure Data Factory örneği oluşturup geliştirebilir ve bunu Batı Avrupa’daki işlem ortamlarınızda iş zamanlamak için kullanabilirsiniz.</span><span class="sxs-lookup"><span data-stu-id="f4608-195">You can create and use an Azure Data Factory instance in North Europe and use it to schedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="f4608-196">Data Factory’nin işlem ortamınızda işi tetiklemesi birkaç milisaniye alsa da, bilgi işlem ortamınızda işin çalıştırılma süresi değişmez.</span><span class="sxs-lookup"><span data-stu-id="f4608-196">It takes a few milliseconds for Data Factory to trigger the job on your compute environment but the time for running the job on your computing environment does not change.</span></span>

## <a name="get-started-with-creating-a-pipeline"></a><span data-ttu-id="f4608-197">İşlem hattı oluşturmaya başlama</span><span class="sxs-lookup"><span data-stu-id="f4608-197">Get started with creating a pipeline</span></span>
<span data-ttu-id="f4608-198">Azure Data Factory'de veri işlem hatları oluşturmak için bu araç veya API'lerden birini kullanabilirsiniz:</span><span class="sxs-lookup"><span data-stu-id="f4608-198">You can use one of these tools or APIs to create data pipelines in Azure Data Factory:</span></span> 

- <span data-ttu-id="f4608-199">Azure portalına</span><span class="sxs-lookup"><span data-stu-id="f4608-199">Azure portal</span></span>
- <span data-ttu-id="f4608-200">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="f4608-200">Visual Studio</span></span>
- <span data-ttu-id="f4608-201">PowerShell</span><span class="sxs-lookup"><span data-stu-id="f4608-201">PowerShell</span></span>
- <span data-ttu-id="f4608-202">.NET API’si</span><span class="sxs-lookup"><span data-stu-id="f4608-202">.NET API</span></span>
- <span data-ttu-id="f4608-203">REST API</span><span class="sxs-lookup"><span data-stu-id="f4608-203">REST API</span></span>
- <span data-ttu-id="f4608-204">Azure Resource Manager şablonu.</span><span class="sxs-lookup"><span data-stu-id="f4608-204">Azure Resource Manager template.</span></span> 

<span data-ttu-id="f4608-205">Veri işlem hatları ile veri fabrikaları oluşturmayı öğrenmek için aşağıdaki öğreticilerde yer alan adım adım yönergeleri izleyin:</span><span class="sxs-lookup"><span data-stu-id="f4608-205">To learn how to build data factories with data pipelines, follow step-by-step instructions in the following tutorials:</span></span>

| <span data-ttu-id="f4608-206">Öğretici</span><span class="sxs-lookup"><span data-stu-id="f4608-206">Tutorial</span></span> | <span data-ttu-id="f4608-207">Açıklama</span><span class="sxs-lookup"><span data-stu-id="f4608-207">Description</span></span> |
| --- | --- |
| [<span data-ttu-id="f4608-208">İki bulut veri deposu arasında veri taşıma</span><span class="sxs-lookup"><span data-stu-id="f4608-208">Move data between two cloud data stores</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |<span data-ttu-id="f4608-209">Bu öğreticide, Blob depolama biriminden SQL veritabanına **veri taşıyan** bir işlem hattı ile veri fabrikası oluşturacaksınız.</span><span class="sxs-lookup"><span data-stu-id="f4608-209">In this tutorial, you create a data factory with a pipeline that **moves data** from Blob storage to SQL database.</span></span> |
| [<span data-ttu-id="f4608-210">Hadoop kümesi kullanarak veri dönüştürme</span><span class="sxs-lookup"><span data-stu-id="f4608-210">Transform data using Hadoop cluster</span></span>](data-factory-build-your-first-pipeline.md) |<span data-ttu-id="f4608-211">Bu öğreticide, bir Azure HDInsight (Hadoop) kümesinde Hive betiği çalıştırarak **veri işleyen** bir veri işlem hattı ile ilk Azure veri fabrikanızı oluşturacaksınız.</span><span class="sxs-lookup"><span data-stu-id="f4608-211">In this tutorial, you build your first Azure data factory with a data pipeline that **processes data** by running Hive script on an Azure HDInsight (Hadoop) cluster.</span></span> |
| [<span data-ttu-id="f4608-212">Veri Yönetimi Ağ Geçidi'ni kullanarak verileri şirket içi veri deposu ile bulut veri deposu arasında taşıma</span><span class="sxs-lookup"><span data-stu-id="f4608-212">Move data between an on-premises data store and a cloud data store using Data Management Gateway</span></span>](data-factory-move-data-between-onprem-and-cloud.md) |<span data-ttu-id="f4608-213">Bu öğreticide, **şirket içi** SQL Server veritabanından Azure blob’a **veri taşıyan** bir işlem hattı ile veri fabrikası oluşturacaksınız.</span><span class="sxs-lookup"><span data-stu-id="f4608-213">In this tutorial, you build a data factory with a pipeline that **moves data** from an **on-premises** SQL Server database to an Azure blob.</span></span> <span data-ttu-id="f4608-214">Adım adım kılavuzun bir parçası olarak makinenize Veri Yönetimi Ağ Geçidi yükleyip bunu yapılandıracaksınız.</span><span class="sxs-lookup"><span data-stu-id="f4608-214">As part of the walkthrough, you install and configure the Data Management Gateway on your machine.</span></span> |
